{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f358a0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 16:39:42.552919: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import timm\n",
    "import sys \n",
    "from torchinfo import summary\n",
    "from scipy import signal\n",
    "import pyVHR as vhr\n",
    "import pickle\n",
    "from typing import Optional\n",
    "import math\n",
    "import os\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "from TorchLossComputer import TorchLossComputer\n",
    "from TorchLossComputerCPU import TorchLossComputerCPU\n",
    "from PhysFormer import ViT_ST_ST_Compact3_TDC_gra_sharp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed817b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/datasets/VHR1/PURE\n"
     ]
    }
   ],
   "source": [
    "PATCH_SIZE = 16\n",
    "EMBED_DIM = PATCH_SIZE * PATCH_SIZE * 3\n",
    "NUM_PATCHES = 100\n",
    "IMG_SIZE = PATCH_SIZE * NUM_PATCHES\n",
    "HEADS = 12\n",
    "BLOCKS = 12\n",
    "BATCH = 300\n",
    "LENGTH = 160\n",
    "\n",
    "vhr.plot.VisualizeParams.renderer = 'notebook'  # or 'notebook'\n",
    "\n",
    "dataset_name = 'pure'           \n",
    "video_DIR = '/var/datasets/VHR1/'  \n",
    "BVP_DIR = '/var/datasets/VHR1/'    \n",
    "\n",
    "dataset = vhr.datasets.datasetFactory(dataset_name, videodataDIR=video_DIR, BVPdataDIR=BVP_DIR)\n",
    "allvideo = dataset.videoFilenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b99c4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, bvp, stride = 5, window = 160):\n",
    "    tmp = []\n",
    "    tmp_bvp = []\n",
    "    for i in range(0, len(lst)-window, stride):\n",
    "        tmp.append(torch.as_tensor(lst[i:i + window]))\n",
    "        tmp_bvp.append(torch.as_tensor(bvp[i:i + window]))\n",
    "    if tmp[-1].shape[0] != tmp[0].shape[0]:\n",
    "        return(torch.stack(tmp[:-1]),torch.stack(tmp_bvp[:-1]))\n",
    "    return(torch.stack(tmp),torch.stack(tmp_bvp))\n",
    "        \n",
    "#webs,train_bvp = chunks(webs,train_bvp,160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7e14710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(tot):\n",
    "    min_len = 0\n",
    "    train_video = []\n",
    "    train_bvp = []\n",
    "    val_video = []\n",
    "    val_bvp = []\n",
    "    test_video = []\n",
    "    test_bvp = []\n",
    "    for idx in range(0,tot):\n",
    "        with open('/var/datasets/PURE_webs/'+str(idx)+'-WEBS-'+str(PATCH_SIZE), 'rb') as f:\n",
    "            #print('/var/datasets/PURE_webs/'+str(idx)+'-WEBS-'+str(PATCH_SIZE))\n",
    "            (webs,labels) = pickle.load(f)\n",
    "            if idx < ((tot/10)*9)-1:   #9 : 0 : 1\n",
    "                train_video.append(webs)\n",
    "                train_bvp.append(labels)\n",
    "            #elif idx < (tot/10)*8+(tot/10):\n",
    "                #print(2)\n",
    "                #val_video.append(webs)\n",
    "                #val_bvp.append(labels)\n",
    "            else:\n",
    "                #print(3)\n",
    "                test_video.append(webs)\n",
    "                test_bvp.append(labels)\n",
    "            if min_len==0 or len(webs)<min_len:\n",
    "                min_len = len(webs)\n",
    "    for i in range(0,len(train_video)):\n",
    "        train_video[i],train_bvp[i] = chunks(train_video[i][:min_len-1], train_bvp[i][:min_len-1])\n",
    "    #for i in range(0,len(val_video)):\n",
    "    #    val_video[i],val_bvp[i] = chunks(val_video[i][:min_len-1], val_bvp[i][:min_len-1],160)\n",
    "    for i in range(0,len(test_video)):\n",
    "        test_video[i],test_bvp[i] = chunks(test_video[i][:min_len-1], test_bvp[i][:min_len-1])\n",
    "    return (train_video, train_bvp), (val_video, val_bvp), (test_video, test_bvp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7adaef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckp(model, optimizer, epoch, loss, iteration, path=\".\"):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'iteration': iteration + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    f_path = path + '/checkpoint.pt'\n",
    "    torch.save(checkpoint, f_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28999bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(model, optimizer, path='./checkpoint.pt'):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer, checkpoint['epoch'], checkpoint['iteration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e27886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neg_Pearson(nn.Module):    # Pearson range [-1, 1] so if < 0, abs|loss| ; i>0, 1- loss                                                                      \n",
    "    def __init__(self):                                                           \n",
    "        super(Neg_Pearson,self).__init__()\n",
    "        return\n",
    "    def forward(self, preds, labels):       # all variable operation    \n",
    "        loss = 0\n",
    "        for i in range(preds.shape[0]):\n",
    "            sum_x = torch.sum(preds[i])\n",
    "            sum_y = torch.sum(labels[i])\n",
    "            sum_xy = torch.sum(preds[i]*labels[i])\n",
    "            sum_x2 = torch.sum(torch.pow(preds[i],2))\n",
    "            sum_y2 = torch.sum(torch.pow(labels[i],2))\n",
    "            N = preds.shape[1]\n",
    "            pearson = (N*sum_xy - sum_x*sum_y)/(torch.sqrt((N*sum_x2 - torch.pow(sum_x,2))*(N*sum_y2 - torch.pow(sum_y,2))))\n",
    "            loss += 1 - pearson\n",
    "        loss = loss/preds.shape[0]\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4b15612",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgrageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.cnt = 0\n",
    "        \n",
    "    def update(self, val, n=1):\n",
    "        self.sum += val * n\n",
    "        self.cnt += n\n",
    "        self.avg = (self.sum / self.cnt).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da28c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_video,train_bvp),(val_video,val_bvp),(test_video,test_bvp) = load_data(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ac2cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video, train_bvp = torch.cat(train_video[:]), torch.cat(train_bvp[:])\n",
    "#val_video, val_bvp     = torch.cat(val_video[:]), torch.cat(val_bvp[:])\n",
    "test_video, test_bvp   = torch.cat(test_video[:]), torch.cat(test_bvp[:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4cda98f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_bvp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3509692/3869231617.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclazz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_bvp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbvp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbvp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclazz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclazz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbvp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclazz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbvp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_bvp' is not defined"
     ]
    }
   ],
   "source": [
    "clazz = {}\n",
    "for frame in train_bvp:\n",
    "    for bvp in video:\n",
    "        if bvp.item() in clazz: clazz[bvp.item()] += 1\n",
    "        else: clazz[bvp.item()] = 1\n",
    "            \n",
    "print(clazz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "faf021cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 21\n",
      "0: 670\n",
      "1: 213\n",
      "2: 256\n",
      "3: 96\n",
      "4: 64\n",
      "5: 353\n",
      "6: 289\n",
      "7: 430\n",
      "8: 576\n",
      "9: 717\n",
      "10: 670\n",
      "11: 1024\n",
      "12: 1081\n",
      "13: 1560\n",
      "14: 2013\n",
      "15: 2292\n",
      "16: 2634\n",
      "17: 3997\n",
      "18: 4838\n",
      "19: 5072\n",
      "20: 6595\n",
      "21: 7415\n",
      "22: 9295\n",
      "23: 9360\n",
      "24: 10748\n",
      "25: 11607\n",
      "26: 11641\n",
      "27: 11426\n",
      "28: 9766\n",
      "29: 8935\n",
      "30: 8583\n",
      "31: 7304\n",
      "32: 6731\n",
      "33: 7013\n",
      "34: 5638\n",
      "35: 4866\n",
      "36: 4570\n",
      "37: 4851\n",
      "38: 5083\n",
      "39: 5412\n",
      "40: 5959\n",
      "41: 4886\n",
      "42: 5016\n",
      "43: 5656\n",
      "44: 5690\n",
      "45: 5346\n",
      "46: 6411\n",
      "47: 6137\n",
      "48: 6317\n",
      "49: 5990\n",
      "50: 6213\n",
      "51: 6188\n",
      "52: 5783\n",
      "53: 4529\n",
      "54: 5161\n",
      "55: 5327\n",
      "56: 4718\n",
      "57: 4161\n",
      "58: 3298\n",
      "59: 3437\n",
      "60: 3711\n",
      "61: 3895\n",
      "62: 3670\n",
      "63: 3215\n",
      "64: 2887\n",
      "65: 3694\n",
      "66: 2581\n",
      "67: 2211\n",
      "68: 2830\n",
      "69: 2218\n",
      "70: 1794\n",
      "71: 2519\n",
      "72: 1733\n",
      "73: 1454\n",
      "74: 1485\n",
      "75: 1123\n",
      "76: 1087\n",
      "77: 1113\n",
      "78: 845\n",
      "79: 809\n",
      "80: 725\n",
      "81: 856\n",
      "82: 511\n",
      "83: 683\n",
      "84: 480\n",
      "85: 448\n",
      "86: 432\n",
      "87: 292\n",
      "88: 388\n",
      "89: 111\n",
      "90: 217\n",
      "91: 153\n",
      "92: 103\n",
      "93: 32\n",
      "94: 103\n",
      "96: 64\n",
      "97: 160\n",
      "99: 32\n",
      "100: 32\n",
      "104: 32\n",
      "105: 64\n"
     ]
    }
   ],
   "source": [
    "for k in sorted(clazz.keys()):\n",
    "    print(str(k) + \": \"+ str(clazz[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1f1a5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2142, 160, 160, 160, 3]) torch.Size([2142, 160])\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "ViT_ST_ST_Compact3_TDC_gra_sharp                                  --\n",
      "├─Conv3d: 1-1                                                     26,214,560\n",
      "├─Transformer_ST_TDC_gra_sharp: 1-2                               --\n",
      "│    └─ModuleList: 2-1                                            --\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-1                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-2                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-3                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-4                           1,485,904\n",
      "├─Transformer_ST_TDC_gra_sharp: 1-3                               --\n",
      "│    └─ModuleList: 2-2                                            --\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-5                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-6                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-7                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-8                           1,485,904\n",
      "├─Transformer_ST_TDC_gra_sharp: 1-4                               --\n",
      "│    └─ModuleList: 2-3                                            --\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-9                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-10                          1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-11                          1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-12                          1,485,904\n",
      "├─Sequential: 1-5                                                 --\n",
      "│    └─Conv3d: 2-4                                                3,040\n",
      "│    └─BatchNorm3d: 2-5                                           80\n",
      "│    └─ReLU: 2-6                                                  --\n",
      "│    └─MaxPool3d: 2-7                                             --\n",
      "├─Sequential: 1-6                                                 --\n",
      "│    └─Conv3d: 2-8                                                86,480\n",
      "│    └─BatchNorm3d: 2-9                                           160\n",
      "│    └─ReLU: 2-10                                                 --\n",
      "│    └─MaxPool3d: 2-11                                            --\n",
      "├─Sequential: 1-7                                                 --\n",
      "│    └─Conv3d: 2-12                                               345,760\n",
      "│    └─BatchNorm3d: 2-13                                          320\n",
      "│    └─ReLU: 2-14                                                 --\n",
      "│    └─MaxPool3d: 2-15                                            --\n",
      "├─Sequential: 1-8                                                 --\n",
      "│    └─Upsample: 2-16                                             --\n",
      "│    └─Conv3d: 2-17                                               76,960\n",
      "│    └─BatchNorm3d: 2-18                                          320\n",
      "│    └─ELU: 2-19                                                  --\n",
      "├─Sequential: 1-9                                                 --\n",
      "│    └─Upsample: 2-20                                             --\n",
      "│    └─Conv3d: 2-21                                               38,480\n",
      "│    └─BatchNorm3d: 2-22                                          160\n",
      "│    └─ELU: 2-23                                                  --\n",
      "├─Conv1d: 1-10                                                    81\n",
      "==========================================================================================\n",
      "Total params: 44,597,249\n",
      "Trainable params: 44,597,249\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "BATCH = 4\n",
    "#train_video = train_video.permute(0,4,1,2,3)\n",
    "#val_video = val_video.permute(0,4,1,2,3)\n",
    "#test_video = test_video.permute(0,4,1,2,3)\n",
    "print(train_video.shape,train_bvp.shape)\n",
    "dataset = torch.utils.data.TensorDataset(train_video.permute(0,4,1,2,3),torch.as_tensor(train_bvp))\n",
    "trainloader = torch.utils.data.DataLoader(dataset,batch_size=BATCH, shuffle=True, num_workers=1)\n",
    "\n",
    "model = ViT_ST_ST_Compact3_TDC_gra_sharp(image_size=(160,160,160), patches=(4,16,16), dim=160, ff_dim=144, num_heads=4, num_layers=12, dropout_rate=0.1, theta=0.7)\n",
    "print(summary(model))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_function = nn.L1Loss()\n",
    "criterion_Pearson = Neg_Pearson() \n",
    "\n",
    "loss = 0.0\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f54552d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, trainloader, epoch_start=0, iter_start=0):\n",
    "    criterion_reg = nn.MSELoss()\n",
    "    criterion_L1loss = nn.L1Loss()\n",
    "    criterion_class = nn.CrossEntropyLoss()\n",
    "    criterion_Pearson = Neg_Pearson()\n",
    "        \n",
    "    a_start = 0.1\n",
    "    b_start = 1.0\n",
    "    exp_a = 0.5\n",
    "    exp_b = 5.0\n",
    "    \n",
    "    writer = SummaryWriter()\n",
    "    \n",
    "    path_log = 'LOG'\n",
    "    isExists = os.path.exists(path_log)\n",
    "    if not isExists:\n",
    "        os.makedirs(path_log)\n",
    "    log_file = open(path_log+'/LOG_log.txt', 'w')\n",
    "    \n",
    "    for epoch in range(epoch_start, epochs):\n",
    "        print(\"\\nStarting epoch\", epoch+1)\n",
    "        loss = 0.0\n",
    "        loss_rPPG_avg = AvgrageMeter()\n",
    "        loss_peak_avg = AvgrageMeter()\n",
    "        loss_kl_avg_test = AvgrageMeter()\n",
    "        loss_bvp_mae = AvgrageMeter()\n",
    "        \n",
    "        model.train()\n",
    "        for i, data in enumerate(trainloader,0):\n",
    "            if i >= iter_start: \n",
    "                \n",
    "                iter_start = 0\n",
    "                inputs, targets = data\n",
    "                inputs, targets = inputs.float().cuda(), targets.float().cuda()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                rPPG = model(inputs,0.2) \n",
    "                rPPG = (rPPG-torch.mean(rPPG)) /torch.std(rPPG)\n",
    "                #loss\n",
    "                loss = criterion_reg\n",
    "                loss_rPPG = criterion_Pearson(rPPG, targets)\n",
    "                fre_loss = 0.0\n",
    "                kl_loss = 0.0\n",
    "                train_mae = 0.0\n",
    "                for bb in range(inputs.shape[0]):\n",
    "                    loss_distribution_kl, fre_loss_temp, train_mae_temp = TorchLossComputer.cross_entropy_power_spectrum_DLDL_softmax2(\n",
    "                        rPPG[bb], torch.mean(targets[bb].float()), 30, std=1.0) \n",
    "                    fre_loss = fre_loss + fre_loss_temp\n",
    "                    kl_loss = kl_loss + loss_distribution_kl\n",
    "                    train_mae = train_mae + train_mae_temp\n",
    "                fre_loss = fre_loss/inputs.shape[0]\n",
    "                kl_loss = kl_loss/inputs.shape[0]\n",
    "                train_mae = train_mae/inputs.shape[0]\n",
    "                print(train_mae)\n",
    "                if epoch >25:\n",
    "                    a = 0.05\n",
    "                    b = 5.0\n",
    "                else:\n",
    "                    a = a_start*math.pow(exp_a, epoch/25.0)\n",
    "                    b = b_start*math.pow(exp_b, epoch/25.0)\n",
    "            \n",
    "                a = 0.1\n",
    "            \n",
    "                loss =  a*loss_rPPG + b*(fre_loss+kl_loss)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                n = inputs.size(0)\n",
    "                loss_rPPG_avg.update(loss_rPPG.data, n)\n",
    "                loss_peak_avg.update(fre_loss.data, n)\n",
    "                loss_kl_avg_test.update(kl_loss.data, n)\n",
    "                loss_bvp_mae.update(train_mae, n)\n",
    "                \n",
    "                print(\"\\n\")\n",
    "                sys.stdout.write('\\r')\n",
    "                sys.stdout.write(f\"Iteration {i+1}, loss= {loss/((i+1)*inputs.shape[0]):1.5f}, NegPearson= {loss_rPPG_avg.avg:1.5f}, kl= {loss_kl_avg_test.avg:1.5f}, fre_CEloss= {loss_peak_avg.avg:1.5f}\")\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "                writer.add_scalar('Epoch '+str(epoch)+' Loss/train', loss/((i+1)*inputs.shape[0]), i)\n",
    "\n",
    "                save_ckp(model, optimizer, loss, epoch, i)\n",
    "                \n",
    "                if( i%50 == 0):\n",
    "                    log_file.write(\"\\n\")        \n",
    "                    log_file.write(f\"Epoch {epoch+1}, Iteration {i+1}, loss= {loss/((i+1)*inputs.shape[0]):1.5f}, NegPearson= {loss_rPPG_avg.avg:1.5f}, kl= {loss_kl_avg_test.avg:1.5f}, fre_CEloss= {loss_peak_avg.avg:1.5f}\")\n",
    "                    log_file.write(\"\\n\")\n",
    "                    log_file.write(\"\\n\")\n",
    "                    log_file.flush()\n",
    "                \n",
    "\n",
    "    return model, loss, loss_rPPG_avg, loss_peak_avg, loss_kl_avg_test, loss_bvp_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "693f0bec",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations per epoch:  536\n",
      "epochs: 25\n",
      "Start\n",
      "\n",
      "Starting epoch 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.22 GiB (GPU 0; 31.75 GiB total capacity; 5.84 GiB already allocated; 747.69 MiB free; 5.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3509692/3965833656.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iterations per epoch: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs: {0}\\nStart\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTraining process has finished.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3509692/2210830945.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, trainloader, epoch_start, iter_start)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mrPPG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mrPPG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrPPG\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrPPG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrPPG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;31m#loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/progetto_tesi/VHR/PhysFormer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, gra_sharp)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStem0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStem1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStem2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, 64, 160, 64, 64]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         return F.max_pool3d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[1;32m    241\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                             self.return_indices)\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool3d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.22 GiB (GPU 0; 31.75 GiB total capacity; 5.84 GiB already allocated; 747.69 MiB free; 5.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model = ViT_ST_ST_Compact3_TDC_gra_sharp(image_size=(160,160,160), patches=(4,16,16), dim=160, ff_dim=144, num_heads=4, num_layers=12, dropout_rate=0.1, theta=0.7)\n",
    "model = model.cuda()\n",
    "model.train() \n",
    "print(\"iterations per epoch: \",len(trainloader)) \n",
    "print(\"epochs: {0}\\nStart\".format(epochs)) \n",
    "train(model,optimizer,trainloader, 0,0) \n",
    "print('\\nTraining process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d64476e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "10\n",
      "10\n",
      "10\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "17\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "24\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "18\n",
      "13\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "8\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "15\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "19\n",
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "17\n",
      "19\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "21\n",
      "16\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "17\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "12\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "6\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "14\n",
      "15\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "10\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "11\n",
      "11\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "11\n",
      "11\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "13\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "17\n",
      "17\n",
      "15\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "14\n",
      "19\n",
      "24\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "24\n",
      "20\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "19\n",
      "15\n",
      "15\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "17\n",
      "12\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "8\n",
      "13\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "14\n",
      "19\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "16\n",
      "11\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "8\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "14\n",
      "19\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "19\n",
      "19\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "15\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "13\n",
      "8\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "6\n",
      "11\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "15\n",
      "15\n",
      "17\n",
      "22\n",
      "27\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "24\n",
      "19\n",
      "14\n",
      "19\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "21\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "25\n",
      "25\n",
      "23\n",
      "18\n",
      "13\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "13\n",
      "15\n",
      "15\n",
      "15\n",
      "10\n",
      "9\n",
      "9\n",
      "12\n",
      "15\n",
      "15\n",
      "15\n",
      "14\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "10\n",
      "13\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "15\n",
      "13\n",
      "13\n",
      "17\n",
      "18\n",
      "18\n",
      "18\n",
      "15\n",
      "12\n",
      "16\n",
      "21\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "25\n",
      "29\n",
      "30\n",
      "30\n",
      "27\n",
      "23\n",
      "23\n",
      "23\n",
      "25\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "22\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "17\n",
      "12\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "8\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "29\n",
      "33\n",
      "33\n",
      "33\n",
      "29\n",
      "28\n",
      "28\n",
      "28\n",
      "27\n",
      "23\n",
      "25\n",
      "25\n",
      "25\n",
      "23\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "19\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "14\n",
      "14\n",
      "14\n",
      "13\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "15\n",
      "18\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "18\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "15\n",
      "15\n",
      "15\n",
      "16\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "22\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "28\n",
      "23\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "18\n",
      "15\n",
      "15\n",
      "15\n",
      "16\n",
      "16\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "14\n",
      "9\n",
      "10\n",
      "15\n",
      "16\n",
      "15\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "13\n",
      "14\n",
      "14\n",
      "13\n",
      "13\n",
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "20\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "27\n",
      "23\n",
      "22\n",
      "22\n",
      "22\n",
      "23\n",
      "25\n",
      "25\n",
      "25\n",
      "26\n",
      "31\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "36\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "40\n",
      "44\n",
      "45\n",
      "45\n",
      "45\n",
      "40\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "31\n",
      "29\n",
      "29\n",
      "29\n",
      "28\n",
      "24\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "16\n",
      "13\n",
      "13\n",
      "13\n",
      "16\n",
      "13\n",
      "8\n",
      "7\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "16\n",
      "16\n",
      "15\n",
      "15\n",
      "17\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "25\n",
      "30\n",
      "31\n",
      "29\n",
      "29\n",
      "30\n",
      "35\n",
      "40\n",
      "42\n",
      "42\n",
      "42\n",
      "45\n",
      "47\n",
      "52\n",
      "52\n",
      "52\n",
      "52\n",
      "54\n",
      "59\n",
      "61\n",
      "61\n",
      "61\n",
      "58\n",
      "59\n",
      "61\n",
      "61\n",
      "61\n",
      "59\n",
      "54\n",
      "54\n",
      "54\n",
      "54\n",
      "51\n",
      "46\n",
      "44\n",
      "44\n",
      "44\n",
      "43\n",
      "38\n",
      "33\n",
      "31\n",
      "31\n",
      "31\n",
      "28\n",
      "23\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "14\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "27\n",
      "23\n",
      "21\n",
      "21\n",
      "21\n",
      "18\n",
      "14\n",
      "14\n",
      "14\n",
      "13\n",
      "8\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "1\n",
      "1\n",
      "1\n",
      "6\n",
      "11\n",
      "11\n",
      "11\n",
      "12\n",
      "16\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "24\n",
      "29\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "34\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "41\n",
      "45\n",
      "45\n",
      "45\n",
      "45\n",
      "50\n",
      "53\n",
      "53\n",
      "53\n",
      "53\n",
      "55\n",
      "53\n",
      "48\n",
      "48\n",
      "48\n",
      "49\n",
      "47\n",
      "42\n",
      "42\n",
      "42\n",
      "43\n",
      "45\n",
      "40\n",
      "39\n",
      "39\n",
      "40\n",
      "45\n",
      "42\n",
      "39\n",
      "39\n",
      "40\n",
      "45\n",
      "43\n",
      "39\n",
      "39\n",
      "39\n",
      "39\n",
      "34\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "29\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "24\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "20\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "14\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "19\n",
      "24\n",
      "26\n",
      "26\n",
      "26\n",
      "28\n",
      "33\n",
      "36\n",
      "36\n",
      "36\n",
      "37\n",
      "42\n",
      "47\n",
      "47\n",
      "47\n",
      "47\n",
      "51\n",
      "56\n",
      "56\n",
      "56\n",
      "56\n",
      "60\n",
      "61\n",
      "56\n",
      "56\n",
      "56\n",
      "56\n",
      "53\n",
      "48\n",
      "48\n",
      "48\n",
      "48\n",
      "46\n",
      "41\n",
      "39\n",
      "39\n",
      "39\n",
      "37\n",
      "32\n",
      "29\n",
      "29\n",
      "29\n",
      "28\n",
      "23\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "14\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "21\n",
      "21\n",
      "17\n",
      "16\n",
      "16\n",
      "18\n",
      "18\n",
      "18\n",
      "14\n",
      "12\n",
      "13\n",
      "14\n",
      "14\n",
      "13\n",
      "8\n",
      "8\n",
      "9\n",
      "12\n",
      "12\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "14\n",
      "14\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "16\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "20\n",
      "25\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "27\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "30\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "34\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "33\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "31\n",
      "26\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "26\n",
      "23\n",
      "19\n",
      "19\n",
      "19\n",
      "20\n",
      "24\n",
      "23\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "20\n",
      "20\n",
      "15\n",
      "14\n",
      "14\n",
      "16\n",
      "18\n",
      "18\n",
      "16\n",
      "16\n",
      "16\n",
      "18\n",
      "20\n",
      "20\n",
      "17\n",
      "17\n",
      "17\n",
      "21\n",
      "23\n",
      "23\n",
      "21\n",
      "21\n",
      "21\n",
      "25\n",
      "27\n",
      "26\n",
      "22\n",
      "22\n",
      "22\n",
      "25\n",
      "26\n",
      "26\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "22\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "18\n",
      "16\n",
      "16\n",
      "17\n",
      "18\n",
      "18\n",
      "14\n",
      "12\n",
      "12\n",
      "16\n",
      "16\n",
      "16\n",
      "12\n",
      "10\n",
      "11\n",
      "16\n",
      "16\n",
      "16\n",
      "13\n",
      "12\n",
      "13\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "20\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "22\n",
      "21\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "23\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "23\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "20\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "22\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "25\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "28\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "26\n",
      "31\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "29\n",
      "27\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "25\n",
      "28\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "27\n",
      "26\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "26\n",
      "30\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "31\n",
      "28\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "29\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "23\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "20\n",
      "21\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "23\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "31\n",
      "29\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "26\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "27\n",
      "25\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "23\n",
      "24\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "24\n",
      "28\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "27\n",
      "28\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "28\n",
      "33\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "34\n",
      "34\n",
      "39\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "38\n",
      "36\n",
      "41\n",
      "43\n",
      "43\n",
      "43\n",
      "40\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "#for t in range(0,train_bvp.size(0)): print(t,torch.min(train_bvp[t]),torch.max(train_bvp[t]))\n",
    "train_bvp[1317][19]\n",
    "plt.imshow(train_video[1317][19].numpy())\n",
    "plt.show()\n",
    "for t in train_bvp:\n",
    "    c=0\n",
    "    for f in t:\n",
    "        if f==0:\n",
    "            c+=1\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79b39176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.MNIST('mnist_train', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "model = torchvision.models.resnet50(False)\n",
    "# Have ResNet model take in grayscale rather than RGB\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image('images', grid, 0)\n",
    "writer.add_graph(model, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2134fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD MODEL\n",
    "\n",
    "epochs = 5\n",
    "model = ViT_ST_ST_Compact3_TDC_gra_sharp(image_size=(160,160,160), patches=(4,16,16), dim=160, ff_dim=144, num_heads=4, num_layers=12, dropout_rate=0.1, theta=0.7)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "model, optimizer, epoch, iteration = load_ckp(model,optimizer,'./checkpoint.pt.bk')\n",
    "#train(model,optimizer, trainloader, epoch, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5654bac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2142, 160, 160, 160, 3]) torch.Size([2142, 160])\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "ViT_ST_ST_Compact3_TDC_gra_sharp                                  --\n",
      "├─Conv3d: 1-1                                                     26,214,560\n",
      "├─Transformer_ST_TDC_gra_sharp: 1-2                               --\n",
      "│    └─ModuleList: 2-1                                            --\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-1                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-2                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-3                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-4                           1,485,904\n",
      "├─Transformer_ST_TDC_gra_sharp: 1-3                               --\n",
      "│    └─ModuleList: 2-2                                            --\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-5                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-6                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-7                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-8                           1,485,904\n",
      "├─Transformer_ST_TDC_gra_sharp: 1-4                               --\n",
      "│    └─ModuleList: 2-3                                            --\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-9                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-10                          1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-11                          1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-12                          1,485,904\n",
      "├─Sequential: 1-5                                                 --\n",
      "│    └─Conv3d: 2-4                                                3,040\n",
      "│    └─BatchNorm3d: 2-5                                           80\n",
      "│    └─ReLU: 2-6                                                  --\n",
      "│    └─MaxPool3d: 2-7                                             --\n",
      "├─Sequential: 1-6                                                 --\n",
      "│    └─Conv3d: 2-8                                                86,480\n",
      "│    └─BatchNorm3d: 2-9                                           160\n",
      "│    └─ReLU: 2-10                                                 --\n",
      "│    └─MaxPool3d: 2-11                                            --\n",
      "├─Sequential: 1-7                                                 --\n",
      "│    └─Conv3d: 2-12                                               345,760\n",
      "│    └─BatchNorm3d: 2-13                                          320\n",
      "│    └─ReLU: 2-14                                                 --\n",
      "│    └─MaxPool3d: 2-15                                            --\n",
      "├─Sequential: 1-8                                                 --\n",
      "│    └─Upsample: 2-16                                             --\n",
      "│    └─Conv3d: 2-17                                               76,960\n",
      "│    └─BatchNorm3d: 2-18                                          320\n",
      "│    └─ELU: 2-19                                                  --\n",
      "├─Sequential: 1-9                                                 --\n",
      "│    └─Upsample: 2-20                                             --\n",
      "│    └─Conv3d: 2-21                                               38,480\n",
      "│    └─BatchNorm3d: 2-22                                          160\n",
      "│    └─ELU: 2-23                                                  --\n",
      "├─Conv1d: 1-10                                                    81\n",
      "==========================================================================================\n",
      "Total params: 44,597,249\n",
      "Trainable params: 44,597,249\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train_video = train_video.permute(0,4,1,2,3)\n",
    "#val_video = val_video.permute(0,4,1,2,3)\n",
    "#test_video = test_video.permute(0,4,1,2,3)\n",
    "print(train_video.shape,train_bvp.shape)\n",
    "dataset = torch.utils.data.TensorDataset(test_video.permute(0,4,1,2,3),torch.as_tensor(test_bvp))\n",
    "testloader = torch.utils.data.DataLoader(dataset, shuffle=True, num_workers=1)\n",
    "\n",
    "model = ViT_ST_ST_Compact3_TDC_gra_sharp(image_size=(160,160,160), patches=(4,16,16), dim=160, ff_dim=144, num_heads=4, num_layers=12, dropout_rate=0.1, theta=0.7)\n",
    "print(summary(model))\n",
    "model, optimizer, epoch, iteration = load_ckp(model,optimizer,'./checkpoint.pt.bk')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_function = nn.L1Loss()\n",
    "criterion_Pearson = Neg_Pearson() \n",
    "\n",
    "loss = 0.0\n",
    "epochs = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6186d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fe87ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('epoch_loss.sv', 'rb') as f:\n",
    "    loss = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53bcf59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0025)\n",
      "tensor(23.)\n",
      "tensor(-0.0467)\n",
      "tensor(75.)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1999815/4017356534.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpredicted_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/progetto_tesi/VHR/PhysFormer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, gra_sharp)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mTrans_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScore1\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgra_sharp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, 4*4*40, 64]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mTrans_features2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScore2\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrans_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgra_sharp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, 4*4*40, 64]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mTrans_features3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScore3\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrans_features2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgra_sharp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, 4*4*40, 64]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/progetto_tesi/VHR/transformer_layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, gra_sharp)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgra_sharp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgra_sharp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/progetto_tesi/VHR/transformer_layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, gra_sharp)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgra_sharp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mAtten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgra_sharp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAtten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/progetto_tesi/VHR/transformer_layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, gra_sharp)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# [B, dim, 40, 4, 4]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, 4*4*40, dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, 4*4*40, dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/progetto_tesi/VHR/transformer_layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# only CD works on temporal kernel size>1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 kernel_diff = self.conv.weight[:, :, 0, :, :].sum(2).sum(2) + self.conv.weight[:, :, 2, :, :].sum(\n\u001b[0m\u001b[1;32m     33\u001b[0m                     2).sum(2)\n\u001b[1;32m     34\u001b[0m                 \u001b[0mkernel_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_diff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): \n",
    "    for data in testloader: \n",
    "        inputs, targets = data \n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        predicted_outputs = model(inputs,0.2) \n",
    "        print(predicted_outputs[0][0])\n",
    "        print(targets[0][0])\n",
    "\n",
    "        #_, predicted = torch.max(predicted_outputs, 1) \n",
    "        #total += outputs.size(0) \n",
    "        #running_accuracy += (predicted == outputs).sum().item() \n",
    "\n",
    "    #print('Accuracy of the model based on the test set of', test_split ,'inputs is: %d %%' % (100 * running_accuracy / total))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60046908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1947, 150, 150, 3]) torch.Size([1947])\n"
     ]
    }
   ],
   "source": [
    "#train_bvp = signal.resample(sigGT.data, len(webs))\n",
    "print(webs.shape,torch.as_tensor(train_bvp).shape)\n",
    "dataset = torch.utils.data.TensorDataset(webs,torch.as_tensor(train_bvp))\n",
    "trainloader = torch.utils.data.DataLoader(dataset, shuffle=True, num_workers=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd398866",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Accuracy: 12.54637 tensor([[33.3883, 33.4594, 33.4671, 33.4381, 33.4450, 33.4685, 33.4702, 33.4694,\n",
      "         33.4371, 33.4689, 33.4699, 33.4692, 33.4323, 33.4369, 33.4478, 33.4447,\n",
      "         33.4683, 33.4036, 33.4307, 33.4642, 33.4683, 33.4700, 33.4674, 33.4713,\n",
      "         33.4649, 33.4346, 33.4710, 33.4680, 33.4678, 33.4389, 33.4655, 33.4705,\n",
      "         33.4475, 33.4087, 33.4680, 33.4308, 33.4707, 33.4556, 33.4609, 33.4681,\n",
      "         33.4681, 33.4705, 33.4030, 33.4583, 33.4490, 33.4658, 33.4659, 33.4619,\n",
      "         33.4395, 33.4692, 33.4637, 33.4693, 33.4654, 33.4597, 33.4446, 33.4483,\n",
      "         33.4561, 33.4448, 33.4606, 33.4654, 33.4650, 33.4665, 33.4690, 33.4684,\n",
      "         33.4694, 33.4434, 33.4625, 33.4686, 33.4012, 33.4627, 33.4681, 33.4530,\n",
      "         33.4712, 33.4235, 33.4270, 33.4539, 33.4641, 33.4694, 33.4646, 33.4666,\n",
      "         33.4708, 33.4479, 33.4219, 33.4604, 33.4122, 33.4586, 33.4699, 33.4640,\n",
      "         33.4649, 33.4517, 33.4699, 33.4114, 33.4297, 33.4703, 33.4051, 33.4590,\n",
      "Iteration 2, Accuracy: 11.50019 tensor([[33.3883, 33.4583, 33.4678, 33.4369, 33.4449, 33.4685, 33.4706, 33.4697,\n",
      "         33.4329, 33.4691, 33.4697, 33.4697, 33.4312, 33.4341, 33.4483, 33.4472,\n",
      "         33.4678, 33.4072, 33.4301, 33.4649, 33.4673, 33.4701, 33.4675, 33.4710,\n",
      "         33.4654, 33.4364, 33.4709, 33.4681, 33.4680, 33.4397, 33.4653, 33.4706,\n",
      "         33.4497, 33.4073, 33.4678, 33.4349, 33.4706, 33.4548, 33.4584, 33.4681,\n",
      "         33.4659, 33.4706, 33.4021, 33.4619, 33.4483, 33.4664, 33.4679, 33.4618,\n",
      "         33.4396, 33.4690, 33.4636, 33.4693, 33.4657, 33.4600, 33.4472, 33.4489,\n",
      "         33.4601, 33.4441, 33.4608, 33.4649, 33.4654, 33.4668, 33.4691, 33.4682,\n",
      "         33.4695, 33.4442, 33.4665, 33.4688, 33.4012, 33.4630, 33.4683, 33.4515,\n",
      "         33.4709, 33.4255, 33.4322, 33.4556, 33.4659, 33.4696, 33.4645, 33.4662,\n",
      "         33.4706, 33.4482, 33.4193, 33.4592, 33.4247, 33.4603, 33.4702, 33.4636,\n",
      "         33.4656, 33.4515, 33.4697, 33.4094, 33.4341, 33.4704, 33.4047, 33.4581,\n",
      "Iteration 3, Accuracy: 7.84886 tensor([[33.3883, 33.4602, 33.4668, 33.4379, 33.4448, 33.4685, 33.4705, 33.4695,\n",
      "         33.4388, 33.4688, 33.4700, 33.4697, 33.4324, 33.4373, 33.4478, 33.4433,\n",
      "         33.4681, 33.4033, 33.4301, 33.4640, 33.4683, 33.4700, 33.4675, 33.4713,\n",
      "         33.4649, 33.4375, 33.4710, 33.4681, 33.4678, 33.4384, 33.4656, 33.4703,\n",
      "         33.4491, 33.4087, 33.4679, 33.4291, 33.4707, 33.4554, 33.4608, 33.4681,\n",
      "         33.4678, 33.4705, 33.4027, 33.4596, 33.4489, 33.4658, 33.4658, 33.4621,\n",
      "         33.4396, 33.4692, 33.4637, 33.4694, 33.4653, 33.4597, 33.4444, 33.4491,\n",
      "         33.4553, 33.4500, 33.4600, 33.4651, 33.4652, 33.4668, 33.4690, 33.4682,\n",
      "         33.4695, 33.4490, 33.4645, 33.4687, 33.4011, 33.4624, 33.4682, 33.4529,\n",
      "         33.4711, 33.4237, 33.4255, 33.4521, 33.4648, 33.4691, 33.4645, 33.4668,\n",
      "         33.4709, 33.4476, 33.4228, 33.4607, 33.4175, 33.4585, 33.4701, 33.4641,\n",
      "         33.4650, 33.4517, 33.4699, 33.4127, 33.4293, 33.4703, 33.4052, 33.4589,\n",
      "Iteration 4, Accuracy: 8.77329 tensor([[33.3883, 33.4599, 33.4667, 33.4392, 33.4450, 33.4693, 33.4710, 33.4698,\n",
      "         33.4349, 33.4690, 33.4701, 33.4697, 33.4317, 33.4337, 33.4468, 33.4423,\n",
      "         33.4687, 33.4081, 33.4318, 33.4645, 33.4676, 33.4700, 33.4683, 33.4713,\n",
      "         33.4646, 33.4319, 33.4711, 33.4684, 33.4684, 33.4388, 33.4657, 33.4707,\n",
      "         33.4456, 33.4081, 33.4681, 33.4301, 33.4708, 33.4549, 33.4585, 33.4685,\n",
      "         33.4680, 33.4707, 33.4038, 33.4609, 33.4483, 33.4665, 33.4663, 33.4624,\n",
      "         33.4394, 33.4687, 33.4640, 33.4694, 33.4655, 33.4553, 33.4378, 33.4469,\n",
      "         33.4543, 33.4502, 33.4613, 33.4656, 33.4653, 33.4671, 33.4692, 33.4690,\n",
      "         33.4697, 33.4469, 33.4649, 33.4691, 33.4010, 33.4631, 33.4683, 33.4526,\n",
      "         33.4711, 33.4217, 33.4242, 33.4478, 33.4644, 33.4692, 33.4624, 33.4673,\n",
      "         33.4709, 33.4475, 33.4191, 33.4619, 33.4081, 33.4606, 33.4700, 33.4645,\n",
      "         33.4656, 33.4505, 33.4698, 33.4095, 33.4258, 33.4706, 33.4071, 33.4615,\n",
      "Iteration 5, Accuracy: 10.92751 tensor([[33.3881, 33.4582, 33.4713, 33.4395, 33.4460, 33.4685, 33.4713, 33.4705,\n",
      "         33.4350, 33.4704, 33.4696, 33.4690, 33.4522, 33.4439, 33.4585, 33.4499,\n",
      "         33.4699, 33.4089, 33.4306, 33.4665, 33.4664, 33.4703, 33.4660, 33.4715,\n",
      "         33.4700, 33.4429, 33.4687, 33.4688, 33.4695, 33.4393, 33.4660, 33.4709,\n",
      "         33.4516, 33.4226, 33.4668, 33.4390, 33.4679, 33.4518, 33.4595, 33.4695,\n",
      "         33.4676, 33.4711, 33.4221, 33.4568, 33.4599, 33.4686, 33.4713, 33.4622,\n",
      "         33.4420, 33.4695, 33.4627, 33.4676, 33.4636, 33.4456, 33.4348, 33.4483,\n",
      "         33.4702, 33.4511, 33.4621, 33.4626, 33.4642, 33.4657, 33.4683, 33.4680,\n",
      "         33.4699, 33.4457, 33.4712, 33.4697, 33.4047, 33.4519, 33.4670, 33.4508,\n",
      "         33.4703, 33.4255, 33.4496, 33.4692, 33.4701, 33.4697, 33.4596, 33.4673,\n",
      "         33.4708, 33.4453, 33.4223, 33.4656, 33.4315, 33.4577, 33.4701, 33.4643,\n",
      "         33.4691, 33.4490, 33.4694, 33.4141, 33.4278, 33.4704, 33.4310, 33.4625,\n",
      "Iteration 6, Accuracy: 9.36389 tensor([[33.3882, 33.4580, 33.4671, 33.4380, 33.4449, 33.4686, 33.4704, 33.4697,\n",
      "         33.4359, 33.4690, 33.4698, 33.4693, 33.4275, 33.4358, 33.4483, 33.4449,\n",
      "         33.4683, 33.4091, 33.4315, 33.4645, 33.4674, 33.4700, 33.4675, 33.4713,\n",
      "         33.4658, 33.4419, 33.4710, 33.4681, 33.4680, 33.4384, 33.4654, 33.4706,\n",
      "         33.4509, 33.4071, 33.4676, 33.4372, 33.4706, 33.4553, 33.4608, 33.4684,\n",
      "         33.4678, 33.4706, 33.4009, 33.4610, 33.4486, 33.4661, 33.4680, 33.4614,\n",
      "         33.4414, 33.4696, 33.4638, 33.4694, 33.4660, 33.4606, 33.4492, 33.4476,\n",
      "         33.4595, 33.4474, 33.4604, 33.4652, 33.4653, 33.4664, 33.4691, 33.4684,\n",
      "         33.4695, 33.4444, 33.4660, 33.4688, 33.4022, 33.4623, 33.4685, 33.4529,\n",
      "         33.4711, 33.4232, 33.4313, 33.4557, 33.4652, 33.4695, 33.4636, 33.4661,\n",
      "         33.4706, 33.4449, 33.4216, 33.4601, 33.4241, 33.4605, 33.4699, 33.4637,\n",
      "         33.4653, 33.4498, 33.4698, 33.4104, 33.4358, 33.4705, 33.4045, 33.4581,\n",
      "Iteration 7, Accuracy: 11.67563 tensor([[33.3883, 33.4612, 33.4677, 33.4389, 33.4462, 33.4692, 33.4706, 33.4696,\n",
      "         33.4366, 33.4691, 33.4701, 33.4698, 33.4353, 33.4422, 33.4487, 33.4444,\n",
      "         33.4700, 33.4015, 33.4203, 33.4657, 33.4688, 33.4699, 33.4676, 33.4715,\n",
      "         33.4677, 33.4316, 33.4705, 33.4685, 33.4687, 33.4388, 33.4659, 33.4704,\n",
      "         33.4505, 33.4153, 33.4695, 33.4272, 33.4703, 33.4563, 33.4605, 33.4684,\n",
      "         33.4664, 33.4703, 33.4080, 33.4612, 33.4522, 33.4665, 33.4692, 33.4619,\n",
      "         33.4389, 33.4688, 33.4640, 33.4686, 33.4649, 33.4599, 33.4453, 33.4435,\n",
      "         33.4560, 33.4479, 33.4614, 33.4640, 33.4649, 33.4659, 33.4692, 33.4689,\n",
      "         33.4697, 33.4475, 33.4652, 33.4689, 33.3960, 33.4600, 33.4680, 33.4517,\n",
      "         33.4711, 33.4260, 33.4272, 33.4584, 33.4663, 33.4695, 33.4615, 33.4669,\n",
      "         33.4709, 33.4443, 33.4231, 33.4634, 33.4120, 33.4592, 33.4703, 33.4644,\n",
      "         33.4664, 33.4478, 33.4690, 33.4193, 33.4290, 33.4699, 33.4094, 33.4606,\n",
      "Iteration 8, Accuracy: 10.77315 tensor([[33.3880, 33.4567, 33.4712, 33.4394, 33.4462, 33.4682, 33.4713, 33.4706,\n",
      "         33.4375, 33.4704, 33.4690, 33.4693, 33.4478, 33.4397, 33.4587, 33.4502,\n",
      "         33.4701, 33.4144, 33.4349, 33.4668, 33.4670, 33.4701, 33.4656, 33.4711,\n",
      "         33.4692, 33.4440, 33.4679, 33.4685, 33.4696, 33.4398, 33.4659, 33.4708,\n",
      "         33.4514, 33.4217, 33.4666, 33.4421, 33.4675, 33.4536, 33.4618, 33.4692,\n",
      "         33.4650, 33.4711, 33.4198, 33.4614, 33.4606, 33.4685, 33.4712, 33.4615,\n",
      "         33.4405, 33.4691, 33.4619, 33.4672, 33.4637, 33.4462, 33.4359, 33.4482,\n",
      "         33.4710, 33.4468, 33.4618, 33.4616, 33.4639, 33.4656, 33.4681, 33.4674,\n",
      "         33.4698, 33.4480, 33.4715, 33.4695, 33.4078, 33.4540, 33.4665, 33.4498,\n",
      "         33.4700, 33.4250, 33.4535, 33.4699, 33.4711, 33.4692, 33.4617, 33.4678,\n",
      "         33.4704, 33.4408, 33.4230, 33.4641, 33.4367, 33.4581, 33.4691, 33.4637,\n",
      "         33.4691, 33.4493, 33.4685, 33.4127, 33.4301, 33.4704, 33.4301, 33.4605,\n",
      "Iteration 9, Accuracy: 10.51566 tensor([[33.3881, 33.4578, 33.4712, 33.4414, 33.4498, 33.4675, 33.4714, 33.4701,\n",
      "         33.4343, 33.4696, 33.4700, 33.4708, 33.4574, 33.4581, 33.4618, 33.4483,\n",
      "         33.4690, 33.4111, 33.4284, 33.4674, 33.4665, 33.4694, 33.4652, 33.4710,\n",
      "         33.4697, 33.4461, 33.4690, 33.4701, 33.4690, 33.4391, 33.4638, 33.4702,\n",
      "         33.4525, 33.4366, 33.4661, 33.4379, 33.4689, 33.4510, 33.4602, 33.4693,\n",
      "         33.4686, 33.4705, 33.4239, 33.4591, 33.4632, 33.4648, 33.4713, 33.4636,\n",
      "         33.4440, 33.4633, 33.4656, 33.4683, 33.4667, 33.4343, 33.4290, 33.4460,\n",
      "         33.4698, 33.4415, 33.4632, 33.4500, 33.4667, 33.4649, 33.4688, 33.4661,\n",
      "         33.4700, 33.4492, 33.4711, 33.4700, 33.4004, 33.4446, 33.4695, 33.4530,\n",
      "         33.4698, 33.4319, 33.4487, 33.4696, 33.4712, 33.4694, 33.4610, 33.4688,\n",
      "         33.4710, 33.4454, 33.4205, 33.4686, 33.4327, 33.4640, 33.4704, 33.4659,\n",
      "         33.4664, 33.4502, 33.4695, 33.4181, 33.4191, 33.4677, 33.4388, 33.4626,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, Accuracy: 10.00970 tensor([[33.3880, 33.4579, 33.4712, 33.4433, 33.4493, 33.4668, 33.4711, 33.4700,\n",
      "         33.4380, 33.4699, 33.4699, 33.4709, 33.4562, 33.4529, 33.4627, 33.4500,\n",
      "         33.4693, 33.4144, 33.4277, 33.4664, 33.4658, 33.4694, 33.4635, 33.4710,\n",
      "         33.4688, 33.4449, 33.4672, 33.4692, 33.4690, 33.4421, 33.4637, 33.4702,\n",
      "         33.4532, 33.4336, 33.4661, 33.4445, 33.4680, 33.4531, 33.4589, 33.4690,\n",
      "         33.4656, 33.4706, 33.4259, 33.4615, 33.4615, 33.4657, 33.4710, 33.4622,\n",
      "         33.4458, 33.4659, 33.4637, 33.4667, 33.4648, 33.4369, 33.4268, 33.4468,\n",
      "         33.4712, 33.4418, 33.4616, 33.4595, 33.4659, 33.4637, 33.4683, 33.4646,\n",
      "         33.4700, 33.4471, 33.4716, 33.4692, 33.4014, 33.4415, 33.4687, 33.4523,\n",
      "         33.4687, 33.4293, 33.4551, 33.4703, 33.4709, 33.4697, 33.4592, 33.4674,\n",
      "         33.4708, 33.4496, 33.4225, 33.4689, 33.4429, 33.4621, 33.4691, 33.4646,\n",
      "         33.4675, 33.4510, 33.4693, 33.4184, 33.4271, 33.4679, 33.4394, 33.4623,\n",
      "Iteration 11, Accuracy: 10.60366 tensor([[33.3880, 33.4602, 33.4708, 33.4467, 33.4521, 33.4656, 33.4700, 33.4694,\n",
      "         33.4513, 33.4604, 33.4686, 33.4706, 33.4645, 33.4643, 33.4713, 33.4523,\n",
      "         33.4689, 33.4234, 33.4272, 33.4682, 33.4636, 33.4675, 33.4625, 33.4688,\n",
      "         33.4674, 33.4504, 33.4667, 33.4699, 33.4691, 33.4581, 33.4629, 33.4689,\n",
      "         33.4543, 33.4495, 33.4638, 33.4474, 33.4672, 33.4426, 33.4615, 33.4687,\n",
      "         33.4672, 33.4691, 33.4241, 33.4583, 33.4692, 33.4635, 33.4708, 33.4660,\n",
      "         33.4605, 33.4541, 33.4675, 33.4673, 33.4683, 33.4245, 33.4263, 33.4509,\n",
      "         33.4715, 33.4420, 33.4656, 33.4467, 33.4687, 33.4648, 33.4687, 33.4625,\n",
      "         33.4710, 33.4477, 33.4715, 33.4701, 33.4047, 33.4159, 33.4702, 33.4533,\n",
      "         33.4674, 33.4349, 33.4640, 33.4709, 33.4710, 33.4700, 33.4572, 33.4701,\n",
      "         33.4692, 33.4454, 33.4198, 33.4715, 33.4516, 33.4687, 33.4690, 33.4675,\n",
      "         33.4673, 33.4545, 33.4665, 33.4088, 33.4204, 33.4637, 33.4495, 33.4664,\n",
      "Iteration 12, Accuracy: 10.34115 tensor([[33.3883, 33.4586, 33.4670, 33.4379, 33.4449, 33.4691, 33.4711, 33.4700,\n",
      "         33.4330, 33.4689, 33.4701, 33.4698, 33.4318, 33.4349, 33.4472, 33.4429,\n",
      "         33.4682, 33.4066, 33.4305, 33.4649, 33.4676, 33.4700, 33.4680, 33.4712,\n",
      "         33.4661, 33.4381, 33.4709, 33.4685, 33.4684, 33.4391, 33.4656, 33.4707,\n",
      "         33.4463, 33.4082, 33.4670, 33.4311, 33.4706, 33.4547, 33.4601, 33.4683,\n",
      "         33.4664, 33.4706, 33.4033, 33.4611, 33.4482, 33.4664, 33.4674, 33.4623,\n",
      "         33.4388, 33.4696, 33.4642, 33.4694, 33.4656, 33.4559, 33.4457, 33.4476,\n",
      "         33.4552, 33.4445, 33.4607, 33.4647, 33.4651, 33.4668, 33.4691, 33.4688,\n",
      "         33.4696, 33.4414, 33.4647, 33.4689, 33.4002, 33.4621, 33.4684, 33.4526,\n",
      "         33.4712, 33.4250, 33.4256, 33.4559, 33.4651, 33.4694, 33.4638, 33.4674,\n",
      "         33.4709, 33.4387, 33.4197, 33.4589, 33.4172, 33.4605, 33.4697, 33.4643,\n",
      "         33.4659, 33.4512, 33.4699, 33.4108, 33.4300, 33.4705, 33.4062, 33.4615,\n",
      "Iteration 13, Accuracy: 10.42689 tensor([[33.3881, 33.4531, 33.4712, 33.4430, 33.4497, 33.4675, 33.4713, 33.4701,\n",
      "         33.4321, 33.4702, 33.4701, 33.4706, 33.4559, 33.4567, 33.4627, 33.4439,\n",
      "         33.4697, 33.4077, 33.4236, 33.4671, 33.4673, 33.4700, 33.4647, 33.4712,\n",
      "         33.4692, 33.4449, 33.4684, 33.4698, 33.4691, 33.4397, 33.4658, 33.4705,\n",
      "         33.4498, 33.4362, 33.4665, 33.4421, 33.4687, 33.4498, 33.4605, 33.4692,\n",
      "         33.4676, 33.4708, 33.4286, 33.4601, 33.4607, 33.4649, 33.4714, 33.4638,\n",
      "         33.4467, 33.4628, 33.4651, 33.4680, 33.4669, 33.4364, 33.4257, 33.4475,\n",
      "         33.4700, 33.4504, 33.4633, 33.4538, 33.4664, 33.4646, 33.4686, 33.4660,\n",
      "         33.4700, 33.4449, 33.4711, 33.4700, 33.3994, 33.4448, 33.4692, 33.4527,\n",
      "         33.4693, 33.4304, 33.4503, 33.4694, 33.4711, 33.4690, 33.4567, 33.4694,\n",
      "         33.4710, 33.4493, 33.4216, 33.4701, 33.4350, 33.4626, 33.4696, 33.4657,\n",
      "         33.4667, 33.4474, 33.4696, 33.4185, 33.4217, 33.4680, 33.4400, 33.4614,\n",
      "Iteration 14, Accuracy: 12.14971 tensor([[33.3883, 33.4581, 33.4634, 33.4340, 33.4465, 33.4694, 33.4699, 33.4697,\n",
      "         33.4373, 33.4686, 33.4700, 33.4694, 33.4228, 33.4344, 33.4459, 33.4446,\n",
      "         33.4675, 33.4037, 33.4309, 33.4641, 33.4682, 33.4700, 33.4684, 33.4710,\n",
      "         33.4625, 33.4367, 33.4711, 33.4682, 33.4677, 33.4385, 33.4657, 33.4706,\n",
      "         33.4458, 33.4102, 33.4672, 33.4349, 33.4710, 33.4590, 33.4586, 33.4679,\n",
      "         33.4664, 33.4690, 33.4026, 33.4618, 33.4450, 33.4663, 33.4636, 33.4624,\n",
      "         33.4393, 33.4686, 33.4645, 33.4697, 33.4673, 33.4622, 33.4528, 33.4460,\n",
      "         33.4544, 33.4532, 33.4609, 33.4639, 33.4654, 33.4674, 33.4694, 33.4692,\n",
      "         33.4696, 33.4406, 33.4614, 33.4683, 33.3991, 33.4638, 33.4685, 33.4518,\n",
      "         33.4695, 33.4262, 33.4293, 33.4491, 33.4624, 33.4693, 33.4648, 33.4669,\n",
      "         33.4708, 33.4469, 33.4201, 33.4591, 33.4201, 33.4571, 33.4694, 33.4638,\n",
      "         33.4646, 33.4504, 33.4699, 33.4137, 33.4397, 33.4704, 33.4021, 33.4558,\n",
      "Iteration 15, Accuracy: 11.70948 tensor([[33.3883, 33.4597, 33.4660, 33.4366, 33.4445, 33.4694, 33.4705, 33.4698,\n",
      "         33.4358, 33.4688, 33.4700, 33.4695, 33.4245, 33.4317, 33.4481, 33.4439,\n",
      "         33.4680, 33.4073, 33.4307, 33.4637, 33.4683, 33.4701, 33.4686, 33.4709,\n",
      "         33.4627, 33.4358, 33.4711, 33.4684, 33.4678, 33.4384, 33.4668, 33.4706,\n",
      "         33.4475, 33.4077, 33.4672, 33.4373, 33.4709, 33.4590, 33.4610, 33.4681,\n",
      "         33.4663, 33.4701, 33.4016, 33.4591, 33.4420, 33.4663, 33.4653, 33.4629,\n",
      "         33.4408, 33.4692, 33.4648, 33.4697, 33.4677, 33.4641, 33.4548, 33.4489,\n",
      "         33.4542, 33.4474, 33.4611, 33.4665, 33.4656, 33.4674, 33.4696, 33.4692,\n",
      "         33.4698, 33.4439, 33.4633, 33.4687, 33.3994, 33.4633, 33.4685, 33.4527,\n",
      "         33.4701, 33.4205, 33.4301, 33.4499, 33.4621, 33.4693, 33.4650, 33.4670,\n",
      "         33.4709, 33.4387, 33.4229, 33.4568, 33.4152, 33.4601, 33.4692, 33.4643,\n",
      "         33.4647, 33.4523, 33.4700, 33.4119, 33.4418, 33.4707, 33.4027, 33.4581,\n",
      "Iteration 16, Accuracy: 11.25600 tensor([[33.3883, 33.4589, 33.4667, 33.4361, 33.4471, 33.4685, 33.4705, 33.4696,\n",
      "         33.4389, 33.4690, 33.4699, 33.4695, 33.4330, 33.4365, 33.4534, 33.4423,\n",
      "         33.4683, 33.4050, 33.4298, 33.4642, 33.4673, 33.4700, 33.4675, 33.4714,\n",
      "         33.4665, 33.4359, 33.4709, 33.4680, 33.4679, 33.4385, 33.4655, 33.4707,\n",
      "         33.4460, 33.4085, 33.4669, 33.4320, 33.4703, 33.4588, 33.4610, 33.4680,\n",
      "         33.4661, 33.4702, 33.4035, 33.4606, 33.4461, 33.4658, 33.4674, 33.4617,\n",
      "         33.4406, 33.4695, 33.4636, 33.4693, 33.4658, 33.4591, 33.4417, 33.4483,\n",
      "         33.4543, 33.4470, 33.4607, 33.4643, 33.4651, 33.4665, 33.4689, 33.4682,\n",
      "         33.4694, 33.4422, 33.4640, 33.4686, 33.4004, 33.4604, 33.4683, 33.4519,\n",
      "         33.4708, 33.4254, 33.4246, 33.4515, 33.4655, 33.4694, 33.4641, 33.4662,\n",
      "         33.4709, 33.4484, 33.4194, 33.4588, 33.4169, 33.4598, 33.4702, 33.4642,\n",
      "         33.4649, 33.4511, 33.4699, 33.4115, 33.4300, 33.4702, 33.4073, 33.4601,\n",
      "Iteration 17, Accuracy: 11.14999 tensor([[33.3883, 33.4616, 33.4683, 33.4379, 33.4450, 33.4678, 33.4710, 33.4695,\n",
      "         33.4351, 33.4693, 33.4702, 33.4696, 33.4277, 33.4367, 33.4484, 33.4462,\n",
      "         33.4680, 33.4046, 33.4308, 33.4643, 33.4673, 33.4699, 33.4673, 33.4714,\n",
      "         33.4653, 33.4383, 33.4709, 33.4681, 33.4675, 33.4391, 33.4654, 33.4704,\n",
      "         33.4472, 33.4075, 33.4668, 33.4354, 33.4706, 33.4586, 33.4604, 33.4679,\n",
      "         33.4663, 33.4706, 33.4003, 33.4609, 33.4469, 33.4652, 33.4676, 33.4619,\n",
      "         33.4396, 33.4671, 33.4645, 33.4693, 33.4657, 33.4603, 33.4448, 33.4486,\n",
      "         33.4590, 33.4439, 33.4598, 33.4632, 33.4654, 33.4664, 33.4687, 33.4678,\n",
      "         33.4694, 33.4487, 33.4640, 33.4689, 33.4009, 33.4625, 33.4682, 33.4531,\n",
      "         33.4706, 33.4234, 33.4335, 33.4553, 33.4659, 33.4693, 33.4645, 33.4662,\n",
      "         33.4705, 33.4495, 33.4194, 33.4602, 33.4195, 33.4607, 33.4706, 33.4647,\n",
      "         33.4641, 33.4513, 33.4688, 33.4108, 33.4389, 33.4701, 33.4010, 33.4578,\n",
      "Iteration 18, Accuracy: 11.44963 tensor([[33.3879, 33.4565, 33.4713, 33.4437, 33.4481, 33.4667, 33.4713, 33.4701,\n",
      "         33.4362, 33.4700, 33.4698, 33.4707, 33.4575, 33.4525, 33.4625, 33.4492,\n",
      "         33.4678, 33.4148, 33.4336, 33.4653, 33.4677, 33.4696, 33.4637, 33.4711,\n",
      "         33.4674, 33.4499, 33.4676, 33.4695, 33.4691, 33.4416, 33.4658, 33.4701,\n",
      "         33.4526, 33.4334, 33.4651, 33.4465, 33.4684, 33.4525, 33.4624, 33.4691,\n",
      "         33.4669, 33.4708, 33.4245, 33.4602, 33.4642, 33.4657, 33.4712, 33.4618,\n",
      "         33.4440, 33.4651, 33.4642, 33.4668, 33.4662, 33.4412, 33.4289, 33.4453,\n",
      "         33.4714, 33.4478, 33.4608, 33.4581, 33.4658, 33.4639, 33.4683, 33.4645,\n",
      "         33.4700, 33.4470, 33.4716, 33.4691, 33.4066, 33.4466, 33.4687, 33.4527,\n",
      "         33.4689, 33.4295, 33.4574, 33.4708, 33.4708, 33.4695, 33.4610, 33.4677,\n",
      "         33.4708, 33.4468, 33.4230, 33.4684, 33.4449, 33.4625, 33.4691, 33.4648,\n",
      "         33.4674, 33.4485, 33.4693, 33.4183, 33.4278, 33.4681, 33.4394, 33.4618,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, Accuracy: 11.08145 tensor([[33.3883, 33.4600, 33.4668, 33.4368, 33.4472, 33.4688, 33.4706, 33.4698,\n",
      "         33.4361, 33.4688, 33.4698, 33.4693, 33.4288, 33.4394, 33.4488, 33.4424,\n",
      "         33.4704, 33.4016, 33.4211, 33.4651, 33.4682, 33.4699, 33.4673, 33.4714,\n",
      "         33.4655, 33.4373, 33.4708, 33.4681, 33.4684, 33.4391, 33.4654, 33.4706,\n",
      "         33.4490, 33.4119, 33.4674, 33.4295, 33.4704, 33.4548, 33.4609, 33.4684,\n",
      "         33.4678, 33.4698, 33.4045, 33.4609, 33.4508, 33.4660, 33.4688, 33.4620,\n",
      "         33.4392, 33.4698, 33.4640, 33.4685, 33.4651, 33.4614, 33.4528, 33.4468,\n",
      "         33.4563, 33.4532, 33.4615, 33.4662, 33.4649, 33.4657, 33.4691, 33.4688,\n",
      "         33.4695, 33.4463, 33.4647, 33.4688, 33.3958, 33.4599, 33.4682, 33.4507,\n",
      "         33.4712, 33.4259, 33.4269, 33.4589, 33.4661, 33.4694, 33.4612, 33.4668,\n",
      "         33.4708, 33.4482, 33.4244, 33.4611, 33.4185, 33.4594, 33.4702, 33.4637,\n",
      "         33.4658, 33.4497, 33.4700, 33.4172, 33.4383, 33.4703, 33.4057, 33.4612,\n",
      "Iteration 20, Accuracy: 10.70015 tensor([[33.3881, 33.4570, 33.4710, 33.4401, 33.4467, 33.4686, 33.4713, 33.4703,\n",
      "         33.4333, 33.4700, 33.4700, 33.4703, 33.4498, 33.4471, 33.4594, 33.4471,\n",
      "         33.4704, 33.4115, 33.4288, 33.4674, 33.4681, 33.4697, 33.4658, 33.4715,\n",
      "         33.4695, 33.4412, 33.4693, 33.4686, 33.4693, 33.4401, 33.4658, 33.4706,\n",
      "         33.4500, 33.4260, 33.4680, 33.4351, 33.4686, 33.4546, 33.4588, 33.4692,\n",
      "         33.4673, 33.4708, 33.4252, 33.4615, 33.4601, 33.4673, 33.4712, 33.4616,\n",
      "         33.4427, 33.4682, 33.4630, 33.4672, 33.4653, 33.4470, 33.4371, 33.4459,\n",
      "         33.4691, 33.4516, 33.4617, 33.4612, 33.4646, 33.4649, 33.4684, 33.4677,\n",
      "         33.4697, 33.4469, 33.4707, 33.4698, 33.4003, 33.4542, 33.4677, 33.4514,\n",
      "         33.4701, 33.4267, 33.4458, 33.4690, 33.4711, 33.4695, 33.4591, 33.4676,\n",
      "         33.4708, 33.4490, 33.4250, 33.4665, 33.4262, 33.4608, 33.4698, 33.4643,\n",
      "         33.4684, 33.4464, 33.4697, 33.4156, 33.4230, 33.4697, 33.4307, 33.4621,\n",
      "Iteration 21, Accuracy: 11.16904 tensor([[33.3884, 33.4588, 33.4633, 33.4363, 33.4457, 33.4696, 33.4686, 33.4697,\n",
      "         33.4379, 33.4686, 33.4699, 33.4689, 33.4235, 33.4302, 33.4479, 33.4428,\n",
      "         33.4660, 33.4042, 33.4324, 33.4644, 33.4683, 33.4700, 33.4689, 33.4704,\n",
      "         33.4617, 33.4396, 33.4711, 33.4683, 33.4680, 33.4388, 33.4657, 33.4705,\n",
      "         33.4435, 33.4065, 33.4672, 33.4343, 33.4711, 33.4576, 33.4578, 33.4682,\n",
      "         33.4666, 33.4689, 33.3990, 33.4590, 33.4426, 33.4670, 33.4652, 33.4627,\n",
      "         33.4404, 33.4695, 33.4644, 33.4701, 33.4657, 33.4642, 33.4586, 33.4488,\n",
      "         33.4495, 33.4482, 33.4617, 33.4659, 33.4655, 33.4680, 33.4697, 33.4697,\n",
      "         33.4698, 33.4471, 33.4582, 33.4685, 33.4019, 33.4638, 33.4681, 33.4513,\n",
      "         33.4683, 33.4211, 33.4255, 33.4490, 33.4595, 33.4691, 33.4644, 33.4669,\n",
      "         33.4710, 33.4378, 33.4217, 33.4558, 33.4156, 33.4553, 33.4687, 33.4647,\n",
      "         33.4658, 33.4494, 33.4698, 33.4092, 33.4405, 33.4710, 33.4001, 33.4545,\n",
      "Iteration 22, Accuracy: 10.90925 tensor([[33.3883, 33.4586, 33.4672, 33.4380, 33.4449, 33.4691, 33.4709, 33.4699,\n",
      "         33.4374, 33.4689, 33.4701, 33.4697, 33.4321, 33.4360, 33.4478, 33.4429,\n",
      "         33.4680, 33.4063, 33.4267, 33.4651, 33.4676, 33.4700, 33.4680, 33.4713,\n",
      "         33.4663, 33.4339, 33.4710, 33.4684, 33.4684, 33.4378, 33.4657, 33.4707,\n",
      "         33.4482, 33.4113, 33.4670, 33.4259, 33.4706, 33.4547, 33.4611, 33.4684,\n",
      "         33.4665, 33.4702, 33.4079, 33.4610, 33.4483, 33.4663, 33.4681, 33.4623,\n",
      "         33.4399, 33.4697, 33.4643, 33.4693, 33.4656, 33.4565, 33.4459, 33.4476,\n",
      "         33.4557, 33.4444, 33.4606, 33.4652, 33.4653, 33.4668, 33.4692, 33.4688,\n",
      "         33.4697, 33.4478, 33.4627, 33.4690, 33.3999, 33.4632, 33.4682, 33.4526,\n",
      "         33.4712, 33.4250, 33.4267, 33.4513, 33.4652, 33.4693, 33.4638, 33.4674,\n",
      "         33.4710, 33.4379, 33.4201, 33.4623, 33.4114, 33.4600, 33.4697, 33.4644,\n",
      "         33.4660, 33.4513, 33.4698, 33.4133, 33.4304, 33.4705, 33.4093, 33.4606,\n",
      "Iteration 23, Accuracy: 10.54556 tensor([[33.3881, 33.4531, 33.4712, 33.4386, 33.4479, 33.4683, 33.4712, 33.4705,\n",
      "         33.4351, 33.4704, 33.4700, 33.4706, 33.4559, 33.4487, 33.4596, 33.4494,\n",
      "         33.4700, 33.4085, 33.4290, 33.4674, 33.4675, 33.4701, 33.4662, 33.4715,\n",
      "         33.4693, 33.4429, 33.4692, 33.4694, 33.4695, 33.4397, 33.4661, 33.4707,\n",
      "         33.4525, 33.4289, 33.4666, 33.4397, 33.4685, 33.4533, 33.4589, 33.4695,\n",
      "         33.4677, 33.4710, 33.4246, 33.4625, 33.4592, 33.4679, 33.4714, 33.4624,\n",
      "         33.4407, 33.4669, 33.4638, 33.4679, 33.4644, 33.4392, 33.4294, 33.4474,\n",
      "         33.4703, 33.4508, 33.4625, 33.4606, 33.4650, 33.4654, 33.4686, 33.4671,\n",
      "         33.4700, 33.4453, 33.4710, 33.4692, 33.4034, 33.4505, 33.4681, 33.4503,\n",
      "         33.4702, 33.4292, 33.4490, 33.4696, 33.4701, 33.4696, 33.4613, 33.4682,\n",
      "         33.4709, 33.4489, 33.4204, 33.4658, 33.4350, 33.4587, 33.4702, 33.4653,\n",
      "         33.4686, 33.4479, 33.4697, 33.4143, 33.4273, 33.4700, 33.4348, 33.4618,\n",
      "Iteration 24, Accuracy: 10.29181 tensor([[33.3881, 33.4585, 33.4713, 33.4394, 33.4463, 33.4678, 33.4712, 33.4706,\n",
      "         33.4384, 33.4704, 33.4693, 33.4701, 33.4507, 33.4426, 33.4587, 33.4508,\n",
      "         33.4700, 33.4148, 33.4300, 33.4661, 33.4671, 33.4701, 33.4654, 33.4715,\n",
      "         33.4696, 33.4467, 33.4682, 33.4689, 33.4697, 33.4396, 33.4658, 33.4709,\n",
      "         33.4542, 33.4215, 33.4664, 33.4407, 33.4676, 33.4507, 33.4600, 33.4693,\n",
      "         33.4672, 33.4712, 33.4209, 33.4597, 33.4601, 33.4683, 33.4712, 33.4613,\n",
      "         33.4418, 33.4689, 33.4619, 33.4678, 33.4642, 33.4385, 33.4283, 33.4481,\n",
      "         33.4709, 33.4517, 33.4617, 33.4630, 33.4635, 33.4655, 33.4681, 33.4670,\n",
      "         33.4699, 33.4473, 33.4714, 33.4690, 33.4040, 33.4542, 33.4669, 33.4499,\n",
      "         33.4698, 33.4251, 33.4530, 33.4696, 33.4711, 33.4699, 33.4614, 33.4674,\n",
      "         33.4704, 33.4460, 33.4208, 33.4642, 33.4367, 33.4574, 33.4690, 33.4640,\n",
      "         33.4690, 33.4484, 33.4690, 33.4125, 33.4303, 33.4702, 33.4299, 33.4615,\n",
      "Iteration 25, Accuracy: 9.97828 tensor([[33.3883, 33.4576, 33.4674, 33.4380, 33.4459, 33.4691, 33.4706, 33.4699,\n",
      "         33.4376, 33.4690, 33.4701, 33.4697, 33.4324, 33.4363, 33.4475, 33.4415,\n",
      "         33.4681, 33.4073, 33.4283, 33.4650, 33.4676, 33.4699, 33.4681, 33.4713,\n",
      "         33.4648, 33.4351, 33.4709, 33.4684, 33.4683, 33.4378, 33.4657, 33.4707,\n",
      "         33.4483, 33.4133, 33.4681, 33.4260, 33.4707, 33.4546, 33.4595, 33.4685,\n",
      "         33.4665, 33.4701, 33.4067, 33.4609, 33.4507, 33.4663, 33.4671, 33.4623,\n",
      "         33.4406, 33.4698, 33.4644, 33.4695, 33.4654, 33.4576, 33.4426, 33.4477,\n",
      "         33.4557, 33.4445, 33.4606, 33.4652, 33.4652, 33.4670, 33.4692, 33.4688,\n",
      "         33.4696, 33.4478, 33.4626, 33.4689, 33.4010, 33.4634, 33.4685, 33.4526,\n",
      "         33.4712, 33.4244, 33.4198, 33.4526, 33.4652, 33.4692, 33.4643, 33.4673,\n",
      "         33.4710, 33.4380, 33.4189, 33.4617, 33.4102, 33.4598, 33.4701, 33.4645,\n",
      "         33.4659, 33.4463, 33.4699, 33.4129, 33.4277, 33.4702, 33.4085, 33.4595,\n",
      "Iteration 26, Accuracy: 9.61544 tensor([[33.3881, 33.4560, 33.4712, 33.4409, 33.4492, 33.4679, 33.4714, 33.4702,\n",
      "         33.4343, 33.4701, 33.4701, 33.4707, 33.4566, 33.4571, 33.4619, 33.4488,\n",
      "         33.4689, 33.4105, 33.4256, 33.4672, 33.4667, 33.4696, 33.4648, 33.4714,\n",
      "         33.4696, 33.4464, 33.4687, 33.4698, 33.4692, 33.4399, 33.4637, 33.4704,\n",
      "         33.4516, 33.4330, 33.4663, 33.4390, 33.4687, 33.4510, 33.4604, 33.4691,\n",
      "         33.4682, 33.4705, 33.4233, 33.4601, 33.4625, 33.4656, 33.4714, 33.4632,\n",
      "         33.4462, 33.4632, 33.4651, 33.4677, 33.4667, 33.4335, 33.4281, 33.4468,\n",
      "         33.4702, 33.4418, 33.4629, 33.4543, 33.4663, 33.4647, 33.4686, 33.4659,\n",
      "         33.4700, 33.4499, 33.4711, 33.4699, 33.3980, 33.4434, 33.4691, 33.4522,\n",
      "         33.4697, 33.4304, 33.4517, 33.4697, 33.4713, 33.4695, 33.4584, 33.4687,\n",
      "         33.4710, 33.4458, 33.4198, 33.4690, 33.4315, 33.4630, 33.4702, 33.4656,\n",
      "         33.4673, 33.4510, 33.4695, 33.4170, 33.4239, 33.4684, 33.4370, 33.4621,\n",
      "Iteration 27, Accuracy: 9.61288 tensor([[33.3883, 33.4602, 33.4662, 33.4363, 33.4460, 33.4688, 33.4705, 33.4695,\n",
      "         33.4372, 33.4689, 33.4698, 33.4697, 33.4281, 33.4339, 33.4479, 33.4409,\n",
      "         33.4682, 33.4056, 33.4286, 33.4640, 33.4684, 33.4701, 33.4678, 33.4714,\n",
      "         33.4656, 33.4354, 33.4710, 33.4681, 33.4682, 33.4386, 33.4665, 33.4704,\n",
      "         33.4463, 33.4112, 33.4670, 33.4321, 33.4707, 33.4591, 33.4609, 33.4684,\n",
      "         33.4677, 33.4700, 33.4030, 33.4595, 33.4483, 33.4660, 33.4672, 33.4621,\n",
      "         33.4420, 33.4692, 33.4640, 33.4690, 33.4651, 33.4597, 33.4466, 33.4458,\n",
      "         33.4551, 33.4446, 33.4608, 33.4654, 33.4652, 33.4666, 33.4690, 33.4684,\n",
      "         33.4696, 33.4468, 33.4641, 33.4690, 33.3995, 33.4617, 33.4683, 33.4528,\n",
      "         33.4711, 33.4250, 33.4256, 33.4548, 33.4657, 33.4693, 33.4637, 33.4666,\n",
      "         33.4708, 33.4475, 33.4191, 33.4618, 33.4173, 33.4585, 33.4698, 33.4642,\n",
      "         33.4652, 33.4480, 33.4700, 33.4105, 33.4294, 33.4703, 33.4058, 33.4600,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28, Accuracy: 9.57150 tensor([[33.3883, 33.4585, 33.4694, 33.4388, 33.4482, 33.4685, 33.4711, 33.4697,\n",
      "         33.4345, 33.4695, 33.4700, 33.4702, 33.4387, 33.4435, 33.4528, 33.4452,\n",
      "         33.4684, 33.4049, 33.4216, 33.4652, 33.4677, 33.4693, 33.4665, 33.4715,\n",
      "         33.4692, 33.4386, 33.4700, 33.4683, 33.4689, 33.4396, 33.4658, 33.4701,\n",
      "         33.4511, 33.4181, 33.4688, 33.4292, 33.4698, 33.4545, 33.4595, 33.4691,\n",
      "         33.4676, 33.4704, 33.4109, 33.4614, 33.4542, 33.4660, 33.4706, 33.4608,\n",
      "         33.4393, 33.4688, 33.4635, 33.4673, 33.4654, 33.4559, 33.4444, 33.4462,\n",
      "         33.4623, 33.4480, 33.4612, 33.4644, 33.4646, 33.4647, 33.4685, 33.4677,\n",
      "         33.4696, 33.4419, 33.4677, 33.4687, 33.3965, 33.4572, 33.4683, 33.4505,\n",
      "         33.4708, 33.4274, 33.4316, 33.4623, 33.4700, 33.4695, 33.4574, 33.4657,\n",
      "         33.4707, 33.4452, 33.4222, 33.4652, 33.4168, 33.4614, 33.4701, 33.4643,\n",
      "         33.4664, 33.4483, 33.4697, 33.4175, 33.4264, 33.4696, 33.4135, 33.4613,\n",
      "Iteration 29, Accuracy: 9.32605 tensor([[33.3883, 33.4595, 33.4645, 33.4360, 33.4465, 33.4694, 33.4703, 33.4699,\n",
      "         33.4370, 33.4689, 33.4702, 33.4690, 33.4269, 33.4371, 33.4482, 33.4409,\n",
      "         33.4679, 33.4030, 33.4316, 33.4650, 33.4684, 33.4699, 33.4687, 33.4713,\n",
      "         33.4647, 33.4309, 33.4711, 33.4684, 33.4682, 33.4384, 33.4658, 33.4708,\n",
      "         33.4478, 33.4093, 33.4671, 33.4315, 33.4708, 33.4564, 33.4594, 33.4682,\n",
      "         33.4685, 33.4701, 33.4023, 33.4603, 33.4423, 33.4661, 33.4665, 33.4623,\n",
      "         33.4400, 33.4699, 33.4644, 33.4697, 33.4650, 33.4608, 33.4510, 33.4487,\n",
      "         33.4523, 33.4481, 33.4613, 33.4646, 33.4655, 33.4676, 33.4694, 33.4692,\n",
      "         33.4697, 33.4428, 33.4603, 33.4693, 33.4016, 33.4620, 33.4684, 33.4526,\n",
      "         33.4703, 33.4261, 33.4233, 33.4525, 33.4635, 33.4693, 33.4650, 33.4668,\n",
      "         33.4710, 33.4471, 33.4214, 33.4598, 33.4136, 33.4581, 33.4698, 33.4649,\n",
      "         33.4654, 33.4521, 33.4692, 33.4122, 33.4310, 33.4706, 33.4038, 33.4582,\n",
      "Iteration 30, Accuracy: 9.63327 tensor([[33.3879, 33.4575, 33.4697, 33.4483, 33.4523, 33.4655, 33.4691, 33.4690,\n",
      "         33.4613, 33.4548, 33.4637, 33.4701, 33.4686, 33.4691, 33.4713, 33.4523,\n",
      "         33.4665, 33.4258, 33.4289, 33.4676, 33.4635, 33.4675, 33.4629, 33.4667,\n",
      "         33.4659, 33.4534, 33.4653, 33.4684, 33.4690, 33.4654, 33.4630, 33.4687,\n",
      "         33.4533, 33.4604, 33.4627, 33.4506, 33.4676, 33.4230, 33.4600, 33.4686,\n",
      "         33.4669, 33.4680, 33.4345, 33.4600, 33.4706, 33.4647, 33.4698, 33.4675,\n",
      "         33.4658, 33.4548, 33.4677, 33.4666, 33.4671, 33.4272, 33.4285, 33.4537,\n",
      "         33.4715, 33.4374, 33.4667, 33.4483, 33.4696, 33.4650, 33.4687, 33.4628,\n",
      "         33.4707, 33.4494, 33.4709, 33.4695, 33.4113, 33.4084, 33.4700, 33.4527,\n",
      "         33.4654, 33.4387, 33.4679, 33.4715, 33.4702, 33.4698, 33.4564, 33.4703,\n",
      "         33.4645, 33.4475, 33.4228, 33.4709, 33.4600, 33.4687, 33.4686, 33.4678,\n",
      "         33.4682, 33.4540, 33.4648, 33.4150, 33.4283, 33.4631, 33.4585, 33.4658,\n",
      "Iteration 31, Accuracy: 9.43691 tensor([[33.3883, 33.4581, 33.4679, 33.4373, 33.4446, 33.4686, 33.4704, 33.4698,\n",
      "         33.4345, 33.4688, 33.4699, 33.4693, 33.4284, 33.4314, 33.4514, 33.4443,\n",
      "         33.4683, 33.4063, 33.4323, 33.4644, 33.4672, 33.4700, 33.4675, 33.4711,\n",
      "         33.4664, 33.4402, 33.4708, 33.4680, 33.4677, 33.4396, 33.4652, 33.4707,\n",
      "         33.4502, 33.4080, 33.4670, 33.4352, 33.4707, 33.4588, 33.4609, 33.4682,\n",
      "         33.4678, 33.4701, 33.3999, 33.4595, 33.4422, 33.4662, 33.4665, 33.4617,\n",
      "         33.4398, 33.4693, 33.4638, 33.4691, 33.4651, 33.4609, 33.4485, 33.4483,\n",
      "         33.4612, 33.4479, 33.4606, 33.4648, 33.4653, 33.4665, 33.4691, 33.4685,\n",
      "         33.4695, 33.4452, 33.4652, 33.4681, 33.4029, 33.4633, 33.4682, 33.4517,\n",
      "         33.4702, 33.4217, 33.4339, 33.4520, 33.4666, 33.4693, 33.4638, 33.4665,\n",
      "         33.4707, 33.4445, 33.4187, 33.4571, 33.4191, 33.4589, 33.4699, 33.4635,\n",
      "         33.4655, 33.4500, 33.4698, 33.4115, 33.4376, 33.4705, 33.4022, 33.4599,\n",
      "Iteration 32, Accuracy: 9.72149 tensor([[33.3880, 33.4586, 33.4705, 33.4463, 33.4508, 33.4661, 33.4702, 33.4696,\n",
      "         33.4508, 33.4631, 33.4697, 33.4710, 33.4647, 33.4636, 33.4710, 33.4525,\n",
      "         33.4680, 33.4198, 33.4261, 33.4672, 33.4636, 33.4678, 33.4622, 33.4695,\n",
      "         33.4679, 33.4500, 33.4658, 33.4706, 33.4688, 33.4572, 33.4626, 33.4692,\n",
      "         33.4551, 33.4474, 33.4639, 33.4484, 33.4665, 33.4436, 33.4612, 33.4689,\n",
      "         33.4689, 33.4696, 33.4268, 33.4614, 33.4693, 33.4656, 33.4702, 33.4647,\n",
      "         33.4593, 33.4577, 33.4665, 33.4663, 33.4674, 33.4257, 33.4262, 33.4501,\n",
      "         33.4716, 33.4437, 33.4651, 33.4449, 33.4676, 33.4640, 33.4684, 33.4625,\n",
      "         33.4708, 33.4487, 33.4713, 33.4695, 33.4064, 33.4180, 33.4698, 33.4523,\n",
      "         33.4670, 33.4356, 33.4653, 33.4714, 33.4704, 33.4700, 33.4521, 33.4691,\n",
      "         33.4700, 33.4454, 33.4204, 33.4711, 33.4535, 33.4682, 33.4685, 33.4672,\n",
      "         33.4684, 33.4499, 33.4672, 33.4076, 33.4276, 33.4657, 33.4472, 33.4650,\n",
      "Iteration 33, Accuracy: 10.50400 tensor([[33.3881, 33.4578, 33.4711, 33.4395, 33.4460, 33.4685, 33.4712, 33.4706,\n",
      "         33.4382, 33.4704, 33.4697, 33.4690, 33.4527, 33.4440, 33.4585, 33.4495,\n",
      "         33.4679, 33.4095, 33.4317, 33.4670, 33.4671, 33.4698, 33.4663, 33.4715,\n",
      "         33.4690, 33.4456, 33.4688, 33.4689, 33.4696, 33.4394, 33.4659, 33.4709,\n",
      "         33.4536, 33.4230, 33.4668, 33.4379, 33.4680, 33.4533, 33.4595, 33.4695,\n",
      "         33.4676, 33.4709, 33.4223, 33.4601, 33.4599, 33.4686, 33.4712, 33.4622,\n",
      "         33.4413, 33.4695, 33.4627, 33.4676, 33.4639, 33.4450, 33.4297, 33.4478,\n",
      "         33.4702, 33.4510, 33.4623, 33.4622, 33.4641, 33.4654, 33.4683, 33.4679,\n",
      "         33.4699, 33.4458, 33.4712, 33.4699, 33.4024, 33.4522, 33.4671, 33.4497,\n",
      "         33.4703, 33.4255, 33.4509, 33.4688, 33.4713, 33.4696, 33.4601, 33.4676,\n",
      "         33.4707, 33.4445, 33.4223, 33.4656, 33.4374, 33.4574, 33.4694, 33.4643,\n",
      "         33.4692, 33.4525, 33.4693, 33.4143, 33.4255, 33.4704, 33.4311, 33.4619,\n",
      "Iteration 34, Accuracy: 10.35556 tensor([[33.3879, 33.4599, 33.4704, 33.4474, 33.4516, 33.4658, 33.4698, 33.4696,\n",
      "         33.4536, 33.4604, 33.4688, 33.4707, 33.4645, 33.4653, 33.4713, 33.4513,\n",
      "         33.4663, 33.4240, 33.4265, 33.4680, 33.4642, 33.4675, 33.4624, 33.4683,\n",
      "         33.4672, 33.4505, 33.4658, 33.4701, 33.4691, 33.4628, 33.4648, 33.4690,\n",
      "         33.4532, 33.4505, 33.4637, 33.4484, 33.4669, 33.4432, 33.4613, 33.4690,\n",
      "         33.4674, 33.4689, 33.4245, 33.4583, 33.4697, 33.4643, 33.4702, 33.4659,\n",
      "         33.4626, 33.4534, 33.4672, 33.4667, 33.4672, 33.4239, 33.4279, 33.4534,\n",
      "         33.4716, 33.4421, 33.4653, 33.4488, 33.4684, 33.4641, 33.4687, 33.4624,\n",
      "         33.4708, 33.4487, 33.4713, 33.4696, 33.4108, 33.4150, 33.4701, 33.4533,\n",
      "         33.4666, 33.4356, 33.4645, 33.4712, 33.4707, 33.4696, 33.4560, 33.4700,\n",
      "         33.4688, 33.4456, 33.4211, 33.4715, 33.4539, 33.4678, 33.4686, 33.4674,\n",
      "         33.4678, 33.4529, 33.4653, 33.4095, 33.4239, 33.4640, 33.4510, 33.4665,\n",
      "Iteration 35, Accuracy: 10.81814 tensor([[33.3883, 33.4581, 33.4654, 33.4356, 33.4464, 33.4693, 33.4699, 33.4697,\n",
      "         33.4374, 33.4688, 33.4698, 33.4691, 33.4272, 33.4393, 33.4483, 33.4433,\n",
      "         33.4679, 33.4069, 33.4294, 33.4637, 33.4684, 33.4702, 33.4683, 33.4711,\n",
      "         33.4648, 33.4383, 33.4710, 33.4682, 33.4680, 33.4382, 33.4657, 33.4707,\n",
      "         33.4473, 33.4088, 33.4671, 33.4314, 33.4708, 33.4590, 33.4606, 33.4683,\n",
      "         33.4665, 33.4700, 33.4030, 33.4607, 33.4494, 33.4661, 33.4656, 33.4630,\n",
      "         33.4390, 33.4699, 33.4647, 33.4698, 33.4650, 33.4635, 33.4542, 33.4475,\n",
      "         33.4568, 33.4445, 33.4612, 33.4651, 33.4654, 33.4671, 33.4694, 33.4691,\n",
      "         33.4696, 33.4429, 33.4627, 33.4688, 33.4016, 33.4629, 33.4687, 33.4516,\n",
      "         33.4702, 33.4239, 33.4277, 33.4504, 33.4618, 33.4694, 33.4648, 33.4675,\n",
      "         33.4708, 33.4472, 33.4225, 33.4603, 33.4208, 33.4586, 33.4693, 33.4644,\n",
      "         33.4651, 33.4507, 33.4692, 33.4130, 33.4410, 33.4707, 33.4045, 33.4554,\n",
      "Iteration 36, Accuracy: 11.00499 tensor([[33.3881, 33.4584, 33.4712, 33.4382, 33.4476, 33.4685, 33.4713, 33.4704,\n",
      "         33.4370, 33.4702, 33.4698, 33.4697, 33.4504, 33.4465, 33.4593, 33.4451,\n",
      "         33.4684, 33.4076, 33.4271, 33.4668, 33.4671, 33.4695, 33.4660, 33.4715,\n",
      "         33.4696, 33.4443, 33.4687, 33.4688, 33.4695, 33.4398, 33.4660, 33.4707,\n",
      "         33.4540, 33.4257, 33.4671, 33.4403, 33.4683, 33.4537, 33.4603, 33.4693,\n",
      "         33.4674, 33.4709, 33.4234, 33.4602, 33.4601, 33.4681, 33.4712, 33.4621,\n",
      "         33.4409, 33.4691, 33.4631, 33.4674, 33.4640, 33.4460, 33.4292, 33.4493,\n",
      "         33.4699, 33.4456, 33.4623, 33.4614, 33.4642, 33.4653, 33.4684, 33.4678,\n",
      "         33.4699, 33.4432, 33.4710, 33.4696, 33.4022, 33.4496, 33.4672, 33.4499,\n",
      "         33.4702, 33.4285, 33.4487, 33.4690, 33.4712, 33.4696, 33.4602, 33.4673,\n",
      "         33.4707, 33.4456, 33.4183, 33.4653, 33.4284, 33.4585, 33.4695, 33.4642,\n",
      "         33.4688, 33.4501, 33.4687, 33.4157, 33.4276, 33.4700, 33.4315, 33.4628,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37, Accuracy: 10.96311 tensor([[33.3881, 33.4531, 33.4712, 33.4433, 33.4497, 33.4667, 33.4710, 33.4701,\n",
      "         33.4371, 33.4700, 33.4700, 33.4708, 33.4556, 33.4563, 33.4631, 33.4449,\n",
      "         33.4694, 33.4122, 33.4206, 33.4665, 33.4674, 33.4691, 33.4637, 33.4709,\n",
      "         33.4692, 33.4415, 33.4679, 33.4698, 33.4689, 33.4401, 33.4659, 33.4704,\n",
      "         33.4523, 33.4351, 33.4660, 33.4443, 33.4682, 33.4515, 33.4600, 33.4688,\n",
      "         33.4677, 33.4702, 33.4233, 33.4617, 33.4625, 33.4646, 33.4713, 33.4624,\n",
      "         33.4438, 33.4636, 33.4647, 33.4670, 33.4666, 33.4395, 33.4260, 33.4490,\n",
      "         33.4705, 33.4476, 33.4618, 33.4543, 33.4661, 33.4635, 33.4685, 33.4652,\n",
      "         33.4701, 33.4465, 33.4714, 33.4696, 33.4001, 33.4437, 33.4692, 33.4524,\n",
      "         33.4691, 33.4293, 33.4520, 33.4696, 33.4711, 33.4694, 33.4575, 33.4681,\n",
      "         33.4709, 33.4498, 33.4237, 33.4691, 33.4364, 33.4634, 33.4699, 33.4653,\n",
      "         33.4667, 33.4489, 33.4702, 33.4159, 33.4232, 33.4675, 33.4384, 33.4627,\n",
      "Iteration 38, Accuracy: 11.00472 tensor([[33.3881, 33.4536, 33.4711, 33.4433, 33.4495, 33.4671, 33.4712, 33.4699,\n",
      "         33.4363, 33.4701, 33.4700, 33.4706, 33.4583, 33.4564, 33.4622, 33.4472,\n",
      "         33.4694, 33.4090, 33.4243, 33.4671, 33.4672, 33.4694, 33.4639, 33.4711,\n",
      "         33.4695, 33.4420, 33.4679, 33.4695, 33.4690, 33.4397, 33.4656, 33.4702,\n",
      "         33.4514, 33.4381, 33.4662, 33.4438, 33.4684, 33.4531, 33.4586, 33.4688,\n",
      "         33.4672, 33.4702, 33.4272, 33.4602, 33.4606, 33.4647, 33.4714, 33.4629,\n",
      "         33.4455, 33.4643, 33.4646, 33.4670, 33.4667, 33.4359, 33.4260, 33.4451,\n",
      "         33.4704, 33.4506, 33.4625, 33.4542, 33.4662, 33.4638, 33.4684, 33.4655,\n",
      "         33.4700, 33.4460, 33.4713, 33.4703, 33.3971, 33.4445, 33.4692, 33.4526,\n",
      "         33.4692, 33.4290, 33.4514, 33.4695, 33.4711, 33.4689, 33.4571, 33.4681,\n",
      "         33.4710, 33.4497, 33.4238, 33.4691, 33.4355, 33.4634, 33.4695, 33.4654,\n",
      "         33.4668, 33.4498, 33.4696, 33.4155, 33.4221, 33.4675, 33.4384, 33.4628,\n",
      "Iteration 39, Accuracy: 10.89031 tensor([[33.3879, 33.4577, 33.4698, 33.4482, 33.4523, 33.4654, 33.4691, 33.4692,\n",
      "         33.4618, 33.4539, 33.4628, 33.4701, 33.4676, 33.4691, 33.4713, 33.4522,\n",
      "         33.4665, 33.4265, 33.4327, 33.4663, 33.4625, 33.4674, 33.4629, 33.4665,\n",
      "         33.4653, 33.4531, 33.4652, 33.4680, 33.4690, 33.4649, 33.4623, 33.4686,\n",
      "         33.4533, 33.4609, 33.4625, 33.4507, 33.4676, 33.4243, 33.4600, 33.4684,\n",
      "         33.4669, 33.4682, 33.4315, 33.4599, 33.4707, 33.4648, 33.4698, 33.4678,\n",
      "         33.4648, 33.4535, 33.4678, 33.4667, 33.4682, 33.4265, 33.4296, 33.4537,\n",
      "         33.4715, 33.4376, 33.4668, 33.4508, 33.4698, 33.4649, 33.4688, 33.4627,\n",
      "         33.4707, 33.4495, 33.4710, 33.4685, 33.4145, 33.4056, 33.4698, 33.4527,\n",
      "         33.4652, 33.4405, 33.4665, 33.4714, 33.4701, 33.4697, 33.4581, 33.4703,\n",
      "         33.4642, 33.4475, 33.4230, 33.4708, 33.4609, 33.4687, 33.4686, 33.4677,\n",
      "         33.4682, 33.4539, 33.4649, 33.4103, 33.4292, 33.4628, 33.4561, 33.4656,\n",
      "Iteration 40, Accuracy: 10.87945 tensor([[33.3881, 33.4568, 33.4712, 33.4439, 33.4483, 33.4668, 33.4710, 33.4697,\n",
      "         33.4365, 33.4701, 33.4701, 33.4708, 33.4557, 33.4581, 33.4650, 33.4490,\n",
      "         33.4679, 33.4114, 33.4247, 33.4666, 33.4674, 33.4692, 33.4638, 33.4710,\n",
      "         33.4691, 33.4426, 33.4677, 33.4697, 33.4691, 33.4414, 33.4660, 33.4702,\n",
      "         33.4516, 33.4347, 33.4668, 33.4446, 33.4684, 33.4513, 33.4589, 33.4691,\n",
      "         33.4678, 33.4702, 33.4237, 33.4602, 33.4624, 33.4644, 33.4713, 33.4624,\n",
      "         33.4477, 33.4630, 33.4648, 33.4674, 33.4686, 33.4405, 33.4267, 33.4464,\n",
      "         33.4706, 33.4414, 33.4618, 33.4547, 33.4663, 33.4633, 33.4684, 33.4647,\n",
      "         33.4702, 33.4443, 33.4715, 33.4698, 33.3995, 33.4437, 33.4693, 33.4524,\n",
      "         33.4688, 33.4307, 33.4525, 33.4699, 33.4712, 33.4694, 33.4571, 33.4683,\n",
      "         33.4710, 33.4461, 33.4206, 33.4694, 33.4373, 33.4635, 33.4700, 33.4653,\n",
      "         33.4662, 33.4509, 33.4693, 33.4184, 33.4239, 33.4673, 33.4346, 33.4629,\n",
      "Iteration 41, Accuracy: 10.77372 tensor([[33.3881, 33.4571, 33.4710, 33.4394, 33.4463, 33.4688, 33.4712, 33.4704,\n",
      "         33.4386, 33.4701, 33.4695, 33.4694, 33.4504, 33.4450, 33.4561, 33.4451,\n",
      "         33.4683, 33.4081, 33.4286, 33.4667, 33.4681, 33.4697, 33.4662, 33.4714,\n",
      "         33.4691, 33.4420, 33.4690, 33.4681, 33.4695, 33.4404, 33.4659, 33.4708,\n",
      "         33.4522, 33.4231, 33.4668, 33.4366, 33.4683, 33.4529, 33.4617, 33.4694,\n",
      "         33.4679, 33.4710, 33.4215, 33.4609, 33.4568, 33.4682, 33.4711, 33.4615,\n",
      "         33.4410, 33.4695, 33.4623, 33.4676, 33.4637, 33.4484, 33.4353, 33.4506,\n",
      "         33.4678, 33.4511, 33.4615, 33.4650, 33.4639, 33.4655, 33.4685, 33.4680,\n",
      "         33.4697, 33.4426, 33.4699, 33.4692, 33.4043, 33.4571, 33.4675, 33.4501,\n",
      "         33.4704, 33.4276, 33.4426, 33.4681, 33.4702, 33.4696, 33.4598, 33.4673,\n",
      "         33.4706, 33.4448, 33.4230, 33.4642, 33.4284, 33.4574, 33.4706, 33.4640,\n",
      "         33.4688, 33.4506, 33.4693, 33.4145, 33.4257, 33.4703, 33.4296, 33.4621,\n",
      "Iteration 42, Accuracy: 11.29211 tensor([[33.3883, 33.4591, 33.4671, 33.4380, 33.4452, 33.4685, 33.4702, 33.4695,\n",
      "         33.4369, 33.4690, 33.4697, 33.4691, 33.4322, 33.4381, 33.4476, 33.4403,\n",
      "         33.4682, 33.4063, 33.4298, 33.4652, 33.4684, 33.4699, 33.4675, 33.4713,\n",
      "         33.4673, 33.4352, 33.4708, 33.4680, 33.4681, 33.4390, 33.4665, 33.4706,\n",
      "         33.4493, 33.4109, 33.4669, 33.4319, 33.4706, 33.4572, 33.4610, 33.4682,\n",
      "         33.4676, 33.4704, 33.4054, 33.4596, 33.4483, 33.4661, 33.4664, 33.4621,\n",
      "         33.4396, 33.4693, 33.4638, 33.4690, 33.4658, 33.4606, 33.4457, 33.4445,\n",
      "         33.4568, 33.4447, 33.4608, 33.4653, 33.4649, 33.4665, 33.4690, 33.4683,\n",
      "         33.4695, 33.4436, 33.4649, 33.4682, 33.4005, 33.4617, 33.4681, 33.4528,\n",
      "         33.4711, 33.4237, 33.4278, 33.4551, 33.4651, 33.4694, 33.4643, 33.4666,\n",
      "         33.4707, 33.4478, 33.4238, 33.4607, 33.4126, 33.4587, 33.4702, 33.4641,\n",
      "         33.4652, 33.4517, 33.4700, 33.4101, 33.4309, 33.4702, 33.4076, 33.4591,\n",
      "         33.4613, 33.3989, 33.4514, 33.4562, 33.4673]])"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1676337/2199582302.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1676337/1482031453.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1676337/1482031453.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1676337/1482031453.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# (n_samples, n_patches + 1, hidden_features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# (n_samples, n_patches + 1, hidden_features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (n_samples, n_patches + 1, hidden_features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyvhr/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "accuracy = 0.0\n",
    "total = 0.0\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(trainloader, 1):\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        outputs = model(inputs)\n",
    "        err = torch.abs(torch.mean(outputs,1)- targets).item()\n",
    "        total = i\n",
    "        accuracy += err\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write(f\"Iteration {i}, Accuracy: {accuracy/total:1.5f} {outputs}\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "083a6ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 15\n",
    "EMBED_DIM = PATCH_SIZE * PATCH_SIZE * 3\n",
    "NUM_PATCHES = 100\n",
    "IMG_SIZE = PATCH_SIZE * NUM_PATCHES\n",
    "HEADS = 5\n",
    "BLOCKS = 12\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "  def __init__(self, img_size, patch_size, in_chans=3, embed_dim=EMBED_DIM):\n",
    "    super().__init__()\n",
    "    self.img_size = img_size\n",
    "    self.patch_size = patch_size\n",
    "    self.n_patches = (img_size // patch_size) ** 2\n",
    "    self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.movedim(x,3,1)\n",
    "    x = self.proj(x)       # (n_samples, embed_dim, n_patches ** 0.5, n_patches ** 0.5)\n",
    "    x = x.flatten(2)        # (n_samples, embed_dim, n_patches)\n",
    "    x = x.transpose(1, 2)  # (n_samples, n_patches, embed_dim)\n",
    "\n",
    "    return x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "\n",
    "\n",
    "  def __init__(self, dim, n_heads=HEADS, qkv_bias=True, attn_p=0., proj_p=0.):\n",
    "    super().__init__()\n",
    "    self.n_heads = n_heads\n",
    "    self.dim = dim\n",
    "    self.head_dim = dim // n_heads\n",
    "    self.scale = self.head_dim ** -0.5\n",
    "\n",
    "    self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "    self.attn_drop = nn.Dropout(attn_p)\n",
    "    self.proj = nn.Linear(dim, dim)\n",
    "    self.proj_drop = nn.Dropout(proj_p)\n",
    "\n",
    "  def forward(self, x):\n",
    "    n_samples, n_tokens, dim = x.shape\n",
    "\n",
    "    if dim != self.dim:\n",
    "      raise ValueError\n",
    "\n",
    "    qkv = self.qkv(x)  # (n_samples, n_patches + 1, 3 * dim)\n",
    "    qkv = qkv.reshape(n_samples, n_tokens, 3, self.n_heads, self.head_dim)  # (n_smaples, n_patches + 1, 3, n_heads, head_dim)\n",
    "    qkv = qkv.permute(2, 0, 3, 1, 4)  # (3, n_samples, n_heads, n_patches + 1, head_dim)\n",
    "\n",
    "    # compute att matrices\n",
    "    q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "    k_t = k.transpose(-2, -1)   # (n_samples, n_heads, head_dim, n_patches + 1)\n",
    "    dp = (q @ k_t) * self.scale\n",
    "\n",
    "    attn = dp.softmax(dim=-1)   # (n_samples, n_heads, n_patches + 1, n_patches + 1)\n",
    "    attn = self.attn_drop(attn)\n",
    "\n",
    "    # compute weigthed avg\n",
    "    weighted_avg = attn @ v  # (n_samples, n_heads, n_patches +1, head_dim)\n",
    "    weighted_avg = weighted_avg.transpose(1, 2)  # (n_samples, n_patches + 1, n_heads, head_dim)\n",
    "    weighted_avg = weighted_avg.flatten(2)  # (n_samples, n_patches + 1, dim)\n",
    "\n",
    "    # linear projection\n",
    "    x = self.proj(weighted_avg)  # (n_samples, n_patches + 1, dim)\n",
    "    x = self.proj_drop(x)        # (n_samples, n_patches + 1, dim)\n",
    "\n",
    "    return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, hidden_features, out_features, p=0.):\n",
    "      super().__init__()\n",
    "      self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "      self.act = nn.GELU()\n",
    "      self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "      self.drop = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.fc1(x)   # (n_samples, n_patches + 1, hidden_features)\n",
    "      x = self.act(x)   # (n_samples, n_patches + 1, hidden_features)\n",
    "      x = self.drop(x)  # (n_samples, n_patches + 1, hidden_features)\n",
    "      x = self.fc2(x)   # (n_samples, n_patches + 1, hidden_features)\n",
    "      x = self.drop(x)  # (n_samples, n_patches + 1, hidden_features)\n",
    "\n",
    "      return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim, n_heads, mlp_ratio=4.0, qkv_bias=True, p=0., attn_p=0.):\n",
    "      super().__init__()\n",
    "      self.norm1 = nn.LayerNorm(dim, eps=1e-6)\n",
    "      self.attn = Attention(dim, n_heads=n_heads, qkv_bias=qkv_bias, attn_p=attn_p, proj_p=p)\n",
    "      self.norm2 = nn.LayerNorm(dim, eps=1e-6)\n",
    "      hidden_features = int(dim * mlp_ratio)\n",
    "      self.mlp = MLP(in_features=dim, hidden_features=hidden_features, out_features=dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "     \n",
    "      \n",
    "      x = x + self.attn(self.norm1(x))\n",
    "      x = x + self.mlp(self.norm2(x))\n",
    "\n",
    "      return x\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "  \n",
    "  def __init__(\n",
    "          self,\n",
    "          img_size=IMG_SIZE,\n",
    "          patch_size=PATCH_SIZE,\n",
    "          in_chans=3,\n",
    "          n_classes=1000,\n",
    "          embed_dim=EMBED_DIM,\n",
    "          depth=BLOCKS,\n",
    "          n_heads=HEADS,\n",
    "          mlp_ratio=4.,\n",
    "          qkv_bias=True,\n",
    "          p=0.,\n",
    "          attn_p=0.,\n",
    "  ):\n",
    "    super().__init__()\n",
    "\n",
    "    self.patch_embed = PatchEmbed(\n",
    "            img_size=img_size,\n",
    "            patch_size=patch_size,\n",
    "            in_chans=in_chans,\n",
    "            embed_dim=embed_dim,\n",
    "    )\n",
    "    self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "    self.pos_embed = nn.Parameter(\n",
    "            torch.zeros(1, 1 + self.patch_embed.n_patches, embed_dim)\n",
    "    )\n",
    "    self.pos_drop = nn.Dropout(p=p)\n",
    "\n",
    "    self.blocks = nn.ModuleList(\n",
    "        [\n",
    "            Block(\n",
    "                dim=embed_dim,\n",
    "                n_heads=n_heads,\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                qkv_bias=qkv_bias,\n",
    "                p=p,\n",
    "                attn_p=attn_p,\n",
    "            )\n",
    "            for _ in range(depth)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.norm = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "    self.head = nn.Linear(embed_dim, n_classes)\n",
    "    self.lastConv = nn.Conv1d(embed_dim, 1,1,stride=1, padding=0)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    n_samples = x.shape[0]\n",
    "    x = self.patch_embed(x)  #(n_samples, n_patches, embed_dim)\n",
    "    \n",
    "    \n",
    "    cls_token = self.cls_token.expand(n_samples, -1, -1)  # (n_samples, 1, embed_dim)\n",
    "    x = torch.cat((cls_token, x), dim=1)  # (n_samples, 1 + n_patches, embed_dim)\n",
    "    #x = x + self.pos_embed  # (n_samples, 1 + n_patches, embed_dim)\n",
    "    x = self.pos_drop(x)\n",
    "\n",
    "    for block in self.blocks:\n",
    "      x = block(x)\n",
    "\n",
    "    x = self.norm(x)\n",
    "\n",
    "    cls_token_final = x[:, 0]  # just the CLS token\n",
    "    #x = self.head(cls_token_final)\n",
    "    #x = x.type(torch.DoubleTensor)\n",
    "    #x = torch.mean(x,1)\n",
    "    #x = torch.mean(x,1)\n",
    "    x = x.permute(0, 2, 1) \n",
    "    x = self.lastConv(x)\n",
    "    x = x.squeeze(1)\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744425cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
