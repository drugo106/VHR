{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f358a0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 11:50:11.963866: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import timm\n",
    "import sys \n",
    "from torchinfo import summary\n",
    "from scipy import signal\n",
    "from scipy.stats import zscore\n",
    "import pyVHR as vhr\n",
    "import pickle\n",
    "from typing import Optional\n",
    "import math\n",
    "import os\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "from TorchLossComputer import TorchLossComputer\n",
    "from TorchLossComputerCPU import TorchLossComputerCPU\n",
    "from PhysFormer import ViT_ST_ST_Compact3_TDC_gra_sharp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed817b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/datasets/VHR1/PURE\n"
     ]
    }
   ],
   "source": [
    "PATCH_SIZE = 16\n",
    "EMBED_DIM = PATCH_SIZE * PATCH_SIZE * 3\n",
    "NUM_PATCHES = 100\n",
    "IMG_SIZE = PATCH_SIZE * NUM_PATCHES\n",
    "HEADS = 12\n",
    "BLOCKS = 12\n",
    "BATCH = 300\n",
    "LENGTH = 160\n",
    "\n",
    "vhr.plot.VisualizeParams.renderer = 'notebook'  # or 'notebook'\n",
    "\n",
    "dataset_name = 'pure'           \n",
    "video_DIR = '/var/datasets/VHR1/'  \n",
    "BVP_DIR = '/var/datasets/VHR1/'    \n",
    "\n",
    "dataset = vhr.datasets.datasetFactory(dataset_name, videodataDIR=video_DIR, BVPdataDIR=BVP_DIR)\n",
    "allvideo = dataset.videoFilenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b99c4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, bvp, stride = 5, window = 160):\n",
    "    tmp = []\n",
    "    tmp_bvp = []\n",
    "    for i in range(0, len(lst)-window, stride):\n",
    "        tmp.append(torch.as_tensor(lst[i:i + window]))\n",
    "        tmp_bvp.append(torch.as_tensor(bvp[i:i + window]))\n",
    "    if tmp[-1].shape[0] != tmp[0].shape[0]:\n",
    "        return(torch.stack(tmp[:-1]),torch.stack(tmp_bvp[:-1]))\n",
    "    return(torch.stack(tmp),torch.stack(tmp_bvp))\n",
    "        \n",
    "#webs,train_bvp = chunks(webs,train_bvp,160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e14710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(tot):\n",
    "    min_len = 0\n",
    "    train_video = []\n",
    "    train_bvp = []\n",
    "    val_video = []\n",
    "    val_bvp = []\n",
    "    test_video = []\n",
    "    test_bvp = []\n",
    "    for idx in range(0,tot):\n",
    "        with open('/var/datasets/PURE_webs/'+str(idx)+'-WEBS-'+str(PATCH_SIZE), 'rb') as f:\n",
    "            #print('/var/datasets/PURE_webs/'+str(idx)+'-WEBS-'+str(PATCH_SIZE))\n",
    "            (webs,labels) = pickle.load(f)\n",
    "            if idx < ((tot/10)*9)-1:   #9 : 0 : 1\n",
    "                train_video.append(webs)\n",
    "                train_bvp.append(zscore(labels))\n",
    "            #elif idx < (tot/10)*8+(tot/10):\n",
    "                #print(2)\n",
    "                #val_video.append(webs)\n",
    "                #val_bvp.append(labels)\n",
    "            else:\n",
    "                #print(3)\n",
    "                test_video.append(webs)\n",
    "                test_bvp.append(zscore(labels))\n",
    "            if min_len==0 or len(webs)<min_len:\n",
    "                min_len = len(webs)\n",
    "    for i in range(0,len(train_video)):\n",
    "        train_video[i],train_bvp[i] = chunks(train_video[i][:min_len-1], train_bvp[i][:min_len-1])\n",
    "    #for i in range(0,len(val_video)):\n",
    "    #    val_video[i],val_bvp[i] = chunks(val_video[i][:min_len-1], val_bvp[i][:min_len-1],160)\n",
    "    for i in range(0,len(test_video)):\n",
    "        test_video[i],test_bvp[i] = chunks(test_video[i][:min_len-1], test_bvp[i][:min_len-1])\n",
    "    return (train_video, train_bvp), (val_video, val_bvp), (test_video, test_bvp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7adaef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckp(model, optimizer, epoch, loss, iteration, path=\".\"):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'iteration': iteration + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    f_path = path + '/checkpoint.pt'\n",
    "    torch.save(checkpoint, f_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28999bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(model, optimizer, path='./checkpoint.pt'):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer, checkpoint['epoch'], checkpoint['iteration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e27886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neg_Pearson(nn.Module):    # Pearson range [-1, 1] so if < 0, abs|loss| ; i>0, 1- loss                                                                      \n",
    "    def __init__(self):                                                           \n",
    "        super(Neg_Pearson,self).__init__()\n",
    "        return\n",
    "    def forward(self, preds, labels):       # all variable operation    \n",
    "        loss = 0\n",
    "        for i in range(preds.shape[0]):\n",
    "            sum_x = torch.sum(preds[i])\n",
    "            sum_y = torch.sum(labels[i])\n",
    "            sum_xy = torch.sum(preds[i]*labels[i])\n",
    "            sum_x2 = torch.sum(torch.pow(preds[i],2))\n",
    "            sum_y2 = torch.sum(torch.pow(labels[i],2))\n",
    "            N = preds.shape[1]\n",
    "            pearson = (N*sum_xy - sum_x*sum_y)/(torch.sqrt((N*sum_x2 - torch.pow(sum_x,2))*(N*sum_y2 - torch.pow(sum_y,2))))\n",
    "            loss += 1 - pearson\n",
    "        loss = loss/preds.shape[0]\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4b15612",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgrageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.cnt = 0\n",
    "        \n",
    "    def update(self, val, n=1):\n",
    "        self.sum += val * n\n",
    "        self.cnt += n\n",
    "        self.avg = (self.sum / self.cnt).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da28c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_video,train_bvp),(val_video,val_bvp),(test_video,test_bvp) = load_data(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24ac2cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video, train_bvp = torch.cat(train_video[:]), torch.cat(train_bvp[:])\n",
    "#val_video, val_bvp     = torch.cat(val_video[:]), torch.cat(val_bvp[:])\n",
    "test_video, test_bvp   = torch.cat(test_video[:]), torch.cat(test_bvp[:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f98389a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_bvp[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4cda98f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_bvp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3509692/3869231617.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclazz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_bvp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbvp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbvp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclazz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclazz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbvp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclazz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbvp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_bvp' is not defined"
     ]
    }
   ],
   "source": [
    "clazz = {}\n",
    "for frame in train_bvp:\n",
    "    for bvp in video:\n",
    "        if bvp.item() in clazz: clazz[bvp.item()] += 1\n",
    "        else: clazz[bvp.item()] = 1\n",
    "            \n",
    "print(clazz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "faf021cf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 21\n",
      "0: 670\n",
      "1: 213\n",
      "2: 256\n",
      "3: 96\n",
      "4: 64\n",
      "5: 353\n",
      "6: 289\n",
      "7: 430\n",
      "8: 576\n",
      "9: 717\n",
      "10: 670\n",
      "11: 1024\n",
      "12: 1081\n",
      "13: 1560\n",
      "14: 2013\n",
      "15: 2292\n",
      "16: 2634\n",
      "17: 3997\n",
      "18: 4838\n",
      "19: 5072\n",
      "20: 6595\n",
      "21: 7415\n",
      "22: 9295\n",
      "23: 9360\n",
      "24: 10748\n",
      "25: 11607\n",
      "26: 11641\n",
      "27: 11426\n",
      "28: 9766\n",
      "29: 8935\n",
      "30: 8583\n",
      "31: 7304\n",
      "32: 6731\n",
      "33: 7013\n",
      "34: 5638\n",
      "35: 4866\n",
      "36: 4570\n",
      "37: 4851\n",
      "38: 5083\n",
      "39: 5412\n",
      "40: 5959\n",
      "41: 4886\n",
      "42: 5016\n",
      "43: 5656\n",
      "44: 5690\n",
      "45: 5346\n",
      "46: 6411\n",
      "47: 6137\n",
      "48: 6317\n",
      "49: 5990\n",
      "50: 6213\n",
      "51: 6188\n",
      "52: 5783\n",
      "53: 4529\n",
      "54: 5161\n",
      "55: 5327\n",
      "56: 4718\n",
      "57: 4161\n",
      "58: 3298\n",
      "59: 3437\n",
      "60: 3711\n",
      "61: 3895\n",
      "62: 3670\n",
      "63: 3215\n",
      "64: 2887\n",
      "65: 3694\n",
      "66: 2581\n",
      "67: 2211\n",
      "68: 2830\n",
      "69: 2218\n",
      "70: 1794\n",
      "71: 2519\n",
      "72: 1733\n",
      "73: 1454\n",
      "74: 1485\n",
      "75: 1123\n",
      "76: 1087\n",
      "77: 1113\n",
      "78: 845\n",
      "79: 809\n",
      "80: 725\n",
      "81: 856\n",
      "82: 511\n",
      "83: 683\n",
      "84: 480\n",
      "85: 448\n",
      "86: 432\n",
      "87: 292\n",
      "88: 388\n",
      "89: 111\n",
      "90: 217\n",
      "91: 153\n",
      "92: 103\n",
      "93: 32\n",
      "94: 103\n",
      "96: 64\n",
      "97: 160\n",
      "99: 32\n",
      "100: 32\n",
      "104: 32\n",
      "105: 64\n"
     ]
    }
   ],
   "source": [
    "for k in sorted(clazz.keys()):\n",
    "    print(str(k) + \": \"+ str(clazz[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1f1a5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2142, 160, 160, 160, 3]) torch.Size([2142, 160])\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "ViT_ST_ST_Compact3_TDC_gra_sharp                                  --\n",
      "├─Conv3d: 1-1                                                     26,214,560\n",
      "├─Transformer_ST_TDC_gra_sharp: 1-2                               --\n",
      "│    └─ModuleList: 2-1                                            --\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-1                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-2                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-3                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-4                           1,485,904\n",
      "├─Transformer_ST_TDC_gra_sharp: 1-3                               --\n",
      "│    └─ModuleList: 2-2                                            --\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-5                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-6                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-7                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-8                           1,485,904\n",
      "├─Transformer_ST_TDC_gra_sharp: 1-4                               --\n",
      "│    └─ModuleList: 2-3                                            --\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-9                           1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-10                          1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-11                          1,485,904\n",
      "│    │    └─Block_ST_TDC_gra_sharp: 3-12                          1,485,904\n",
      "├─Sequential: 1-5                                                 --\n",
      "│    └─Conv3d: 2-4                                                3,040\n",
      "│    └─BatchNorm3d: 2-5                                           80\n",
      "│    └─ReLU: 2-6                                                  --\n",
      "│    └─MaxPool3d: 2-7                                             --\n",
      "├─Sequential: 1-6                                                 --\n",
      "│    └─Conv3d: 2-8                                                86,480\n",
      "│    └─BatchNorm3d: 2-9                                           160\n",
      "│    └─ReLU: 2-10                                                 --\n",
      "│    └─MaxPool3d: 2-11                                            --\n",
      "├─Sequential: 1-7                                                 --\n",
      "│    └─Conv3d: 2-12                                               345,760\n",
      "│    └─BatchNorm3d: 2-13                                          320\n",
      "│    └─ReLU: 2-14                                                 --\n",
      "│    └─MaxPool3d: 2-15                                            --\n",
      "├─Sequential: 1-8                                                 --\n",
      "│    └─Upsample: 2-16                                             --\n",
      "│    └─Conv3d: 2-17                                               76,960\n",
      "│    └─BatchNorm3d: 2-18                                          320\n",
      "│    └─ELU: 2-19                                                  --\n",
      "├─Sequential: 1-9                                                 --\n",
      "│    └─Upsample: 2-20                                             --\n",
      "│    └─Conv3d: 2-21                                               38,480\n",
      "│    └─BatchNorm3d: 2-22                                          160\n",
      "│    └─ELU: 2-23                                                  --\n",
      "├─Conv1d: 1-10                                                    81\n",
      "==========================================================================================\n",
      "Total params: 44,597,249\n",
      "Trainable params: 44,597,249\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "BATCH = 4\n",
    "#train_video = train_video.permute(0,4,1,2,3)\n",
    "#val_video = val_video.permute(0,4,1,2,3)\n",
    "#test_video = test_video.permute(0,4,1,2,3)\n",
    "print(train_video.shape,train_bvp.shape)\n",
    "dataset = torch.utils.data.TensorDataset(train_video.permute(0,4,1,2,3),train_bvp)\n",
    "trainloader = torch.utils.data.DataLoader(dataset,batch_size=BATCH, shuffle=True, num_workers=1)\n",
    "\n",
    "model = ViT_ST_ST_Compact3_TDC_gra_sharp(image_size=(160,160,160), patches=(4,16,16), dim=160, ff_dim=144, num_heads=4, num_layers=12, dropout_rate=0.1, theta=0.7)\n",
    "print(summary(model))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_function = nn.L1Loss()\n",
    "criterion_Pearson = Neg_Pearson() \n",
    "\n",
    "loss = 0.0\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f54552d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, trainloader, epoch_start=0, iter_start=0):\n",
    "    criterion_reg = nn.MSELoss()\n",
    "    criterion_L1loss = nn.L1Loss()\n",
    "    criterion_class = nn.CrossEntropyLoss()\n",
    "    criterion_Pearson = Neg_Pearson()\n",
    "        \n",
    "    a_start = 0.1\n",
    "    b_start = 1.0\n",
    "    exp_a = 0.5\n",
    "    exp_b = 5.0\n",
    "    \n",
    "    writer = SummaryWriter()\n",
    "    \n",
    "    path_log = 'LOG'\n",
    "    isExists = os.path.exists(path_log)\n",
    "    if not isExists:\n",
    "        os.makedirs(path_log)\n",
    "    log_file = open(path_log+'/LOG_log.txt', 'w')\n",
    "    \n",
    "    for epoch in range(epoch_start, epochs):\n",
    "        print(\"\\nStarting epoch\", epoch+1)\n",
    "        loss = 0.0\n",
    "        loss_rPPG_avg = AvgrageMeter()\n",
    "        loss_peak_avg = AvgrageMeter()\n",
    "        loss_kl_avg_test = AvgrageMeter()\n",
    "        loss_bvp_mae = AvgrageMeter()\n",
    "        \n",
    "        model.train()\n",
    "        for i, data in enumerate(trainloader,0):\n",
    "            if i >= iter_start: \n",
    "                \n",
    "                iter_start = 0\n",
    "                inputs, targets = data\n",
    "                inputs, targets = inputs.float().cuda(), targets.float().cuda()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                rPPG = model(inputs,0.2) \n",
    "                rPPG = (rPPG-torch.mean(rPPG)) /torch.std(rPPG)\n",
    "                #loss\n",
    "                loss = criterion_reg\n",
    "                loss_rPPG = criterion_Pearson(rPPG, targets)\n",
    "                fre_loss = 0.0\n",
    "                kl_loss = 0.0\n",
    "                train_mae = 0.0\n",
    "                \"\"\"for bb in range(inputs.shape[0]):\n",
    "                    loss_distribution_kl, fre_loss_temp, train_mae_temp = TorchLossComputer.cross_entropy_power_spectrum_DLDL_softmax2(\n",
    "                        rPPG[bb], torch.mean(targets[bb].float()), 30, std=1.0) \n",
    "                    fre_loss = fre_loss + fre_loss_temp\n",
    "                    kl_loss = kl_loss + loss_distribution_kl\n",
    "                    train_mae = train_mae + train_mae_temp\n",
    "                fre_loss = fre_loss/inputs.shape[0]\n",
    "                kl_loss = kl_loss/inputs.shape[0]\n",
    "                train_mae = train_mae/inputs.shape[0]\n",
    "                print(train_mae)\n",
    "                if epoch >25:\n",
    "                    a = 0.05\n",
    "                    b = 5.0\n",
    "                else:\n",
    "                    a = a_start*math.pow(exp_a, epoch/25.0)\n",
    "                    b = b_start*math.pow(exp_b, epoch/25.0)\n",
    "            \n",
    "                a = 0.1\n",
    "            \n",
    "                loss =  a*loss_rPPG + b*(fre_loss+kl_loss)\n",
    "                \"\"\"\n",
    "                #print(rPPG[0])\n",
    "                #print(targets[0])\n",
    "                \n",
    "                #fre_loss = sum(sum(rPPG - targets)/4)\n",
    "                #print(fre_loss)\n",
    "                #print(loss_rPPG)\n",
    "                \n",
    "                loss = loss_rPPG \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                n = inputs.size(0)\n",
    "                loss_rPPG_avg.update(loss_rPPG.data, n)\n",
    "                #loss_peak_avg.update(fre_loss.data, n)\n",
    "                #loss_kl_avg_test.update(kl_loss.data, n)\n",
    "                #loss_bvp_mae.update(train_mae, n)\n",
    "                \n",
    "                sys.stdout.write('\\r')\n",
    "                sys.stdout.write(f\"Iteration {i+1}, loss= {loss/((i+1)*inputs.shape[0]):1.5f}, NegPearson= {loss_rPPG_avg.avg:1.5f}, kl= {loss_kl_avg_test.avg:1.5f}, fre_CEloss= {loss_peak_avg.avg:1.5f}\")\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "                writer.add_scalar('Epoch '+str(epoch)+' Loss/train', loss/((i+1)*inputs.shape[0]), i)\n",
    "\n",
    "                save_ckp(model, optimizer, loss, epoch, i)\n",
    "                \n",
    "                if( i%50 == 0):\n",
    "                    log_file.write(\"\\n\")        \n",
    "                    log_file.write(f\"Epoch {epoch+1}, Iteration {i+1}, loss= {loss/((i+1)*inputs.shape[0]):1.5f}, NegPearson= {loss_rPPG_avg.avg:1.5f}, kl= {loss_kl_avg_test.avg:1.5f}, fre_CEloss= {loss_peak_avg.avg:1.5f}\")\n",
    "                    log_file.write(\"\\n\")\n",
    "                    log_file.write(\"\\n\")\n",
    "                    log_file.flush()\n",
    "                \n",
    "\n",
    "    return model, loss, loss_rPPG_avg, loss_peak_avg, loss_kl_avg_test, loss_bvp_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f0bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations per epoch:  536\n",
      "epochs: 25\n",
      "Start\n",
      "\n",
      "Starting epoch 1\n",
      "\n",
      "\n",
      "Iteration 1, loss= 0.24216, NegPearson= 0.96864, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 2, loss= 0.11285, NegPearson= 0.93573, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 3, loss= 0.08459, NegPearson= 0.96216, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 4, loss= 0.05942, NegPearson= 0.95928, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 5, loss= 0.04892, NegPearson= 0.96309, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 6, loss= 0.04184, NegPearson= 0.96995, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 7, loss= 0.03875, NegPearson= 0.98639, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 8, loss= 0.03421, NegPearson= 0.99991, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 9, loss= 0.02433, NegPearson= 0.98612, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 10, loss= 0.02775, NegPearson= 0.99852, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 11, loss= 0.02343, NegPearson= 1.00148, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 12, loss= 0.02092, NegPearson= 1.00170, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 13, loss= 0.01876, NegPearson= 0.99967, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 14, loss= 0.01827, NegPearson= 1.00135, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 15, loss= 0.01652, NegPearson= 1.00066, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 16, loss= 0.01384, NegPearson= 0.99349, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 17, loss= 0.01317, NegPearson= 0.98773, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 18, loss= 0.01413, NegPearson= 0.98935, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 19, loss= 0.01366, NegPearson= 0.99194, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 20, loss= 0.01215, NegPearson= 0.99093, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 21, loss= 0.01187, NegPearson= 0.99120, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 22, loss= 0.01121, NegPearson= 0.99097, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 23, loss= 0.01135, NegPearson= 0.99327, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 24, loss= 0.01006, NegPearson= 0.99215, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 25, loss= 0.01050, NegPearson= 0.99444, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 26, loss= 0.00871, NegPearson= 0.99103, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 27, loss= 0.00825, NegPearson= 0.98731, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 28, loss= 0.00944, NegPearson= 0.98982, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 29, loss= 0.00966, NegPearson= 0.99431, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 30, loss= 0.00799, NegPearson= 0.99314, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 31, loss= 0.00863, NegPearson= 0.99562, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 32, loss= 0.00822, NegPearson= 0.99739, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 33, loss= 0.00742, NegPearson= 0.99683, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 34, loss= 0.00713, NegPearson= 0.99605, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 35, loss= 0.00703, NegPearson= 0.99570, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 36, loss= 0.00715, NegPearson= 0.99663, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 37, loss= 0.00697, NegPearson= 0.99757, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 38, loss= 0.00668, NegPearson= 0.99802, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 39, loss= 0.00621, NegPearson= 0.99728, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 40, loss= 0.00574, NegPearson= 0.99531, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 41, loss= 0.00619, NegPearson= 0.99578, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 42, loss= 0.00555, NegPearson= 0.99427, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 43, loss= 0.00643, NegPearson= 0.99688, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 44, loss= 0.00592, NegPearson= 0.99792, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 45, loss= 0.00536, NegPearson= 0.99719, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 46, loss= 0.00528, NegPearson= 0.99663, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 47, loss= 0.00536, NegPearson= 0.99684, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 48, loss= 0.00522, NegPearson= 0.99695, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 49, loss= 0.00559, NegPearson= 0.99896, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 50, loss= 0.00484, NegPearson= 0.99834, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 51, loss= 0.00475, NegPearson= 0.99778, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 52, loss= 0.00461, NegPearson= 0.99702, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 53, loss= 0.00524, NegPearson= 0.99918, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 54, loss= 0.00448, NegPearson= 0.99859, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 55, loss= 0.00463, NegPearson= 0.99895, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 56, loss= 0.00467, NegPearson= 0.99980, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 57, loss= 0.00421, NegPearson= 0.99909, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 58, loss= 0.00405, NegPearson= 0.99807, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 59, loss= 0.00429, NegPearson= 0.99833, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 60, loss= 0.00388, NegPearson= 0.99720, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 61, loss= 0.00450, NegPearson= 0.99887, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 62, loss= 0.00430, NegPearson= 0.99998, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 63, loss= 0.00412, NegPearson= 1.00057, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 64, loss= 0.00383, NegPearson= 1.00027, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 65, loss= 0.00368, NegPearson= 0.99962, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 66, loss= 0.00399, NegPearson= 1.00042, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 67, loss= 0.00349, NegPearson= 0.99945, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 68, loss= 0.00352, NegPearson= 0.99882, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 69, loss= 0.00374, NegPearson= 0.99930, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 70, loss= 0.00383, NegPearson= 1.00034, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 71, loss= 0.00371, NegPearson= 1.00107, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 72, loss= 0.00350, NegPearson= 1.00117, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 73, loss= 0.00308, NegPearson= 0.99976, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 74, loss= 0.00331, NegPearson= 0.99949, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 75, loss= 0.00291, NegPearson= 0.99779, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 76, loss= 0.00363, NegPearson= 0.99919, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 77, loss= 0.00329, NegPearson= 0.99937, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 78, loss= 0.00293, NegPearson= 0.99828, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 79, loss= 0.00296, NegPearson= 0.99749, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 80, loss= 0.00315, NegPearson= 0.99760, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 81, loss= 0.00284, NegPearson= 0.99665, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 82, loss= 0.00283, NegPearson= 0.99579, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 83, loss= 0.00329, NegPearson= 0.99694, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 84, loss= 0.00301, NegPearson= 0.99709, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 85, loss= 0.00287, NegPearson= 0.99685, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 86, loss= 0.00316, NegPearson= 0.99788, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 87, loss= 0.00290, NegPearson= 0.99799, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 88, loss= 0.00296, NegPearson= 0.99850, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 89, loss= 0.00295, NegPearson= 0.99908, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 90, loss= 0.00294, NegPearson= 0.99976, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 91, loss= 0.00280, NegPearson= 0.99996, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 92, loss= 0.00282, NegPearson= 1.00036, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 93, loss= 0.00235, NegPearson= 0.99901, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 94, loss= 0.00303, NegPearson= 1.00049, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 95, loss= 0.00277, NegPearson= 1.00104, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 96, loss= 0.00278, NegPearson= 1.00174, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 97, loss= 0.00244, NegPearson= 1.00116, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 98, loss= 0.00255, NegPearson= 1.00115, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 99, loss= 0.00214, NegPearson= 0.99959, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 100, loss= 0.00270, NegPearson= 1.00039, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 101, loss= 0.00240, NegPearson= 1.00009, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 102, loss= 0.00226, NegPearson= 0.99934, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 103, loss= 0.00240, NegPearson= 0.99924, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 104, loss= 0.00225, NegPearson= 0.99862, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 105, loss= 0.00267, NegPearson= 0.99979, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 106, loss= 0.00247, NegPearson= 1.00026, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 107, loss= 0.00234, NegPearson= 1.00028, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 108, loss= 0.00226, NegPearson= 1.00006, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 109, loss= 0.00247, NegPearson= 1.00076, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 110, loss= 0.00244, NegPearson= 1.00144, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 111, loss= 0.00218, NegPearson= 1.00114, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 112, loss= 0.00220, NegPearson= 1.00099, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 113, loss= 0.00172, NegPearson= 0.99901, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 114, loss= 0.00223, NegPearson= 0.99917, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 115, loss= 0.00184, NegPearson= 0.99785, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 116, loss= 0.00193, NegPearson= 0.99696, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 117, loss= 0.00216, NegPearson= 0.99709, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 118, loss= 0.00188, NegPearson= 0.99615, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 119, loss= 0.00194, NegPearson= 0.99554, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 120, loss= 0.00197, NegPearson= 0.99511, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 121, loss= 0.00188, NegPearson= 0.99440, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 122, loss= 0.00233, NegPearson= 0.99558, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 123, loss= 0.00209, NegPearson= 0.99586, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 124, loss= 0.00199, NegPearson= 0.99580, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 125, loss= 0.00203, NegPearson= 0.99594, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 126, loss= 0.00189, NegPearson= 0.99561, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 127, loss= 0.00196, NegPearson= 0.99561, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 128, loss= 0.00194, NegPearson= 0.99560, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 129, loss= 0.00197, NegPearson= 0.99575, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 130, loss= 0.00188, NegPearson= 0.99559, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 131, loss= 0.00179, NegPearson= 0.99517, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 132, loss= 0.00194, NegPearson= 0.99540, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 133, loss= 0.00203, NegPearson= 0.99602, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 134, loss= 0.00201, NegPearson= 0.99664, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 135, loss= 0.00170, NegPearson= 0.99607, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 136, loss= 0.00188, NegPearson= 0.99626, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 137, loss= 0.00183, NegPearson= 0.99631, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 138, loss= 0.00180, NegPearson= 0.99630, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 139, loss= 0.00193, NegPearson= 0.99686, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 140, loss= 0.00186, NegPearson= 0.99717, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 141, loss= 0.00182, NegPearson= 0.99740, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 142, loss= 0.00177, NegPearson= 0.99746, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 143, loss= 0.00185, NegPearson= 0.99789, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 144, loss= 0.00191, NegPearson= 0.99859, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 145, loss= 0.00182, NegPearson= 0.99899, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 146, loss= 0.00158, NegPearson= 0.99847, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 147, loss= 0.00164, NegPearson= 0.99824, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 148, loss= 0.00171, NegPearson= 0.99834, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 149, loss= 0.00149, NegPearson= 0.99760, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 150, loss= 0.00171, NegPearson= 0.99780, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 151, loss= 0.00159, NegPearson= 0.99754, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 152, loss= 0.00164, NegPearson= 0.99754, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 153, loss= 0.00160, NegPearson= 0.99741, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 154, loss= 0.00157, NegPearson= 0.99724, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 155, loss= 0.00160, NegPearson= 0.99718, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 156, loss= 0.00158, NegPearson= 0.99711, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 157, loss= 0.00156, NegPearson= 0.99699, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 158, loss= 0.00172, NegPearson= 0.99756, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 159, loss= 0.00159, NegPearson= 0.99766, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 160, loss= 0.00147, NegPearson= 0.99729, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 161, loss= 0.00139, NegPearson= 0.99665, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 162, loss= 0.00149, NegPearson= 0.99645, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 163, loss= 0.00152, NegPearson= 0.99640, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 164, loss= 0.00158, NegPearson= 0.99666, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 165, loss= 0.00166, NegPearson= 0.99727, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 166, loss= 0.00125, NegPearson= 0.99624, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 167, loss= 0.00140, NegPearson= 0.99587, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 168, loss= 0.00154, NegPearson= 0.99612, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 169, loss= 0.00143, NegPearson= 0.99594, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 170, loss= 0.00156, NegPearson= 0.99634, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 171, loss= 0.00129, NegPearson= 0.99568, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 172, loss= 0.00153, NegPearson= 0.99602, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 173, loss= 0.00139, NegPearson= 0.99583, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 174, loss= 0.00143, NegPearson= 0.99583, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 175, loss= 0.00154, NegPearson= 0.99631, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 176, loss= 0.00147, NegPearson= 0.99654, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 177, loss= 0.00140, NegPearson= 0.99649, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 178, loss= 0.00147, NegPearson= 0.99677, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 179, loss= 0.00161, NegPearson= 0.99763, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 180, loss= 0.00137, NegPearson= 0.99759, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 181, loss= 0.00149, NegPearson= 0.99802, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 182, loss= 0.00132, NegPearson= 0.99782, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 183, loss= 0.00133, NegPearson= 0.99767, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 184, loss= 0.00130, NegPearson= 0.99746, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 185, loss= 0.00142, NegPearson= 0.99775, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 186, loss= 0.00123, NegPearson= 0.99729, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 187, loss= 0.00135, NegPearson= 0.99736, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 188, loss= 0.00126, NegPearson= 0.99709, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 189, loss= 0.00115, NegPearson= 0.99643, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 190, loss= 0.00137, NegPearson= 0.99668, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 191, loss= 0.00137, NegPearson= 0.99694, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 192, loss= 0.00119, NegPearson= 0.99650, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 193, loss= 0.00123, NegPearson= 0.99628, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 194, loss= 0.00124, NegPearson= 0.99608, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 195, loss= 0.00129, NegPearson= 0.99613, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 196, loss= 0.00130, NegPearson= 0.99627, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 197, loss= 0.00137, NegPearson= 0.99667, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 198, loss= 0.00118, NegPearson= 0.99638, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 199, loss= 0.00128, NegPearson= 0.99649, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 200, loss= 0.00114, NegPearson= 0.99607, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 201, loss= 0.00134, NegPearson= 0.99647, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 202, loss= 0.00124, NegPearson= 0.99650, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 203, loss= 0.00122, NegPearson= 0.99648, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 204, loss= 0.00119, NegPearson= 0.99638, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 205, loss= 0.00107, NegPearson= 0.99579, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 206, loss= 0.00130, NegPearson= 0.99616, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 207, loss= 0.00126, NegPearson= 0.99640, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 208, loss= 0.00136, NegPearson= 0.99705, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 209, loss= 0.00106, NegPearson= 0.99652, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 210, loss= 0.00108, NegPearson= 0.99607, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 211, loss= 0.00114, NegPearson= 0.99592, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 212, loss= 0.00115, NegPearson= 0.99584, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 213, loss= 0.00112, NegPearson= 0.99566, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 214, loss= 0.00115, NegPearson= 0.99560, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 215, loss= 0.00112, NegPearson= 0.99545, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 216, loss= 0.00121, NegPearson= 0.99566, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 217, loss= 0.00124, NegPearson= 0.99602, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 218, loss= 0.00116, NegPearson= 0.99610, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 219, loss= 0.00103, NegPearson= 0.99566, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 220, loss= 0.00101, NegPearson= 0.99517, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 221, loss= 0.00114, NegPearson= 0.99524, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 222, loss= 0.00110, NegPearson= 0.99514, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 223, loss= 0.00110, NegPearson= 0.99507, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 224, loss= 0.00112, NegPearson= 0.99511, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 225, loss= 0.00129, NegPearson= 0.99583, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 226, loss= 0.00113, NegPearson= 0.99592, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 227, loss= 0.00111, NegPearson= 0.99599, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 228, loss= 0.00110, NegPearson= 0.99602, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 229, loss= 0.00108, NegPearson= 0.99597, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 230, loss= 0.00106, NegPearson= 0.99589, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 231, loss= 0.00114, NegPearson= 0.99615, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 232, loss= 0.00110, NegPearson= 0.99626, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 233, loss= 0.00109, NegPearson= 0.99633, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 234, loss= 0.00108, NegPearson= 0.99638, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 235, loss= 0.00120, NegPearson= 0.99693, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 236, loss= 0.00109, NegPearson= 0.99706, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 237, loss= 0.00098, NegPearson= 0.99678, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 238, loss= 0.00117, NegPearson= 0.99726, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 239, loss= 0.00101, NegPearson= 0.99711, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 240, loss= 0.00099, NegPearson= 0.99691, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 241, loss= 0.00108, NegPearson= 0.99707, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 242, loss= 0.00102, NegPearson= 0.99704, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 243, loss= 0.00101, NegPearson= 0.99696, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 244, loss= 0.00107, NegPearson= 0.99713, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 245, loss= 0.00102, NegPearson= 0.99714, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 246, loss= 0.00095, NegPearson= 0.99687, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 247, loss= 0.00109, NegPearson= 0.99718, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 248, loss= 0.00102, NegPearson= 0.99725, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 249, loss= 0.00102, NegPearson= 0.99731, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 250, loss= 0.00098, NegPearson= 0.99723, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 251, loss= 0.00092, NegPearson= 0.99692, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 252, loss= 0.00102, NegPearson= 0.99703, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 253, loss= 0.00109, NegPearson= 0.99747, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 254, loss= 0.00112, NegPearson= 0.99801, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 255, loss= 0.00089, NegPearson= 0.99765, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 256, loss= 0.00101, NegPearson= 0.99780, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 257, loss= 0.00099, NegPearson= 0.99787, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 258, loss= 0.00088, NegPearson= 0.99751, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 259, loss= 0.00101, NegPearson= 0.99769, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 260, loss= 0.00098, NegPearson= 0.99777, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 261, loss= 0.00090, NegPearson= 0.99755, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 262, loss= 0.00099, NegPearson= 0.99771, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 263, loss= 0.00087, NegPearson= 0.99739, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 264, loss= 0.00087, NegPearson= 0.99711, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 265, loss= 0.00094, NegPearson= 0.99711, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 266, loss= 0.00087, NegPearson= 0.99684, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 267, loss= 0.00093, NegPearson= 0.99682, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 268, loss= 0.00082, NegPearson= 0.99639, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 269, loss= 0.00086, NegPearson= 0.99612, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 270, loss= 0.00097, NegPearson= 0.99629, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 271, loss= 0.00100, NegPearson= 0.99664, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 272, loss= 0.00102, NegPearson= 0.99705, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 273, loss= 0.00083, NegPearson= 0.99670, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 274, loss= 0.00085, NegPearson= 0.99648, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 275, loss= 0.00090, NegPearson= 0.99647, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 276, loss= 0.00084, NegPearson= 0.99623, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 277, loss= 0.00087, NegPearson= 0.99611, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 278, loss= 0.00080, NegPearson= 0.99571, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 279, loss= 0.00084, NegPearson= 0.99549, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 280, loss= 0.00094, NegPearson= 0.99571, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 281, loss= 0.00085, NegPearson= 0.99555, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 282, loss= 0.00093, NegPearson= 0.99572, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 283, loss= 0.00090, NegPearson= 0.99580, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 284, loss= 0.00090, NegPearson= 0.99588, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 285, loss= 0.00093, NegPearson= 0.99609, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 286, loss= 0.00094, NegPearson= 0.99638, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 287, loss= 0.00096, NegPearson= 0.99674, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 288, loss= 0.00085, NegPearson= 0.99668, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 289, loss= 0.00091, NegPearson= 0.99686, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 290, loss= 0.00080, NegPearson= 0.99664, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 291, loss= 0.00085, NegPearson= 0.99663, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 292, loss= 0.00086, NegPearson= 0.99665, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 293, loss= 0.00088, NegPearson= 0.99678, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 294, loss= 0.00087, NegPearson= 0.99689, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 295, loss= 0.00086, NegPearson= 0.99695, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 296, loss= 0.00078, NegPearson= 0.99670, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 297, loss= 0.00081, NegPearson= 0.99659, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 298, loss= 0.00080, NegPearson= 0.99643, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 299, loss= 0.00086, NegPearson= 0.99653, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 300, loss= 0.00084, NegPearson= 0.99655, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 301, loss= 0.00084, NegPearson= 0.99659, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 302, loss= 0.00086, NegPearson= 0.99674, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 303, loss= 0.00081, NegPearson= 0.99671, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 304, loss= 0.00081, NegPearson= 0.99667, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 305, loss= 0.00077, NegPearson= 0.99649, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 306, loss= 0.00083, NegPearson= 0.99657, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 307, loss= 0.00085, NegPearson= 0.99672, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 308, loss= 0.00074, NegPearson= 0.99645, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 309, loss= 0.00071, NegPearson= 0.99607, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 310, loss= 0.00086, NegPearson= 0.99629, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 311, loss= 0.00075, NegPearson= 0.99608, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 312, loss= 0.00081, NegPearson= 0.99612, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 313, loss= 0.00083, NegPearson= 0.99624, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 314, loss= 0.00086, NegPearson= 0.99650, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 315, loss= 0.00079, NegPearson= 0.99651, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 316, loss= 0.00080, NegPearson= 0.99656, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 317, loss= 0.00083, NegPearson= 0.99676, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 318, loss= 0.00081, NegPearson= 0.99685, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 319, loss= 0.00073, NegPearson= 0.99663, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 320, loss= 0.00069, NegPearson= 0.99626, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 321, loss= 0.00078, NegPearson= 0.99626, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 322, loss= 0.00074, NegPearson= 0.99612, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 323, loss= 0.00072, NegPearson= 0.99592, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 324, loss= 0.00080, NegPearson= 0.99606, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 325, loss= 0.00078, NegPearson= 0.99612, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 326, loss= 0.00080, NegPearson= 0.99628, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 327, loss= 0.00071, NegPearson= 0.99606, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 328, loss= 0.00073, NegPearson= 0.99594, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 329, loss= 0.00072, NegPearson= 0.99579, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 330, loss= 0.00076, NegPearson= 0.99583, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 331, loss= 0.00077, NegPearson= 0.99589, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 332, loss= 0.00080, NegPearson= 0.99611, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 333, loss= 0.00075, NegPearson= 0.99610, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 334, loss= 0.00084, NegPearson= 0.99646, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 335, loss= 0.00073, NegPearson= 0.99640, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 336, loss= 0.00074, NegPearson= 0.99638, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 337, loss= 0.00068, NegPearson= 0.99616, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 338, loss= 0.00074, NegPearson= 0.99619, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 339, loss= 0.00070, NegPearson= 0.99605, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 340, loss= 0.00072, NegPearson= 0.99600, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 341, loss= 0.00081, NegPearson= 0.99631, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 342, loss= 0.00069, NegPearson= 0.99616, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 343, loss= 0.00074, NegPearson= 0.99620, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 344, loss= 0.00081, NegPearson= 0.99655, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 345, loss= 0.00060, NegPearson= 0.99608, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 346, loss= 0.00073, NegPearson= 0.99613, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 347, loss= 0.00068, NegPearson= 0.99597, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 348, loss= 0.00072, NegPearson= 0.99600, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 349, loss= 0.00075, NegPearson= 0.99616, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 350, loss= 0.00074, NegPearson= 0.99627, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 351, loss= 0.00067, NegPearson= 0.99611, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 352, loss= 0.00077, NegPearson= 0.99636, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 353, loss= 0.00070, NegPearson= 0.99635, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 354, loss= 0.00071, NegPearson= 0.99638, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 355, loss= 0.00080, NegPearson= 0.99677, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 356, loss= 0.00073, NegPearson= 0.99688, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 357, loss= 0.00066, NegPearson= 0.99673, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 358, loss= 0.00074, NegPearson= 0.99690, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 359, loss= 0.00077, NegPearson= 0.99720, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 360, loss= 0.00063, NegPearson= 0.99695, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 361, loss= 0.00064, NegPearson= 0.99676, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 362, loss= 0.00067, NegPearson= 0.99671, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 363, loss= 0.00076, NegPearson= 0.99701, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 364, loss= 0.00071, NegPearson= 0.99713, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 365, loss= 0.00073, NegPearson= 0.99731, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 366, loss= 0.00066, NegPearson= 0.99723, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 367, loss= 0.00078, NegPearson= 0.99762, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 368, loss= 0.00069, NegPearson= 0.99767, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 369, loss= 0.00074, NegPearson= 0.99791, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 370, loss= 0.00063, NegPearson= 0.99772, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 371, loss= 0.00062, NegPearson= 0.99751, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 372, loss= 0.00065, NegPearson= 0.99743, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 373, loss= 0.00065, NegPearson= 0.99735, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 374, loss= 0.00073, NegPearson= 0.99760, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 375, loss= 0.00060, NegPearson= 0.99736, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 376, loss= 0.00062, NegPearson= 0.99718, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 377, loss= 0.00060, NegPearson= 0.99693, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 378, loss= 0.00063, NegPearson= 0.99683, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 379, loss= 0.00066, NegPearson= 0.99684, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 380, loss= 0.00065, NegPearson= 0.99683, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 381, loss= 0.00067, NegPearson= 0.99691, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 382, loss= 0.00069, NegPearson= 0.99704, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 383, loss= 0.00066, NegPearson= 0.99706, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 384, loss= 0.00072, NegPearson= 0.99732, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 385, loss= 0.00067, NegPearson= 0.99743, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 386, loss= 0.00065, NegPearson= 0.99745, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 387, loss= 0.00065, NegPearson= 0.99747, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 388, loss= 0.00065, NegPearson= 0.99751, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 389, loss= 0.00065, NegPearson= 0.99754, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 390, loss= 0.00060, NegPearson= 0.99739, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 391, loss= 0.00061, NegPearson= 0.99729, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 392, loss= 0.00061, NegPearson= 0.99719, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 393, loss= 0.00067, NegPearson= 0.99734, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 394, loss= 0.00063, NegPearson= 0.99732, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 395, loss= 0.00062, NegPearson= 0.99729, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 396, loss= 0.00066, NegPearson= 0.99743, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 397, loss= 0.00067, NegPearson= 0.99758, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 398, loss= 0.00061, NegPearson= 0.99751, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 399, loss= 0.00060, NegPearson= 0.99742, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 400, loss= 0.00066, NegPearson= 0.99755, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 401, loss= 0.00061, NegPearson= 0.99749, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 402, loss= 0.00069, NegPearson= 0.99775, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 403, loss= 0.00061, NegPearson= 0.99770, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 404, loss= 0.00063, NegPearson= 0.99775, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 405, loss= 0.00066, NegPearson= 0.99793, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 406, loss= 0.00062, NegPearson= 0.99794, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 407, loss= 0.00063, NegPearson= 0.99802, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 408, loss= 0.00065, NegPearson= 0.99819, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 409, loss= 0.00073, NegPearson= 0.99865, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 410, loss= 0.00062, NegPearson= 0.99869, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 411, loss= 0.00060, NegPearson= 0.99866, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 412, loss= 0.00055, NegPearson= 0.99843, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 413, loss= 0.00057, NegPearson= 0.99831, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 414, loss= 0.00058, NegPearson= 0.99820, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 415, loss= 0.00060, NegPearson= 0.99818, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 416, loss= 0.00060, NegPearson= 0.99820, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 417, loss= 0.00064, NegPearson= 0.99838, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 418, loss= 0.00061, NegPearson= 0.99842, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 419, loss= 0.00057, NegPearson= 0.99830, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 420, loss= 0.00059, NegPearson= 0.99829, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 421, loss= 0.00059, NegPearson= 0.99827, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 422, loss= 0.00064, NegPearson= 0.99848, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 423, loss= 0.00063, NegPearson= 0.99865, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 424, loss= 0.00059, NegPearson= 0.99866, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 425, loss= 0.00057, NegPearson= 0.99857, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 426, loss= 0.00061, NegPearson= 0.99865, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 427, loss= 0.00063, NegPearson= 0.99883, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 428, loss= 0.00055, NegPearson= 0.99870, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 429, loss= 0.00057, NegPearson= 0.99865, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 430, loss= 0.00060, NegPearson= 0.99873, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 431, loss= 0.00055, NegPearson= 0.99860, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 432, loss= 0.00060, NegPearson= 0.99869, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 433, loss= 0.00061, NegPearson= 0.99884, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 434, loss= 0.00060, NegPearson= 0.99895, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 435, loss= 0.00062, NegPearson= 0.99912, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 436, loss= 0.00056, NegPearson= 0.99907, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 437, loss= 0.00064, NegPearson= 0.99933, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 438, loss= 0.00057, NegPearson= 0.99934, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 439, loss= 0.00065, NegPearson= 0.99965, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 440, loss= 0.00058, NegPearson= 0.99971, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 441, loss= 0.00051, NegPearson= 0.99949, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 442, loss= 0.00053, NegPearson= 0.99935, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 443, loss= 0.00060, NegPearson= 0.99952, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 444, loss= 0.00057, NegPearson= 0.99956, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 445, loss= 0.00050, NegPearson= 0.99933, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 446, loss= 0.00053, NegPearson= 0.99923, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 447, loss= 0.00053, NegPearson= 0.99913, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 448, loss= 0.00053, NegPearson= 0.99902, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 449, loss= 0.00060, NegPearson= 0.99921, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 450, loss= 0.00055, NegPearson= 0.99917, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 451, loss= 0.00055, NegPearson= 0.99914, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 452, loss= 0.00057, NegPearson= 0.99921, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 453, loss= 0.00065, NegPearson= 0.99961, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 454, loss= 0.00052, NegPearson= 0.99949, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 455, loss= 0.00053, NegPearson= 0.99942, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 456, loss= 0.00059, NegPearson= 0.99960, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 457, loss= 0.00056, NegPearson= 0.99966, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 458, loss= 0.00055, NegPearson= 0.99966, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 459, loss= 0.00051, NegPearson= 0.99951, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 460, loss= 0.00054, NegPearson= 0.99951, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 461, loss= 0.00055, NegPearson= 0.99956, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 462, loss= 0.00060, NegPearson= 0.99977, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 463, loss= 0.00046, NegPearson= 0.99947, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 464, loss= 0.00062, NegPearson= 0.99979, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 465, loss= 0.00058, NegPearson= 0.99997, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 466, loss= 0.00056, NegPearson= 1.00007, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 467, loss= 0.00053, NegPearson= 1.00005, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 468, loss= 0.00054, NegPearson= 1.00007, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 469, loss= 0.00047, NegPearson= 0.99981, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 470, loss= 0.00051, NegPearson= 0.99972, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 471, loss= 0.00056, NegPearson= 0.99985, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 472, loss= 0.00051, NegPearson= 0.99977, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 473, loss= 0.00058, NegPearson= 0.99995, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 474, loss= 0.00052, NegPearson= 0.99993, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 475, loss= 0.00053, NegPearson= 0.99996, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 476, loss= 0.00053, NegPearson= 0.99997, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 477, loss= 0.00053, NegPearson= 0.99999, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 478, loss= 0.00054, NegPearson= 1.00004, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 479, loss= 0.00053, NegPearson= 1.00008, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 480, loss= 0.00056, NegPearson= 1.00022, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 481, loss= 0.00051, NegPearson= 1.00019, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 482, loss= 0.00056, NegPearson= 1.00034, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 483, loss= 0.00055, NegPearson= 1.00047, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 484, loss= 0.00050, NegPearson= 1.00039, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 485, loss= 0.00048, NegPearson= 1.00024, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 486, loss= 0.00051, NegPearson= 1.00023, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 487, loss= 0.00052, NegPearson= 1.00025, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 488, loss= 0.00047, NegPearson= 1.00007, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 489, loss= 0.00047, NegPearson= 0.99992, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 490, loss= 0.00056, NegPearson= 1.00011, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 491, loss= 0.00048, NegPearson= 1.00001, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 492, loss= 0.00050, NegPearson= 0.99999, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 493, loss= 0.00049, NegPearson= 0.99994, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 494, loss= 0.00048, NegPearson= 0.99984, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 495, loss= 0.00045, NegPearson= 0.99962, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 496, loss= 0.00049, NegPearson= 0.99958, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 497, loss= 0.00043, NegPearson= 0.99929, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 498, loss= 0.00049, NegPearson= 0.99924, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 499, loss= 0.00051, NegPearson= 0.99926, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 500, loss= 0.00051, NegPearson= 0.99930, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 501, loss= 0.00051, NegPearson= 0.99936, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 502, loss= 0.00047, NegPearson= 0.99926, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 503, loss= 0.00051, NegPearson= 0.99933, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 504, loss= 0.00047, NegPearson= 0.99921, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 505, loss= 0.00047, NegPearson= 0.99912, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 506, loss= 0.00042, NegPearson= 0.99882, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 507, loss= 0.00050, NegPearson= 0.99883, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 508, loss= 0.00047, NegPearson= 0.99873, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 509, loss= 0.00049, NegPearson= 0.99874, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 510, loss= 0.00051, NegPearson= 0.99881, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 511, loss= 0.00054, NegPearson= 0.99900, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 512, loss= 0.00045, NegPearson= 0.99885, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 513, loss= 0.00053, NegPearson= 0.99904, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 514, loss= 0.00044, NegPearson= 0.99885, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 515, loss= 0.00044, NegPearson= 0.99867, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 516, loss= 0.00044, NegPearson= 0.99851, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 517, loss= 0.00052, NegPearson= 0.99867, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 518, loss= 0.00048, NegPearson= 0.99866, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 519, loss= 0.00049, NegPearson= 0.99871, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 520, loss= 0.00053, NegPearson= 0.99892, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 521, loss= 0.00053, NegPearson= 0.99910, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 522, loss= 0.00051, NegPearson= 0.99924, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 523, loss= 0.00050, NegPearson= 0.99932, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 524, loss= 0.00037, NegPearson= 0.99891, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 525, loss= 0.00047, NegPearson= 0.99887, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 526, loss= 0.00045, NegPearson= 0.99876, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 527, loss= 0.00051, NegPearson= 0.99891, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 528, loss= 0.00047, NegPearson= 0.99890, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 529, loss= 0.00038, NegPearson= 0.99855, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 530, loss= 0.00047, NegPearson= 0.99854, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 531, loss= 0.00048, NegPearson= 0.99856, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 532, loss= 0.00041, NegPearson= 0.99833, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 533, loss= 0.00049, NegPearson= 0.99842, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 534, loss= 0.00052, NegPearson= 0.99861, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 535, loss= 0.00051, NegPearson= 0.99880, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 536, loss= 0.00098, NegPearson= 0.99884, kl= 0.00000, fre_CEloss= 0.00000\n",
      "Starting epoch 2\n",
      "\n",
      "\n",
      "Iteration 1, loss= 0.28243, NegPearson= 1.12971, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 2, loss= 0.12669, NegPearson= 1.07161, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 3, loss= 0.07503, NegPearson= 1.01453, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 4, loss= 0.06637, NegPearson= 1.02636, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 5, loss= 0.04802, NegPearson= 1.01318, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 6, loss= 0.04192, NegPearson= 1.01199, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 7, loss= 0.03494, NegPearson= 1.00719, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 8, loss= 0.03046, NegPearson= 1.00312, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 9, loss= 0.02870, NegPearson= 1.00647, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 10, loss= 0.02429, NegPearson= 1.00299, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 11, loss= 0.02363, NegPearson= 1.00633, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 12, loss= 0.02059, NegPearson= 1.00483, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 13, loss= 0.01976, NegPearson= 1.00659, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 14, loss= 0.01876, NegPearson= 1.00974, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 15, loss= 0.01524, NegPearson= 1.00337, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 16, loss= 0.01425, NegPearson= 0.99765, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 17, loss= 0.01411, NegPearson= 0.99541, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 18, loss= 0.01332, NegPearson= 0.99341, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 19, loss= 0.01326, NegPearson= 0.99418, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 20, loss= 0.01283, NegPearson= 0.99580, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 21, loss= 0.01032, NegPearson= 0.98968, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 22, loss= 0.01031, NegPearson= 0.98591, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 23, loss= 0.01081, NegPearson= 0.98630, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 24, loss= 0.00953, NegPearson= 0.98334, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 25, loss= 0.00872, NegPearson= 0.97890, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 26, loss= 0.00939, NegPearson= 0.97882, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 27, loss= 0.00890, NegPearson= 0.97815, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 28, loss= 0.00876, NegPearson= 0.97826, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 29, loss= 0.00811, NegPearson= 0.97695, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 30, loss= 0.00884, NegPearson= 0.97975, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 31, loss= 0.00751, NegPearson= 0.97818, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 32, loss= 0.00735, NegPearson= 0.97702, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 33, loss= 0.00773, NegPearson= 0.97834, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 34, loss= 0.00778, NegPearson= 0.98067, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 35, loss= 0.00634, NegPearson= 0.97801, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 36, loss= 0.00660, NegPearson= 0.97725, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 37, loss= 0.00696, NegPearson= 0.97868, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 38, loss= 0.00580, NegPearson= 0.97611, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 39, loss= 0.00641, NegPearson= 0.97672, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 40, loss= 0.00604, NegPearson= 0.97645, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 41, loss= 0.00558, NegPearson= 0.97494, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 42, loss= 0.00585, NegPearson= 0.97514, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 43, loss= 0.00602, NegPearson= 0.97653, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 44, loss= 0.00540, NegPearson= 0.97594, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 45, loss= 0.00518, NegPearson= 0.97499, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 46, loss= 0.00580, NegPearson= 0.97699, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 47, loss= 0.00578, NegPearson= 0.97934, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 48, loss= 0.00504, NegPearson= 0.97908, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 49, loss= 0.00512, NegPearson= 0.97958, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 50, loss= 0.00513, NegPearson= 0.98051, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 51, loss= 0.00524, NegPearson= 0.98226, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 52, loss= 0.00464, NegPearson= 0.98194, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 53, loss= 0.00498, NegPearson= 0.98333, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 54, loss= 0.00479, NegPearson= 0.98429, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 55, loss= 0.00502, NegPearson= 0.98648, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 56, loss= 0.00450, NegPearson= 0.98686, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 57, loss= 0.00417, NegPearson= 0.98623, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 58, loss= 0.00399, NegPearson= 0.98518, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 59, loss= 0.00422, NegPearson= 0.98538, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 60, loss= 0.00439, NegPearson= 0.98651, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 61, loss= 0.00414, NegPearson= 0.98689, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 62, loss= 0.00379, NegPearson= 0.98613, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 63, loss= 0.00383, NegPearson= 0.98579, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 64, loss= 0.00422, NegPearson= 0.98727, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 65, loss= 0.00387, NegPearson= 0.98755, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 66, loss= 0.00360, NegPearson= 0.98698, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 67, loss= 0.00343, NegPearson= 0.98595, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 68, loss= 0.00323, NegPearson= 0.98438, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 69, loss= 0.00359, NegPearson= 0.98450, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 70, loss= 0.00360, NegPearson= 0.98481, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 71, loss= 0.00366, NegPearson= 0.98559, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 72, loss= 0.00318, NegPearson= 0.98460, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 73, loss= 0.00335, NegPearson= 0.98452, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 74, loss= 0.00358, NegPearson= 0.98554, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 75, loss= 0.00330, NegPearson= 0.98559, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 76, loss= 0.00322, NegPearson= 0.98550, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 77, loss= 0.00330, NegPearson= 0.98590, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 78, loss= 0.00313, NegPearson= 0.98579, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 79, loss= 0.00327, NegPearson= 0.98640, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 80, loss= 0.00298, NegPearson= 0.98599, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 81, loss= 0.00292, NegPearson= 0.98550, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 82, loss= 0.00283, NegPearson= 0.98481, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 83, loss= 0.00302, NegPearson= 0.98500, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 84, loss= 0.00297, NegPearson= 0.98514, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 85, loss= 0.00313, NegPearson= 0.98606, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 86, loss= 0.00298, NegPearson= 0.98652, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 87, loss= 0.00279, NegPearson= 0.98635, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 88, loss= 0.00295, NegPearson= 0.98692, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 89, loss= 0.00265, NegPearson= 0.98644, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 90, loss= 0.00276, NegPearson= 0.98651, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 91, loss= 0.00289, NegPearson= 0.98724, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 92, loss= 0.00261, NegPearson= 0.98696, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 93, loss= 0.00270, NegPearson= 0.98716, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 94, loss= 0.00265, NegPearson= 0.98727, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 95, loss= 0.00279, NegPearson= 0.98802, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 96, loss= 0.00281, NegPearson= 0.98898, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 97, loss= 0.00254, NegPearson= 0.98893, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 98, loss= 0.00264, NegPearson= 0.98939, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 99, loss= 0.00263, NegPearson= 0.98992, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 100, loss= 0.00240, NegPearson= 0.98964, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 101, loss= 0.00240, NegPearson= 0.98944, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 102, loss= 0.00245, NegPearson= 0.98955, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 103, loss= 0.00265, NegPearson= 0.99055, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 104, loss= 0.00240, NegPearson= 0.99065, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 105, loss= 0.00213, NegPearson= 0.98975, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 106, loss= 0.00204, NegPearson= 0.98859, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 107, loss= 0.00226, NegPearson= 0.98837, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 108, loss= 0.00234, NegPearson= 0.98859, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 109, loss= 0.00236, NegPearson= 0.98897, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 110, loss= 0.00202, NegPearson= 0.98807, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 111, loss= 0.00242, NegPearson= 0.98883, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 112, loss= 0.00239, NegPearson= 0.98956, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 113, loss= 0.00237, NegPearson= 0.99028, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 114, loss= 0.00229, NegPearson= 0.99074, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 115, loss= 0.00240, NegPearson= 0.99173, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 116, loss= 0.00205, NegPearson= 0.99136, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 117, loss= 0.00212, NegPearson= 0.99135, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 118, loss= 0.00213, NegPearson= 0.99148, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 119, loss= 0.00212, NegPearson= 0.99161, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 120, loss= 0.00195, NegPearson= 0.99113, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 121, loss= 0.00228, NegPearson= 0.99205, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 122, loss= 0.00209, NegPearson= 0.99228, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 123, loss= 0.00210, NegPearson= 0.99260, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 124, loss= 0.00205, NegPearson= 0.99281, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 125, loss= 0.00187, NegPearson= 0.99236, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 126, loss= 0.00187, NegPearson= 0.99195, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 127, loss= 0.00168, NegPearson= 0.99084, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 128, loss= 0.00209, NegPearson= 0.99146, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 129, loss= 0.00188, NegPearson= 0.99128, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 130, loss= 0.00196, NegPearson= 0.99149, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 131, loss= 0.00210, NegPearson= 0.99234, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 132, loss= 0.00178, NegPearson= 0.99193, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 133, loss= 0.00199, NegPearson= 0.99244, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 134, loss= 0.00209, NegPearson= 0.99341, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 135, loss= 0.00183, NegPearson= 0.99338, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 136, loss= 0.00173, NegPearson= 0.99301, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 137, loss= 0.00195, NegPearson= 0.99358, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 138, loss= 0.00195, NegPearson= 0.99417, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 139, loss= 0.00179, NegPearson= 0.99419, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 140, loss= 0.00171, NegPearson= 0.99392, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 141, loss= 0.00198, NegPearson= 0.99477, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 142, loss= 0.00192, NegPearson= 0.99546, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 143, loss= 0.00179, NegPearson= 0.99567, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 144, loss= 0.00169, NegPearson= 0.99552, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 145, loss= 0.00181, NegPearson= 0.99590, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 146, loss= 0.00183, NegPearson= 0.99639, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 147, loss= 0.00168, NegPearson= 0.99635, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 148, loss= 0.00186, NegPearson= 0.99706, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 149, loss= 0.00171, NegPearson= 0.99722, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 150, loss= 0.00161, NegPearson= 0.99702, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 151, loss= 0.00182, NegPearson= 0.99772, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 152, loss= 0.00158, NegPearson= 0.99747, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 153, loss= 0.00171, NegPearson= 0.99781, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 154, loss= 0.00178, NegPearson= 0.99844, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 155, loss= 0.00158, NegPearson= 0.99833, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 156, loss= 0.00169, NegPearson= 0.99870, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 157, loss= 0.00158, NegPearson= 0.99867, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 158, loss= 0.00170, NegPearson= 0.99914, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 159, loss= 0.00142, NegPearson= 0.99852, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 160, loss= 0.00144, NegPearson= 0.99804, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 161, loss= 0.00156, NegPearson= 0.99807, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 162, loss= 0.00164, NegPearson= 0.99847, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 163, loss= 0.00174, NegPearson= 0.99932, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 164, loss= 0.00141, NegPearson= 0.99888, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 165, loss= 0.00163, NegPearson= 0.99935, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 166, loss= 0.00135, NegPearson= 0.99875, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 167, loss= 0.00148, NegPearson= 0.99871, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 168, loss= 0.00155, NegPearson= 0.99894, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 169, loss= 0.00158, NegPearson= 0.99933, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 170, loss= 0.00149, NegPearson= 0.99942, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 171, loss= 0.00132, NegPearson= 0.99886, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 172, loss= 0.00152, NegPearson= 0.99915, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 173, loss= 0.00142, NegPearson= 0.99907, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 174, loss= 0.00138, NegPearson= 0.99883, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 175, loss= 0.00122, NegPearson= 0.99801, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 176, loss= 0.00139, NegPearson= 0.99789, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 177, loss= 0.00127, NegPearson= 0.99734, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 178, loss= 0.00143, NegPearson= 0.99745, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 179, loss= 0.00129, NegPearson= 0.99704, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 180, loss= 0.00151, NegPearson= 0.99753, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 181, loss= 0.00129, NegPearson= 0.99719, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 182, loss= 0.00133, NegPearson= 0.99702, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 183, loss= 0.00123, NegPearson= 0.99650, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 184, loss= 0.00144, NegPearson= 0.99684, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 185, loss= 0.00135, NegPearson= 0.99686, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 186, loss= 0.00139, NegPearson= 0.99707, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 187, loss= 0.00135, NegPearson= 0.99714, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 188, loss= 0.00132, NegPearson= 0.99710, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 189, loss= 0.00142, NegPearson= 0.99752, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 190, loss= 0.00136, NegPearson= 0.99772, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 191, loss= 0.00144, NegPearson= 0.99826, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 192, loss= 0.00140, NegPearson= 0.99865, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 193, loss= 0.00128, NegPearson= 0.99859, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 194, loss= 0.00133, NegPearson= 0.99876, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 195, loss= 0.00134, NegPearson= 0.99899, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 196, loss= 0.00137, NegPearson= 0.99937, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 197, loss= 0.00127, NegPearson= 0.99936, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 198, loss= 0.00128, NegPearson= 0.99946, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 199, loss= 0.00119, NegPearson= 0.99921, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 200, loss= 0.00129, NegPearson= 0.99938, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 201, loss= 0.00122, NegPearson= 0.99930, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 202, loss= 0.00131, NegPearson= 0.99960, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 203, loss= 0.00130, NegPearson= 0.99988, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 204, loss= 0.00118, NegPearson= 0.99969, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 205, loss= 0.00123, NegPearson= 0.99974, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 206, loss= 0.00121, NegPearson= 0.99973, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 207, loss= 0.00121, NegPearson= 0.99974, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 208, loss= 0.00127, NegPearson= 1.00004, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 209, loss= 0.00116, NegPearson= 0.99990, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 210, loss= 0.00135, NegPearson= 1.00052, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 211, loss= 0.00129, NegPearson= 1.00096, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 212, loss= 0.00106, NegPearson= 1.00050, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 213, loss= 0.00130, NegPearson= 1.00101, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 214, loss= 0.00119, NegPearson= 1.00111, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 215, loss= 0.00126, NegPearson= 1.00148, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 216, loss= 0.00120, NegPearson= 1.00166, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 217, loss= 0.00102, NegPearson= 1.00113, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 218, loss= 0.00106, NegPearson= 1.00080, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 219, loss= 0.00125, NegPearson= 1.00123, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 220, loss= 0.00113, NegPearson= 1.00121, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 221, loss= 0.00110, NegPearson= 1.00106, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 222, loss= 0.00110, NegPearson= 1.00094, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 223, loss= 0.00120, NegPearson= 1.00124, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 224, loss= 0.00116, NegPearson= 1.00141, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 225, loss= 0.00111, NegPearson= 1.00140, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 226, loss= 0.00114, NegPearson= 1.00153, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 227, loss= 0.00096, NegPearson= 1.00095, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 228, loss= 0.00102, NegPearson= 1.00063, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 229, loss= 0.00124, NegPearson= 1.00121, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 230, loss= 0.00117, NegPearson= 1.00152, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 231, loss= 0.00104, NegPearson= 1.00132, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 232, loss= 0.00110, NegPearson= 1.00142, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 233, loss= 0.00107, NegPearson= 1.00141, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 234, loss= 0.00105, NegPearson= 1.00135, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 235, loss= 0.00111, NegPearson= 1.00153, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 236, loss= 0.00095, NegPearson= 1.00109, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 237, loss= 0.00108, NegPearson= 1.00120, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 238, loss= 0.00099, NegPearson= 1.00097, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 239, loss= 0.00098, NegPearson= 1.00072, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 240, loss= 0.00100, NegPearson= 1.00055, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 241, loss= 0.00109, NegPearson= 1.00076, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 242, loss= 0.00102, NegPearson= 1.00070, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 243, loss= 0.00095, NegPearson= 1.00039, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 244, loss= 0.00103, NegPearson= 1.00040, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 245, loss= 0.00097, NegPearson= 1.00019, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 246, loss= 0.00096, NegPearson= 0.99995, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 247, loss= 0.00100, NegPearson= 0.99989, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 248, loss= 0.00105, NegPearson= 1.00005, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 249, loss= 0.00094, NegPearson= 0.99981, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 250, loss= 0.00090, NegPearson= 0.99942, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 251, loss= 0.00101, NegPearson= 0.99948, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 252, loss= 0.00106, NegPearson= 0.99976, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 253, loss= 0.00095, NegPearson= 0.99961, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 254, loss= 0.00104, NegPearson= 0.99984, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 255, loss= 0.00100, NegPearson= 0.99994, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 256, loss= 0.00091, NegPearson= 0.99968, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 257, loss= 0.00093, NegPearson= 0.99953, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 258, loss= 0.00091, NegPearson= 0.99928, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 259, loss= 0.00094, NegPearson= 0.99918, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 260, loss= 0.00091, NegPearson= 0.99899, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 261, loss= 0.00097, NegPearson= 0.99907, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 262, loss= 0.00097, NegPearson= 0.99915, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 263, loss= 0.00082, NegPearson= 0.99864, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 264, loss= 0.00097, NegPearson= 0.99875, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 265, loss= 0.00096, NegPearson= 0.99882, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 266, loss= 0.00100, NegPearson= 0.99907, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 267, loss= 0.00103, NegPearson= 0.99945, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 268, loss= 0.00094, NegPearson= 0.99949, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 269, loss= 0.00096, NegPearson= 0.99960, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 270, loss= 0.00086, NegPearson= 0.99933, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 271, loss= 0.00087, NegPearson= 0.99912, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 272, loss= 0.00086, NegPearson= 0.99886, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 273, loss= 0.00098, NegPearson= 0.99914, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 274, loss= 0.00097, NegPearson= 0.99936, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 275, loss= 0.00096, NegPearson= 0.99955, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 276, loss= 0.00084, NegPearson= 0.99929, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 277, loss= 0.00088, NegPearson= 0.99921, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 278, loss= 0.00095, NegPearson= 0.99942, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 279, loss= 0.00084, NegPearson= 0.99920, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 280, loss= 0.00087, NegPearson= 0.99911, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 281, loss= 0.00085, NegPearson= 0.99894, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 282, loss= 0.00092, NegPearson= 0.99910, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 283, loss= 0.00078, NegPearson= 0.99867, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 284, loss= 0.00090, NegPearson= 0.99876, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 285, loss= 0.00087, NegPearson= 0.99875, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 286, loss= 0.00090, NegPearson= 0.99887, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 287, loss= 0.00080, NegPearson= 0.99860, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 288, loss= 0.00094, NegPearson= 0.99891, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 289, loss= 0.00088, NegPearson= 0.99899, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 290, loss= 0.00091, NegPearson= 0.99919, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 291, loss= 0.00083, NegPearson= 0.99907, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 292, loss= 0.00095, NegPearson= 0.99945, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 293, loss= 0.00076, NegPearson= 0.99910, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 294, loss= 0.00077, NegPearson= 0.99878, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 295, loss= 0.00089, NegPearson= 0.99894, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 296, loss= 0.00089, NegPearson= 0.99914, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 297, loss= 0.00085, NegPearson= 0.99919, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 298, loss= 0.00085, NegPearson= 0.99924, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 299, loss= 0.00089, NegPearson= 0.99947, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 300, loss= 0.00087, NegPearson= 0.99960, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 301, loss= 0.00081, NegPearson= 0.99952, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 302, loss= 0.00091, NegPearson= 0.99986, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 303, loss= 0.00085, NegPearson= 0.99996, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 304, loss= 0.00090, NegPearson= 1.00027, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 305, loss= 0.00082, NegPearson= 1.00026, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 306, loss= 0.00088, NegPearson= 1.00052, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 307, loss= 0.00075, NegPearson= 1.00027, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 308, loss= 0.00090, NegPearson= 1.00061, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 309, loss= 0.00071, NegPearson= 1.00022, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 310, loss= 0.00088, NegPearson= 1.00050, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 311, loss= 0.00075, NegPearson= 1.00029, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 312, loss= 0.00075, NegPearson= 1.00006, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 313, loss= 0.00080, NegPearson= 1.00008, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 314, loss= 0.00084, NegPearson= 1.00027, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 315, loss= 0.00082, NegPearson= 1.00036, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 316, loss= 0.00085, NegPearson= 1.00060, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 317, loss= 0.00081, NegPearson= 1.00067, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 318, loss= 0.00077, NegPearson= 1.00059, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 319, loss= 0.00073, NegPearson= 1.00036, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 320, loss= 0.00086, NegPearson= 1.00066, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 321, loss= 0.00073, NegPearson= 1.00046, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 322, loss= 0.00081, NegPearson= 1.00060, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 323, loss= 0.00083, NegPearson= 1.00084, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 324, loss= 0.00076, NegPearson= 1.00078, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 325, loss= 0.00080, NegPearson= 1.00088, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 326, loss= 0.00079, NegPearson= 1.00097, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 327, loss= 0.00079, NegPearson= 1.00106, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 328, loss= 0.00072, NegPearson= 1.00090, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 329, loss= 0.00082, NegPearson= 1.00114, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 330, loss= 0.00075, NegPearson= 1.00111, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 331, loss= 0.00075, NegPearson= 1.00107, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 332, loss= 0.00089, NegPearson= 1.00163, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 333, loss= 0.00075, NegPearson= 1.00163, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 334, loss= 0.00071, NegPearson= 1.00146, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 335, loss= 0.00080, NegPearson= 1.00168, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 336, loss= 0.00068, NegPearson= 1.00143, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 337, loss= 0.00069, NegPearson= 1.00122, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 338, loss= 0.00073, NegPearson= 1.00118, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 339, loss= 0.00074, NegPearson= 1.00120, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 340, loss= 0.00070, NegPearson= 1.00103, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 341, loss= 0.00075, NegPearson= 1.00110, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 342, loss= 0.00081, NegPearson= 1.00141, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 343, loss= 0.00072, NegPearson= 1.00136, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 344, loss= 0.00072, NegPearson= 1.00133, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 345, loss= 0.00074, NegPearson= 1.00139, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 346, loss= 0.00065, NegPearson= 1.00109, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 347, loss= 0.00069, NegPearson= 1.00095, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 348, loss= 0.00071, NegPearson= 1.00090, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 349, loss= 0.00068, NegPearson= 1.00075, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 350, loss= 0.00079, NegPearson= 1.00104, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 351, loss= 0.00068, NegPearson= 1.00090, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 352, loss= 0.00069, NegPearson= 1.00083, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 353, loss= 0.00071, NegPearson= 1.00084, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 354, loss= 0.00068, NegPearson= 1.00072, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 355, loss= 0.00071, NegPearson= 1.00075, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 356, loss= 0.00068, NegPearson= 1.00065, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 357, loss= 0.00070, NegPearson= 1.00064, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 358, loss= 0.00071, NegPearson= 1.00071, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 359, loss= 0.00070, NegPearson= 1.00074, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 360, loss= 0.00069, NegPearson= 1.00073, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 361, loss= 0.00064, NegPearson= 1.00052, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 362, loss= 0.00069, NegPearson= 1.00053, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 363, loss= 0.00066, NegPearson= 1.00041, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 364, loss= 0.00070, NegPearson= 1.00046, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 365, loss= 0.00070, NegPearson= 1.00053, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 366, loss= 0.00074, NegPearson= 1.00075, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 367, loss= 0.00066, NegPearson= 1.00066, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 368, loss= 0.00079, NegPearson= 1.00109, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 369, loss= 0.00056, NegPearson= 1.00063, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 370, loss= 0.00061, NegPearson= 1.00038, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 371, loss= 0.00069, NegPearson= 1.00046, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 372, loss= 0.00065, NegPearson= 1.00038, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 373, loss= 0.00065, NegPearson= 1.00029, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 374, loss= 0.00061, NegPearson= 1.00007, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 375, loss= 0.00070, NegPearson= 1.00020, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 376, loss= 0.00070, NegPearson= 1.00036, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 377, loss= 0.00066, NegPearson= 1.00033, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 378, loss= 0.00068, NegPearson= 1.00042, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 379, loss= 0.00069, NegPearson= 1.00054, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 380, loss= 0.00071, NegPearson= 1.00074, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 381, loss= 0.00067, NegPearson= 1.00077, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 382, loss= 0.00065, NegPearson= 1.00076, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 383, loss= 0.00066, NegPearson= 1.00079, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 384, loss= 0.00062, NegPearson= 1.00068, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 385, loss= 0.00060, NegPearson= 1.00049, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 386, loss= 0.00067, NegPearson= 1.00060, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 387, loss= 0.00067, NegPearson= 1.00068, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 388, loss= 0.00062, NegPearson= 1.00058, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 389, loss= 0.00059, NegPearson= 1.00036, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 390, loss= 0.00067, NegPearson= 1.00047, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 391, loss= 0.00064, NegPearson= 1.00048, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 392, loss= 0.00060, NegPearson= 1.00031, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 393, loss= 0.00061, NegPearson= 1.00020, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 394, loss= 0.00070, NegPearson= 1.00044, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 395, loss= 0.00069, NegPearson= 1.00066, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 396, loss= 0.00066, NegPearson= 1.00078, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 397, loss= 0.00068, NegPearson= 1.00097, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 398, loss= 0.00060, NegPearson= 1.00085, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 399, loss= 0.00061, NegPearson= 1.00080, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 400, loss= 0.00059, NegPearson= 1.00066, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 401, loss= 0.00065, NegPearson= 1.00077, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 402, loss= 0.00058, NegPearson= 1.00061, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 403, loss= 0.00059, NegPearson= 1.00047, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 404, loss= 0.00057, NegPearson= 1.00026, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 405, loss= 0.00063, NegPearson= 1.00030, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 406, loss= 0.00065, NegPearson= 1.00044, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 407, loss= 0.00060, NegPearson= 1.00040, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 408, loss= 0.00053, NegPearson= 1.00008, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 409, loss= 0.00054, NegPearson= 0.99981, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 410, loss= 0.00062, NegPearson= 0.99985, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 411, loss= 0.00060, NegPearson= 0.99980, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 412, loss= 0.00062, NegPearson= 0.99987, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 413, loss= 0.00064, NegPearson= 1.00001, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 414, loss= 0.00061, NegPearson= 1.00003, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 415, loss= 0.00057, NegPearson= 0.99991, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 416, loss= 0.00067, NegPearson= 1.00017, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 417, loss= 0.00061, NegPearson= 1.00023, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 418, loss= 0.00057, NegPearson= 1.00011, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 419, loss= 0.00065, NegPearson= 1.00031, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 420, loss= 0.00059, NegPearson= 1.00029, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 421, loss= 0.00057, NegPearson= 1.00018, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 422, loss= 0.00060, NegPearson= 1.00020, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 423, loss= 0.00061, NegPearson= 1.00028, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 424, loss= 0.00067, NegPearson= 1.00058, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 425, loss= 0.00059, NegPearson= 1.00061, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 426, loss= 0.00063, NegPearson= 1.00078, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 427, loss= 0.00054, NegPearson= 1.00060, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 428, loss= 0.00060, NegPearson= 1.00066, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 429, loss= 0.00057, NegPearson= 1.00062, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 430, loss= 0.00059, NegPearson= 1.00065, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 431, loss= 0.00067, NegPearson= 1.00100, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 432, loss= 0.00058, NegPearson= 1.00099, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 433, loss= 0.00060, NegPearson= 1.00109, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 434, loss= 0.00054, NegPearson= 1.00092, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 435, loss= 0.00067, NegPearson= 1.00130, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 436, loss= 0.00065, NegPearson= 1.00159, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 437, loss= 0.00057, NegPearson= 1.00159, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 438, loss= 0.00058, NegPearson= 1.00160, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 439, loss= 0.00057, NegPearson= 1.00162, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 440, loss= 0.00055, NegPearson= 1.00156, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 441, loss= 0.00055, NegPearson= 1.00150, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 442, loss= 0.00061, NegPearson= 1.00169, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 443, loss= 0.00061, NegPearson= 1.00188, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 444, loss= 0.00057, NegPearson= 1.00191, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 445, loss= 0.00057, NegPearson= 1.00194, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 446, loss= 0.00056, NegPearson= 1.00193, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 447, loss= 0.00053, NegPearson= 1.00182, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 448, loss= 0.00060, NegPearson= 1.00200, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 449, loss= 0.00061, NegPearson= 1.00221, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 450, loss= 0.00050, NegPearson= 1.00197, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 451, loss= 0.00060, NegPearson= 1.00217, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 452, loss= 0.00051, NegPearson= 1.00200, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 453, loss= 0.00053, NegPearson= 1.00191, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 454, loss= 0.00054, NegPearson= 1.00185, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 455, loss= 0.00051, NegPearson= 1.00170, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 456, loss= 0.00055, NegPearson= 1.00169, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 457, loss= 0.00059, NegPearson= 1.00186, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 458, loss= 0.00062, NegPearson= 1.00214, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 459, loss= 0.00056, NegPearson= 1.00222, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 460, loss= 0.00058, NegPearson= 1.00235, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 461, loss= 0.00053, NegPearson= 1.00231, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 462, loss= 0.00060, NegPearson= 1.00253, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 463, loss= 0.00050, NegPearson= 1.00236, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 464, loss= 0.00059, NegPearson= 1.00255, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 465, loss= 0.00051, NegPearson= 1.00242, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 466, loss= 0.00059, NegPearson= 1.00265, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 467, loss= 0.00057, NegPearson= 1.00279, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 468, loss= 0.00054, NegPearson= 1.00279, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 469, loss= 0.00048, NegPearson= 1.00258, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 470, loss= 0.00054, NegPearson= 1.00259, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 471, loss= 0.00061, NegPearson= 1.00290, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 472, loss= 0.00048, NegPearson= 1.00268, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 473, loss= 0.00053, NegPearson= 1.00268, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 474, loss= 0.00054, NegPearson= 1.00274, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 475, loss= 0.00049, NegPearson= 1.00260, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 476, loss= 0.00052, NegPearson= 1.00257, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 477, loss= 0.00054, NegPearson= 1.00264, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 478, loss= 0.00055, NegPearson= 1.00273, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 479, loss= 0.00053, NegPearson= 1.00276, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 480, loss= 0.00051, NegPearson= 1.00272, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 481, loss= 0.00050, NegPearson= 1.00263, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 482, loss= 0.00053, NegPearson= 1.00268, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 483, loss= 0.00054, NegPearson= 1.00274, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 484, loss= 0.00050, NegPearson= 1.00267, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 485, loss= 0.00046, NegPearson= 1.00245, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 486, loss= 0.00055, NegPearson= 1.00258, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 487, loss= 0.00048, NegPearson= 1.00244, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 488, loss= 0.00051, NegPearson= 1.00241, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 489, loss= 0.00052, NegPearson= 1.00245, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 490, loss= 0.00054, NegPearson= 1.00255, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 491, loss= 0.00054, NegPearson= 1.00266, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 492, loss= 0.00051, NegPearson= 1.00268, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 493, loss= 0.00048, NegPearson= 1.00256, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 494, loss= 0.00052, NegPearson= 1.00263, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 495, loss= 0.00054, NegPearson= 1.00275, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 496, loss= 0.00047, NegPearson= 1.00263, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 497, loss= 0.00050, NegPearson= 1.00260, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 498, loss= 0.00047, NegPearson= 1.00244, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 499, loss= 0.00051, NegPearson= 1.00248, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 500, loss= 0.00052, NegPearson= 1.00256, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 501, loss= 0.00050, NegPearson= 1.00254, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 502, loss= 0.00044, NegPearson= 1.00232, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 503, loss= 0.00045, NegPearson= 1.00211, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 504, loss= 0.00049, NegPearson= 1.00208, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 505, loss= 0.00052, NegPearson= 1.00218, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 506, loss= 0.00049, NegPearson= 1.00217, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 507, loss= 0.00050, NegPearson= 1.00220, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 508, loss= 0.00044, NegPearson= 1.00197, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 509, loss= 0.00049, NegPearson= 1.00196, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 510, loss= 0.00049, NegPearson= 1.00194, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 511, loss= 0.00047, NegPearson= 1.00186, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 512, loss= 0.00045, NegPearson= 1.00169, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 513, loss= 0.00050, NegPearson= 1.00173, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 514, loss= 0.00049, NegPearson= 1.00175, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 515, loss= 0.00048, NegPearson= 1.00171, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 516, loss= 0.00047, NegPearson= 1.00165, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 517, loss= 0.00049, NegPearson= 1.00169, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 518, loss= 0.00052, NegPearson= 1.00184, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 519, loss= 0.00056, NegPearson= 1.00216, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 520, loss= 0.00050, NegPearson= 1.00222, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 521, loss= 0.00040, NegPearson= 1.00190, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 522, loss= 0.00046, NegPearson= 1.00181, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 523, loss= 0.00044, NegPearson= 1.00167, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 524, loss= 0.00043, NegPearson= 1.00147, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 525, loss= 0.00050, NegPearson= 1.00155, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 526, loss= 0.00049, NegPearson= 1.00162, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 527, loss= 0.00049, NegPearson= 1.00168, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 528, loss= 0.00048, NegPearson= 1.00171, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 529, loss= 0.00050, NegPearson= 1.00181, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 530, loss= 0.00046, NegPearson= 1.00176, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 531, loss= 0.00041, NegPearson= 1.00152, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 532, loss= 0.00048, NegPearson= 1.00156, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 533, loss= 0.00046, NegPearson= 1.00152, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 534, loss= 0.00048, NegPearson= 1.00158, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 535, loss= 0.00043, NegPearson= 1.00144, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 536, loss= 0.00092, NegPearson= 1.00143, kl= 0.00000, fre_CEloss= 0.00000\n",
      "Starting epoch 3\n",
      "\n",
      "\n",
      "Iteration 1, loss= 0.24698, NegPearson= 0.98794, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 2, loss= 0.13547, NegPearson= 1.03583, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 3, loss= 0.08879, NegPearson= 1.04572, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 4, loss= 0.06567, NegPearson= 1.04696, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 5, loss= 0.05156, NegPearson= 1.04380, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 6, loss= 0.04538, NegPearson= 1.05136, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 7, loss= 0.03469, NegPearson= 1.03994, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 8, loss= 0.03070, NegPearson= 1.03273, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 9, loss= 0.02692, NegPearson= 1.02567, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 10, loss= 0.02396, NegPearson= 1.01893, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 11, loss= 0.02189, NegPearson= 1.01385, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 12, loss= 0.01882, NegPearson= 1.00465, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 13, loss= 0.01926, NegPearson= 1.00441, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 14, loss= 0.01741, NegPearson= 1.00231, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 15, loss= 0.01701, NegPearson= 1.00352, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 16, loss= 0.01625, NegPearson= 1.00579, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 17, loss= 0.01438, NegPearson= 1.00415, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 18, loss= 0.01236, NegPearson= 0.99778, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 19, loss= 0.01257, NegPearson= 0.99554, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 20, loss= 0.01177, NegPearson= 0.99285, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 21, loss= 0.01312, NegPearson= 0.99806, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 22, loss= 0.01132, NegPearson= 0.99799, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 23, loss= 0.01030, NegPearson= 0.99581, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 24, loss= 0.01065, NegPearson= 0.99690, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 25, loss= 0.01027, NegPearson= 0.99812, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 26, loss= 0.00906, NegPearson= 0.99595, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 27, loss= 0.00866, NegPearson= 0.99370, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 28, loss= 0.00916, NegPearson= 0.99485, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 29, loss= 0.00854, NegPearson= 0.99469, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 30, loss= 0.00873, NegPearson= 0.99647, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 31, loss= 0.00808, NegPearson= 0.99665, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 32, loss= 0.00847, NegPearson= 0.99938, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 33, loss= 0.00835, NegPearson= 1.00250, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 34, loss= 0.00748, NegPearson= 1.00293, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 35, loss= 0.00686, NegPearson= 1.00171, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 36, loss= 0.00721, NegPearson= 1.00274, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 37, loss= 0.00659, NegPearson= 1.00201, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 38, loss= 0.00644, NegPearson= 1.00142, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 39, loss= 0.00643, NegPearson= 1.00146, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 40, loss= 0.00676, NegPearson= 1.00348, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 41, loss= 0.00641, NegPearson= 1.00466, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 42, loss= 0.00598, NegPearson= 1.00468, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 43, loss= 0.00646, NegPearson= 1.00717, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 44, loss= 0.00570, NegPearson= 1.00709, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 45, loss= 0.00532, NegPearson= 1.00598, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 46, loss= 0.00585, NegPearson= 1.00749, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 47, loss= 0.00536, NegPearson= 1.00750, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 48, loss= 0.00507, NegPearson= 1.00678, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 49, loss= 0.00535, NegPearson= 1.00762, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 50, loss= 0.00433, NegPearson= 1.00480, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 51, loss= 0.00534, NegPearson= 1.00645, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 52, loss= 0.00500, NegPearson= 1.00709, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 53, loss= 0.00493, NegPearson= 1.00781, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 54, loss= 0.00442, NegPearson= 1.00684, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 55, loss= 0.00454, NegPearson= 1.00668, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 56, loss= 0.00441, NegPearson= 1.00634, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 57, loss= 0.00393, NegPearson= 1.00440, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 58, loss= 0.00422, NegPearson= 1.00396, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 59, loss= 0.00440, NegPearson= 1.00453, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 60, loss= 0.00434, NegPearson= 1.00517, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 61, loss= 0.00434, NegPearson= 1.00604, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 62, loss= 0.00419, NegPearson= 1.00658, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 63, loss= 0.00383, NegPearson= 1.00591, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 64, loss= 0.00394, NegPearson= 1.00595, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 65, loss= 0.00341, NegPearson= 1.00412, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 66, loss= 0.00382, NegPearson= 1.00418, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 67, loss= 0.00353, NegPearson= 1.00332, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 68, loss= 0.00362, NegPearson= 1.00304, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 69, loss= 0.00391, NegPearson= 1.00413, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 70, loss= 0.00307, NegPearson= 1.00205, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 71, loss= 0.00329, NegPearson= 1.00108, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 72, loss= 0.00356, NegPearson= 1.00144, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 73, loss= 0.00350, NegPearson= 1.00170, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 74, loss= 0.00351, NegPearson= 1.00221, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 75, loss= 0.00353, NegPearson= 1.00298, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 76, loss= 0.00353, NegPearson= 1.00389, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 77, loss= 0.00320, NegPearson= 1.00364, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 78, loss= 0.00315, NegPearson= 1.00339, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 79, loss= 0.00332, NegPearson= 1.00396, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 80, loss= 0.00291, NegPearson= 1.00307, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 81, loss= 0.00303, NegPearson= 1.00282, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 82, loss= 0.00327, NegPearson= 1.00367, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 83, loss= 0.00313, NegPearson= 1.00411, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 84, loss= 0.00291, NegPearson= 1.00380, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 85, loss= 0.00294, NegPearson= 1.00373, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 86, loss= 0.00299, NegPearson= 1.00402, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 87, loss= 0.00282, NegPearson= 1.00378, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 88, loss= 0.00311, NegPearson= 1.00481, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 89, loss= 0.00306, NegPearson= 1.00575, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 90, loss= 0.00299, NegPearson= 1.00654, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 91, loss= 0.00280, NegPearson= 1.00670, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 92, loss= 0.00289, NegPearson= 1.00731, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 93, loss= 0.00272, NegPearson= 1.00736, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 94, loss= 0.00259, NegPearson= 1.00700, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 95, loss= 0.00246, NegPearson= 1.00625, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 96, loss= 0.00283, NegPearson= 1.00707, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 97, loss= 0.00260, NegPearson= 1.00707, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 98, loss= 0.00264, NegPearson= 1.00737, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 99, loss= 0.00271, NegPearson= 1.00805, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 100, loss= 0.00238, NegPearson= 1.00751, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 101, loss= 0.00248, NegPearson= 1.00744, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 102, loss= 0.00251, NegPearson= 1.00759, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 103, loss= 0.00251, NegPearson= 1.00787, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 104, loss= 0.00227, NegPearson= 1.00725, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 105, loss= 0.00238, NegPearson= 1.00720, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 106, loss= 0.00243, NegPearson= 1.00744, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 107, loss= 0.00247, NegPearson= 1.00790, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 108, loss= 0.00247, NegPearson= 1.00846, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 109, loss= 0.00245, NegPearson= 1.00902, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 110, loss= 0.00247, NegPearson= 1.00974, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 111, loss= 0.00213, NegPearson= 1.00916, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 112, loss= 0.00230, NegPearson= 1.00935, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 113, loss= 0.00193, NegPearson= 1.00815, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 114, loss= 0.00220, NegPearson= 1.00812, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 115, loss= 0.00229, NegPearson= 1.00850, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 116, loss= 0.00216, NegPearson= 1.00846, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 117, loss= 0.00218, NegPearson= 1.00855, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 118, loss= 0.00226, NegPearson= 1.00904, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 119, loss= 0.00230, NegPearson= 1.00975, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 120, loss= 0.00215, NegPearson= 1.00994, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 121, loss= 0.00193, NegPearson= 1.00930, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 122, loss= 0.00200, NegPearson= 1.00903, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 123, loss= 0.00197, NegPearson= 1.00869, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 124, loss= 0.00189, NegPearson= 1.00811, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 125, loss= 0.00176, NegPearson= 1.00709, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 126, loss= 0.00190, NegPearson= 1.00669, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 127, loss= 0.00216, NegPearson= 1.00739, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 128, loss= 0.00191, NegPearson= 1.00714, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 129, loss= 0.00207, NegPearson= 1.00763, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 130, loss= 0.00198, NegPearson= 1.00779, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 131, loss= 0.00184, NegPearson= 1.00747, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 132, loss= 0.00195, NegPearson= 1.00765, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 133, loss= 0.00191, NegPearson= 1.00773, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 134, loss= 0.00171, NegPearson= 1.00705, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 135, loss= 0.00199, NegPearson= 1.00756, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 136, loss= 0.00193, NegPearson= 1.00787, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 137, loss= 0.00199, NegPearson= 1.00848, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 138, loss= 0.00184, NegPearson= 1.00854, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 139, loss= 0.00187, NegPearson= 1.00877, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 140, loss= 0.00166, NegPearson= 1.00819, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 141, loss= 0.00168, NegPearson= 1.00776, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 142, loss= 0.00185, NegPearson= 1.00806, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 143, loss= 0.00183, NegPearson= 1.00834, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 144, loss= 0.00161, NegPearson= 1.00778, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 145, loss= 0.00169, NegPearson= 1.00759, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 146, loss= 0.00159, NegPearson= 1.00706, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 147, loss= 0.00178, NegPearson= 1.00735, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 148, loss= 0.00171, NegPearson= 1.00737, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 149, loss= 0.00166, NegPearson= 1.00724, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 150, loss= 0.00155, NegPearson= 1.00674, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 151, loss= 0.00158, NegPearson= 1.00639, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 152, loss= 0.00176, NegPearson= 1.00681, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 153, loss= 0.00171, NegPearson= 1.00709, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 154, loss= 0.00160, NegPearson= 1.00695, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 155, loss= 0.00156, NegPearson= 1.00667, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 156, loss= 0.00164, NegPearson= 1.00678, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 157, loss= 0.00161, NegPearson= 1.00680, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 158, loss= 0.00146, NegPearson= 1.00626, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 159, loss= 0.00148, NegPearson= 1.00586, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 160, loss= 0.00168, NegPearson= 1.00628, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 161, loss= 0.00168, NegPearson= 1.00674, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 162, loss= 0.00165, NegPearson= 1.00711, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 163, loss= 0.00144, NegPearson= 1.00669, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 164, loss= 0.00164, NegPearson= 1.00712, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 165, loss= 0.00137, NegPearson= 1.00648, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 166, loss= 0.00187, NegPearson= 1.00791, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 167, loss= 0.00145, NegPearson= 1.00767, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 168, loss= 0.00149, NegPearson= 1.00761, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 169, loss= 0.00141, NegPearson= 1.00729, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 170, loss= 0.00151, NegPearson= 1.00742, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 171, loss= 0.00145, NegPearson= 1.00734, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 172, loss= 0.00128, NegPearson= 1.00660, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 173, loss= 0.00154, NegPearson= 1.00693, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 174, loss= 0.00129, NegPearson= 1.00628, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 175, loss= 0.00143, NegPearson= 1.00627, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 176, loss= 0.00152, NegPearson= 1.00665, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 177, loss= 0.00157, NegPearson= 1.00722, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 178, loss= 0.00132, NegPearson= 1.00685, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 179, loss= 0.00124, NegPearson= 1.00620, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 180, loss= 0.00125, NegPearson= 1.00560, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 181, loss= 0.00134, NegPearson= 1.00543, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 182, loss= 0.00131, NegPearson= 1.00513, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 183, loss= 0.00145, NegPearson= 1.00544, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 184, loss= 0.00135, NegPearson= 1.00538, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 185, loss= 0.00137, NegPearson= 1.00544, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 186, loss= 0.00135, NegPearson= 1.00543, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 187, loss= 0.00131, NegPearson= 1.00531, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 188, loss= 0.00131, NegPearson= 1.00522, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 189, loss= 0.00126, NegPearson= 1.00494, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 190, loss= 0.00109, NegPearson= 1.00401, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 191, loss= 0.00119, NegPearson= 1.00350, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 192, loss= 0.00133, NegPearson= 1.00360, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 193, loss= 0.00142, NegPearson= 1.00406, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 194, loss= 0.00125, NegPearson= 1.00387, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 195, loss= 0.00133, NegPearson= 1.00402, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 196, loss= 0.00129, NegPearson= 1.00405, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 197, loss= 0.00131, NegPearson= 1.00420, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 198, loss= 0.00129, NegPearson= 1.00430, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 199, loss= 0.00134, NegPearson= 1.00460, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 200, loss= 0.00120, NegPearson= 1.00436, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 201, loss= 0.00125, NegPearson= 1.00437, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 202, loss= 0.00119, NegPearson= 1.00415, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 203, loss= 0.00121, NegPearson= 1.00405, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 204, loss= 0.00122, NegPearson= 1.00402, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 205, loss= 0.00117, NegPearson= 1.00380, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 206, loss= 0.00115, NegPearson= 1.00352, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 207, loss= 0.00115, NegPearson= 1.00326, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 208, loss= 0.00118, NegPearson= 1.00315, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 209, loss= 0.00114, NegPearson= 1.00291, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 210, loss= 0.00133, NegPearson= 1.00347, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 211, loss= 0.00119, NegPearson= 1.00348, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 212, loss= 0.00127, NegPearson= 1.00383, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 213, loss= 0.00106, NegPearson= 1.00335, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 214, loss= 0.00110, NegPearson= 1.00306, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 215, loss= 0.00130, NegPearson= 1.00361, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 216, loss= 0.00111, NegPearson= 1.00342, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 217, loss= 0.00110, NegPearson= 1.00321, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 218, loss= 0.00126, NegPearson= 1.00363, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 219, loss= 0.00102, NegPearson= 1.00313, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 220, loss= 0.00122, NegPearson= 1.00344, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 221, loss= 0.00108, NegPearson= 1.00321, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 222, loss= 0.00116, NegPearson= 1.00332, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 223, loss= 0.00109, NegPearson= 1.00319, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 224, loss= 0.00090, NegPearson= 1.00231, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 225, loss= 0.00119, NegPearson= 1.00261, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 226, loss= 0.00117, NegPearson= 1.00287, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 227, loss= 0.00108, NegPearson= 1.00279, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 228, loss= 0.00113, NegPearson= 1.00289, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 229, loss= 0.00102, NegPearson= 1.00258, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 230, loss= 0.00114, NegPearson= 1.00278, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 231, loss= 0.00104, NegPearson= 1.00262, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 232, loss= 0.00115, NegPearson= 1.00291, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 233, loss= 0.00100, NegPearson= 1.00260, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 234, loss= 0.00098, NegPearson= 1.00225, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 235, loss= 0.00108, NegPearson= 1.00229, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 236, loss= 0.00097, NegPearson= 1.00195, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 237, loss= 0.00104, NegPearson= 1.00190, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 238, loss= 0.00110, NegPearson= 1.00209, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 239, loss= 0.00091, NegPearson= 1.00154, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 240, loss= 0.00104, NegPearson= 1.00154, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 241, loss= 0.00105, NegPearson= 1.00159, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 242, loss= 0.00108, NegPearson= 1.00176, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 243, loss= 0.00115, NegPearson= 1.00223, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 244, loss= 0.00102, NegPearson= 1.00220, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 245, loss= 0.00111, NegPearson= 1.00256, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 246, loss= 0.00113, NegPearson= 1.00300, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 247, loss= 0.00095, NegPearson= 1.00272, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 248, loss= 0.00093, NegPearson= 1.00241, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 249, loss= 0.00099, NegPearson= 1.00233, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 250, loss= 0.00100, NegPearson= 1.00233, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 251, loss= 0.00096, NegPearson= 1.00217, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 252, loss= 0.00102, NegPearson= 1.00226, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 253, loss= 0.00100, NegPearson= 1.00230, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 254, loss= 0.00098, NegPearson= 1.00225, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 255, loss= 0.00094, NegPearson= 1.00210, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 256, loss= 0.00096, NegPearson= 1.00202, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 257, loss= 0.00092, NegPearson= 1.00179, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 258, loss= 0.00082, NegPearson= 1.00120, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 259, loss= 0.00089, NegPearson= 1.00090, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 260, loss= 0.00101, NegPearson= 1.00111, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 261, loss= 0.00107, NegPearson= 1.00154, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 262, loss= 0.00099, NegPearson= 1.00167, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 263, loss= 0.00095, NegPearson= 1.00166, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 264, loss= 0.00099, NegPearson= 1.00181, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 265, loss= 0.00098, NegPearson= 1.00195, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 266, loss= 0.00090, NegPearson= 1.00179, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 267, loss= 0.00101, NegPearson= 1.00209, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 268, loss= 0.00088, NegPearson= 1.00185, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 269, loss= 0.00094, NegPearson= 1.00189, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 270, loss= 0.00097, NegPearson= 1.00207, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 271, loss= 0.00087, NegPearson= 1.00184, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 272, loss= 0.00099, NegPearson= 1.00214, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 273, loss= 0.00099, NegPearson= 1.00243, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 274, loss= 0.00095, NegPearson= 1.00255, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 275, loss= 0.00092, NegPearson= 1.00260, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 276, loss= 0.00089, NegPearson= 1.00252, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 277, loss= 0.00092, NegPearson= 1.00258, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 278, loss= 0.00085, NegPearson= 1.00237, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 279, loss= 0.00091, NegPearson= 1.00241, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 280, loss= 0.00090, NegPearson= 1.00243, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 281, loss= 0.00096, NegPearson= 1.00272, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 282, loss= 0.00084, NegPearson= 1.00254, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 283, loss= 0.00091, NegPearson= 1.00262, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 284, loss= 0.00088, NegPearson= 1.00260, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 285, loss= 0.00088, NegPearson= 1.00261, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 286, loss= 0.00085, NegPearson= 1.00250, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 287, loss= 0.00090, NegPearson= 1.00262, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 288, loss= 0.00079, NegPearson= 1.00228, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 289, loss= 0.00082, NegPearson= 1.00211, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 290, loss= 0.00083, NegPearson= 1.00199, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 291, loss= 0.00078, NegPearson= 1.00167, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 292, loss= 0.00090, NegPearson= 1.00185, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 293, loss= 0.00090, NegPearson= 1.00203, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 294, loss= 0.00087, NegPearson= 1.00210, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 295, loss= 0.00077, NegPearson= 1.00177, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 296, loss= 0.00085, NegPearson= 1.00180, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 297, loss= 0.00088, NegPearson= 1.00194, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 298, loss= 0.00078, NegPearson= 1.00171, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 299, loss= 0.00080, NegPearson= 1.00158, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 300, loss= 0.00084, NegPearson= 1.00161, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 301, loss= 0.00083, NegPearson= 1.00159, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 302, loss= 0.00085, NegPearson= 1.00166, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 303, loss= 0.00091, NegPearson= 1.00200, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 304, loss= 0.00076, NegPearson= 1.00175, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 305, loss= 0.00087, NegPearson= 1.00196, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 306, loss= 0.00082, NegPearson= 1.00196, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 307, loss= 0.00093, NegPearson= 1.00242, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 308, loss= 0.00076, NegPearson= 1.00222, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 309, loss= 0.00081, NegPearson= 1.00221, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 310, loss= 0.00085, NegPearson= 1.00237, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 311, loss= 0.00083, NegPearson= 1.00248, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 312, loss= 0.00072, NegPearson= 1.00216, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 313, loss= 0.00088, NegPearson= 1.00250, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 314, loss= 0.00079, NegPearson= 1.00247, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 315, loss= 0.00071, NegPearson= 1.00212, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 316, loss= 0.00079, NegPearson= 1.00209, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 317, loss= 0.00088, NegPearson= 1.00246, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 318, loss= 0.00075, NegPearson= 1.00232, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 319, loss= 0.00076, NegPearson= 1.00220, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 320, loss= 0.00066, NegPearson= 1.00173, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 321, loss= 0.00086, NegPearson= 1.00207, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 322, loss= 0.00074, NegPearson= 1.00190, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 323, loss= 0.00074, NegPearson= 1.00175, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 324, loss= 0.00068, NegPearson= 1.00136, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 325, loss= 0.00077, NegPearson= 1.00135, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 326, loss= 0.00076, NegPearson= 1.00132, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 327, loss= 0.00080, NegPearson= 1.00144, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 328, loss= 0.00081, NegPearson= 1.00164, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 329, loss= 0.00080, NegPearson= 1.00181, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 330, loss= 0.00079, NegPearson= 1.00192, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 331, loss= 0.00077, NegPearson= 1.00197, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 332, loss= 0.00073, NegPearson= 1.00187, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 333, loss= 0.00078, NegPearson= 1.00196, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 334, loss= 0.00078, NegPearson= 1.00209, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 335, loss= 0.00063, NegPearson= 1.00163, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 336, loss= 0.00074, NegPearson= 1.00162, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 337, loss= 0.00076, NegPearson= 1.00168, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 338, loss= 0.00073, NegPearson= 1.00163, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 339, loss= 0.00078, NegPearson= 1.00180, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 340, loss= 0.00084, NegPearson= 1.00220, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 341, loss= 0.00070, NegPearson= 1.00206, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 342, loss= 0.00076, NegPearson= 1.00217, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 343, loss= 0.00067, NegPearson= 1.00193, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 344, loss= 0.00077, NegPearson= 1.00211, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 345, loss= 0.00070, NegPearson= 1.00200, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 346, loss= 0.00068, NegPearson= 1.00182, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 347, loss= 0.00074, NegPearson= 1.00190, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 348, loss= 0.00080, NegPearson= 1.00222, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 349, loss= 0.00074, NegPearson= 1.00232, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 350, loss= 0.00072, NegPearson= 1.00234, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 351, loss= 0.00067, NegPearson= 1.00218, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 352, loss= 0.00071, NegPearson= 1.00218, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 353, loss= 0.00066, NegPearson= 1.00198, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 354, loss= 0.00062, NegPearson= 1.00165, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 355, loss= 0.00073, NegPearson= 1.00175, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 356, loss= 0.00067, NegPearson= 1.00161, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 357, loss= 0.00059, NegPearson= 1.00118, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 358, loss= 0.00072, NegPearson= 1.00126, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 359, loss= 0.00072, NegPearson= 1.00134, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 360, loss= 0.00073, NegPearson= 1.00148, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 361, loss= 0.00059, NegPearson= 1.00107, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 362, loss= 0.00063, NegPearson= 1.00082, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 363, loss= 0.00065, NegPearson= 1.00068, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 364, loss= 0.00076, NegPearson= 1.00097, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 365, loss= 0.00071, NegPearson= 1.00108, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 366, loss= 0.00065, NegPearson= 1.00093, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 367, loss= 0.00072, NegPearson= 1.00108, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 368, loss= 0.00062, NegPearson= 1.00084, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 369, loss= 0.00069, NegPearson= 1.00089, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 370, loss= 0.00058, NegPearson= 1.00051, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 371, loss= 0.00064, NegPearson= 1.00038, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 372, loss= 0.00069, NegPearson= 1.00045, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 373, loss= 0.00064, NegPearson= 1.00034, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 374, loss= 0.00066, NegPearson= 1.00032, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 375, loss= 0.00070, NegPearson= 1.00045, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 376, loss= 0.00065, NegPearson= 1.00039, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 377, loss= 0.00068, NegPearson= 1.00045, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 378, loss= 0.00074, NegPearson= 1.00077, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 379, loss= 0.00061, NegPearson= 1.00055, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 380, loss= 0.00065, NegPearson= 1.00051, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 381, loss= 0.00066, NegPearson= 1.00053, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 382, loss= 0.00061, NegPearson= 1.00037, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 383, loss= 0.00061, NegPearson= 1.00022, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 384, loss= 0.00066, NegPearson= 1.00026, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 385, loss= 0.00064, NegPearson= 1.00022, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 386, loss= 0.00058, NegPearson= 0.99995, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 387, loss= 0.00060, NegPearson= 0.99978, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 388, loss= 0.00060, NegPearson= 0.99962, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 389, loss= 0.00059, NegPearson= 0.99939, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 390, loss= 0.00076, NegPearson= 0.99988, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 391, loss= 0.00057, NegPearson= 0.99959, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 392, loss= 0.00067, NegPearson= 0.99970, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 393, loss= 0.00067, NegPearson= 0.99984, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 394, loss= 0.00057, NegPearson= 0.99959, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 395, loss= 0.00068, NegPearson= 0.99976, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 396, loss= 0.00066, NegPearson= 0.99989, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 397, loss= 0.00058, NegPearson= 0.99971, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 398, loss= 0.00059, NegPearson= 0.99954, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 399, loss= 0.00063, NegPearson= 0.99958, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 400, loss= 0.00060, NegPearson= 0.99949, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 401, loss= 0.00063, NegPearson= 0.99952, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 402, loss= 0.00060, NegPearson= 0.99945, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 403, loss= 0.00061, NegPearson= 0.99942, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 404, loss= 0.00059, NegPearson= 0.99933, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 405, loss= 0.00061, NegPearson= 0.99929, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 406, loss= 0.00059, NegPearson= 0.99919, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 407, loss= 0.00068, NegPearson= 0.99947, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 408, loss= 0.00063, NegPearson= 0.99955, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 409, loss= 0.00061, NegPearson= 0.99953, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 410, loss= 0.00061, NegPearson= 0.99952, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 411, loss= 0.00067, NegPearson= 0.99977, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 412, loss= 0.00057, NegPearson= 0.99964, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 413, loss= 0.00059, NegPearson= 0.99958, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 414, loss= 0.00058, NegPearson= 0.99947, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 415, loss= 0.00066, NegPearson= 0.99971, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 416, loss= 0.00058, NegPearson= 0.99963, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 417, loss= 0.00061, NegPearson= 0.99968, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 418, loss= 0.00060, NegPearson= 0.99967, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 419, loss= 0.00055, NegPearson= 0.99947, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 420, loss= 0.00063, NegPearson= 0.99962, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 421, loss= 0.00068, NegPearson= 0.99997, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 422, loss= 0.00055, NegPearson= 0.99979, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 423, loss= 0.00055, NegPearson= 0.99964, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 424, loss= 0.00058, NegPearson= 0.99960, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 425, loss= 0.00061, NegPearson= 0.99970, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 426, loss= 0.00063, NegPearson= 0.99988, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 427, loss= 0.00060, NegPearson= 0.99995, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 428, loss= 0.00058, NegPearson= 0.99994, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 429, loss= 0.00063, NegPearson= 1.00011, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 430, loss= 0.00054, NegPearson= 0.99994, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 431, loss= 0.00063, NegPearson= 1.00013, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 432, loss= 0.00062, NegPearson= 1.00031, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 433, loss= 0.00056, NegPearson= 1.00024, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 434, loss= 0.00059, NegPearson= 1.00031, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 435, loss= 0.00062, NegPearson= 1.00049, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 436, loss= 0.00057, NegPearson= 1.00048, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 437, loss= 0.00055, NegPearson= 1.00037, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 438, loss= 0.00057, NegPearson= 1.00037, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 439, loss= 0.00057, NegPearson= 1.00036, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 440, loss= 0.00053, NegPearson= 1.00022, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 441, loss= 0.00055, NegPearson= 1.00014, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 442, loss= 0.00051, NegPearson= 0.99993, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 443, loss= 0.00050, NegPearson= 0.99969, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 444, loss= 0.00054, NegPearson= 0.99960, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 445, loss= 0.00056, NegPearson= 0.99960, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 446, loss= 0.00061, NegPearson= 0.99979, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 447, loss= 0.00061, NegPearson= 0.99998, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 448, loss= 0.00056, NegPearson= 0.99999, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 449, loss= 0.00050, NegPearson= 0.99975, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 450, loss= 0.00057, NegPearson= 0.99982, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 451, loss= 0.00053, NegPearson= 0.99975, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 452, loss= 0.00059, NegPearson= 0.99990, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 453, loss= 0.00061, NegPearson= 1.00013, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 454, loss= 0.00058, NegPearson= 1.00023, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 455, loss= 0.00057, NegPearson= 1.00029, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 456, loss= 0.00054, NegPearson= 1.00025, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 457, loss= 0.00060, NegPearson= 1.00046, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 458, loss= 0.00058, NegPearson= 1.00059, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 459, loss= 0.00058, NegPearson= 1.00073, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 460, loss= 0.00059, NegPearson= 1.00089, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 461, loss= 0.00052, NegPearson= 1.00080, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 462, loss= 0.00054, NegPearson= 1.00081, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 463, loss= 0.00053, NegPearson= 1.00076, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 464, loss= 0.00057, NegPearson= 1.00089, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 465, loss= 0.00058, NegPearson= 1.00104, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 466, loss= 0.00054, NegPearson= 1.00104, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 467, loss= 0.00059, NegPearson= 1.00126, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 468, loss= 0.00047, NegPearson= 1.00102, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 469, loss= 0.00053, NegPearson= 1.00100, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 470, loss= 0.00043, NegPearson= 1.00058, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 471, loss= 0.00055, NegPearson= 1.00065, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 472, loss= 0.00049, NegPearson= 1.00049, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 473, loss= 0.00056, NegPearson= 1.00061, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 474, loss= 0.00054, NegPearson= 1.00066, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 475, loss= 0.00052, NegPearson= 1.00063, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 476, loss= 0.00057, NegPearson= 1.00080, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 477, loss= 0.00051, NegPearson= 1.00074, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 478, loss= 0.00050, NegPearson= 1.00065, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 479, loss= 0.00051, NegPearson= 1.00058, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 480, loss= 0.00052, NegPearson= 1.00058, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 481, loss= 0.00053, NegPearson= 1.00063, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 482, loss= 0.00049, NegPearson= 1.00053, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 483, loss= 0.00049, NegPearson= 1.00043, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 484, loss= 0.00053, NegPearson= 1.00047, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 485, loss= 0.00054, NegPearson= 1.00057, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 486, loss= 0.00057, NegPearson= 1.00079, kl= 0.00000, fre_CEloss= 0.00000\n",
      "\n",
      "Iteration 487, loss= 0.00051, NegPearson= 1.00079, kl= 0.00000, fre_CEloss= 0.00000"
     ]
    }
   ],
   "source": [
    "model = ViT_ST_ST_Compact3_TDC_gra_sharp(image_size=(160,160,160), patches=(4,16,16), dim=160, ff_dim=144, num_heads=4, num_layers=12, dropout_rate=0.1, theta=0.7)\n",
    "model = model.cuda()\n",
    "model.train() \n",
    "print(\"iterations per epoch: \",len(trainloader)) \n",
    "print(\"epochs: {0}\\nStart\".format(epochs)) \n",
    "train(model,optimizer,trainloader, 0,0) \n",
    "print('\\nTraining process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2134fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD MODEL\n",
    "\n",
    "epochs = 5\n",
    "model = ViT_ST_ST_Compact3_TDC_gra_sharp(image_size=(160,160,160), patches=(4,16,16), dim=160, ff_dim=144, num_heads=4, num_layers=12, dropout_rate=0.1, theta=0.7)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "model, optimizer, epoch, iteration = load_ckp(model,optimizer,'./ViTVHR_PURE.pt')\n",
    "#train(model,optimizer, trainloader, epoch, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5654bac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([357, 160, 160, 160, 3]) torch.Size([357, 160])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train_video = train_video.permute(0,4,1,2,3)\n",
    "#val_video = val_video.permute(0,4,1,2,3)\n",
    "#test_video = test_video.permute(0,4,1,2,3)\n",
    "def test_chunk1(model):\n",
    "    print(test_video.shape,test_bvp.shape)\n",
    "    dataset = torch.utils.data.TensorDataset(test_video.permute(0,4,1,2,3),test_bvp)\n",
    "    testloader = torch.utils.data.DataLoader(dataset, shuffle=True, num_workers=1)\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    rPPG = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader):\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.float().cuda(), targets.float().cuda()\n",
    "            rPPG.append((model(inputs, 2.0).cpu()[0],targets.cpu()[0]))\n",
    "    return rPPG\n",
    "    \n",
    "rPPG = test_chunk1(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73a47683",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rPPG', 'wb') as f:\n",
    "    pickle.dump(rPPG,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1035b33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([24., 31., 43., 57., 64., 62., 57., 51., 45., 43., 43., 44., 44., 43.,\n",
       "        40., 37., 33., 31., 29., 26., 26., 25., 24., 23., 27., 38., 53., 66.,\n",
       "        70., 67., 62., 57., 52., 49., 48., 48., 49., 46., 42., 39., 36., 32.,\n",
       "        30., 28., 27., 26., 25., 26., 31., 44., 60., 71., 72., 69., 64., 59.,\n",
       "        54., 51., 50., 49., 48., 45., 41., 38., 34., 31., 28., 26., 25., 24.,\n",
       "        24., 24., 28., 40., 55., 66., 68., 63., 55., 51., 46., 45., 44., 45.,\n",
       "        42., 40., 36., 33., 29., 26., 25., 24., 23., 23., 22., 23., 31., 44.,\n",
       "        57., 62., 60., 54., 49., 44., 42., 42., 43., 42., 40., 38., 34., 31.,\n",
       "        29., 27., 26., 25., 24., 24., 23., 27., 37., 51., 62., 63., 59., 54.,\n",
       "        50., 45., 43., 44., 44., 43., 40., 38., 34., 31., 28., 26., 26., 25.,\n",
       "        24., 24., 23., 27., 36., 51., 63., 67., 64., 59., 55., 51., 47., 46.,\n",
       "        45., 45., 42., 39., 35., 32.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rPPG[r[0]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36a1a9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146, 166, 215, 146, 166, 215]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADSCAYAAAAPFY9jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABJTUlEQVR4nO2dd5yUxf3H37O7t1dpR4ejCiigiIo1CVERCyaYYsFYMNFUTTG/aGzpMRLTi8YkGrFjS4TEChprVDwCKCJNitSTdhzXts7vj5l5ntndZ/d2r3C7ZD+v173u2XnmeZ7vM89868x8R0gpKaKIIrzh624Ciigin1FkkCKKyIAigxRRRAYUGaSIIjKgyCBFFJEBRQYpoogMKDJIEUVkwEHBIEKIjUKI0w7wM38ohLg/y7p5S18+05YPaBeD6EZtEUI0CiHqhBBzhRBV+tyLQohWfW6XEOLvQojB1rVThBD/EkLsFULUCyFWCiFuFkL06ayXylf6hBCHa7qk/ktHW5M+/0ESbacJIbbqc3EhxL7ObDtN37O6XTxHkIUQs4QQ72ka3xdCfMw6VyGEuF1fv08I8XJn0KXvPVsIsUQI0SCE2CKEuFUIEbDOXyWEqBVChIQQc5OuHanbrNH6+142z82ZQSyiPimlrAKOBqYAN1nVrtLnxgG9gd/oa08CXgReAw6TUvYGzgSiwJG50lKA9MWBJuAH+rcnbfr5bwDBJNqeBdYDY4FSYFYn0gYQAR4BLvc6KYSYDvwc+DzQA5iq6TH4C1ANjNf/r+4kugAqgG8B/YDjgWnAd6zz24CfAn/LcI/eUsoq/feTrJ4qpWzzD9gIfBd4GwgBW4DTrPO/AP6lj18ErrDOXQms0MevAn/I5plp6Pgi8B6wH1gJHK3Lo8CTQAsggWbgLH3uMk2vTZ8ExujfbwC79fVRYAdwiPXMicBCYA9QB9ygy38I3K+PS4CHgCXJ9Om224P6gHH994ZqegnwFLDHou3Pmr7fA4uBvcBt+p4SeLOd9C0GGjzabiOqo70N7AMeBiboZ10GvGo96z9JbTdX0/YkivGjwJHtbLvHgWAOfeHbwD89yn8KzE0qG6npDuTa53LRIBcCZ6MkbtQUCiGGATOApckXCCH6AZ8FlgohKoETdUPkDCHEeaiGvRToCcxEdWyDk4GPAUOBAHCGLq8G+mSgbwRQhZKMAngHuFmf7wEsAp4BhgBjgOeT7lEOPAEM0n9e9FUBH+rrtwDD9LXDUNK/UdfzA+fo4zJgOKpzzQIqgVpgALBSCPGWEOLMLOl7A9VZp6dpu/NRmnIUMAn1zZLbyo/SdgDPCyG2oCT5LOBHKEHYCDyiTax3UQIxm7YLAedLKcPJz82AqcC7OdQH2KTNs7v1t28bOWiQLyT9bgTqgU3A7UC5JQWb9bmtwANAf6AGxcWHWfe5VddrAm5qg4ZngW+mORcF/mL93ocyF+qBXcD2JPokSppuBd4H7rfo+xKwStf9p753Cn0oZl0AvISS9p706bbaBVxs/Y7oZ21CdZr/6HNbgLA+1whsQEnXB3WZBH4LrNLPliiNlNJ2SfRtytB2Gw1t1jcxz7sMrUFQndzQcCLK1KkDlurzN+hzu1Cm4Y+BGDC+Ddp+D4gcLYkv6Lbql6UGqUIxdwAYCDwGPNvZGmRz0u9PSSl7SylHSCm/JqVssc59Q58bKqW8SEq5E2UqxAHH6ZRSXiuVnf8PTXwmDEN15nRYZx1L4CV97+8A7yfRB8rEGAq8guokhr4KVIOizz2Rgb4TUBJ3Thv0GdPN4F8AUsoRwH1AXAgxGaXpvq7r/A3li4RQbS/1PZ4AqqSUM/XvXWlos+kLZaCNJNqaUW2QDLv9dkopd6FMtcHW+SjQqjVBI4qBTm+DtjlS9+JsIIT4FHALyoTelc01UspGKWWtlDIqpaxD+XmnawshI3JhkA7Ni5dSNqHs58+08xabgUMyPSJNeROJHzzoebFL39SkZ47O8MznUB/reVRnyERfOhj6TkaZVb/Q5ZejTJ1PojTOelI7bhgoz4K+IcDkDtCGlHIvyo+yYbf520nnNuPNaMm0PS+EGJgNMdqk/CsqAPNONtekgaG7zf5/oMdBrgW+IIS4TggxAEAIUYOyfdvCncB3hBDHCIUxQogRWVy3HJgohJgshChDOWyZ6DsL6KHp+xfKpzkJ8AshegghjrcvkFIak+QQ4NpM9AkhBMrP8enfZSgpPBHlJywGVujqD6Gc3+f076+j/IcfAD4hxLn6dylwghCiNAN9/wJ+IISYlqntNH0BlC8EKuBgt912XV6tQ8sTgbW67GWUn9VDRxJ3afoGtkHbgygmyegTCCFORZnrn5VSLvY4H9A0+lHfqsxENIUQxwshDhVC+IQQfVFm3YtSyn2ZngkHmEGklK8Cp6Kk9BohRD3KiXsR+EMb1z6Kcp4fREVinkA54G09cw3KHl6E+phpG0XT922UllmDkoINqE79dX39KR7X/QS4F2WizctA3wiU4z1T/25BMcGPUZ34KBTDgDJ1WlHmEVLKp4Evoxzjwfo5e1GRpHKUmZSOvlmoaNKTGWgz9N0IfEL/fkfTYdrOfKNFKObZjXLEkVJG9LVlqDb+HSrMe3wbtP1E07NICJHpe34P6AU8ZY1lPG2dvwnVntcBF+tjEz4fjepn+1ECKIQKOrUJkYP5V0QR/3M4KKaaFFFEVyGvGEQIcUfSdADzd0d30wbZ0SeEeDpNnRu6m7bupC8b5CNtRROriCIyIK80SBFF5BvaGpzLS/Tr10+OHDmyW2lYsmTJLill/+TyfKYNup++TLTlIwqSQUaOHEltbW230iCE2ORVns+0QffTl4m2fMT/hIn1zDPPcOihhzJmzBjmzJmTcv7Xv/41EyZMYNKkSUybNo1Nm9xv6Pf7mTx5MpMnT+aYqdO5/u/JA8b5gfnLtnLLU+8Risa6mxRP/Oyp9/jLy5lmu+QnClKD5IJYLMaVV17JwoULqamp4dhjj2XmzJlMmDDBqXPUUUdRW1tLRUUFf/rTn7j22mt5+OGHASgvL2fZsmUAfPext/n3qp3d8Rpt4o8vrGPth41MGNKzu0nxxIurP2R0v6q2K+YZDnoNsnjxYsaMGcPo0aMJBoPMmjWL+fPnJ9Q55ZRTqKhQ04ZOOOEEtmzZ4nmv1miM0pL8bLKKoJ/yEj8zjxzS3aR4IhqTBPyiu8nIGQe9Btm6dSvDhg1zftfU1PDmm2+mrX/XXXdx1llnOb9bW1uZMmUKgUCAXiecR+mIKWmv7U7EJZwwuho1nSr/EInHKfHnp3DJhMKjuAtx//33U1tbyzXXXOOUbdq0idraWh588EFeu/9XxOp3pFwnhPiSUOuha3fu7BwTrC2/KRQKccEFFzBmzBiOP/549u/cht+Xn8wBWoPkMX3pcNAzyNChQ9m82V3KsmXLFoYOHZpSb9GiRdx8880sWLCA0tLShOsBRo8ezYBxR9G8fV3KtVLKv0gpp0gpp/Tv3/EIpvGbnn76aVauXMlDDz3EypUrE+rcdddd9OnTh3Xr1nH11Vez+p934MtT7QEQicUpCRRedys8inPEsccey9q1a9mwYQPhcJh58+Yxc+bMhDpLly7ly1/+MgsWLGDAgAFO+d69ewmFQgC8/8E2Nq9aSr+a9iz5yA3Z+E3z589n9uzZAJx77rnsXruE/GUPiMQkJUUNkn8IBAL88Y9/5IwzzmD8+PGcf/75TJw4ke9///ssWLAAgGuuuYbGxkbOO+88Jk+e7DDQe++9x5QpUzjyyCM5bdo0eh5/HjNPPq7Lafbym7Zu3Zq2TiAQIFBWRaTZeyZ/Nibgss31jLzuSdbvbPQ831FEY3ECBeiDHPROOsCMGTOYMWNGQtmPf/xj53jRokWe15100km8845auPaPpVu4+uHlTJ+Q1eK3Aw4pIZ2FJaX8CyolD1OmTPGcfPfwW8oMfW3dLkb37/xwbCRejGId1IjGVL86EI5wNn6TqVNTU0M0GiXa2khlz+zyx63esZ+5/9mIPVH1kVr1vMrSzu8SkViccDROia+oQQ4YorE4L6/dSUs4nlBeHvRx8rgB+Dq5I8fiB45BbL9p6NChzJs3jwcffDChzsyZM7nnnns48cQTeeyxx+h9yFH4s+yA/1i6lYcWf8DAnm4wQr8eFcHO7xJPr1CRv0IM83ZKa+jF9L9DrQe+U0o5J+l8KWpJ6jGoZZoXSCk36nPXoxIUxFDZUJ7N5pmvvb+bL8z1nlN09+eP5ZRDB3ieay+iugcdiFCl7TfFYjG+8IUvOH7TlClTmDlzJpdffjmXXHIJY8aMobq6muFnfiPrKFZcSspKfLx5g5uSd03dfk7/zctE4/EMV7YP+1sjAJw3pYZvdfrduxYdZhChEordhkpKtgV4SwixQEppxyUvB/ZKKccIIWahkrRdIISYgEo8NhGVeWOREGKclLLNCUUtYZW77k8XHc0hA5TN3NAS4dw7XmddXWOnM8iB1CDQtt9UVlbGo48+6vw+8ZbnyVZAx+MyhZlKdQg2HO18Bonoe5aV+NuomX/oDJ13HLBOSrle50Oah5sd0OAc4B59/BgwTWfQOAeYJ6UMSSk3oHJbZRUmMibBqP6VjBvYg3EDezBxSC/AlfadiZijQfLTTIh5dPp0iEs8GER13tZI5zOIo30L0EnvjK89lMSkclt0mWcdKWUUlfWib5bXeiKuHUz7Q5u+G++CVZKOBsnTjxyXZO13SWRKxKtEv1dXmFgRHeAoRCe9YChOjuUbJWEziF8fx7pAgxxIH6Q9iEtJtqRJDw1iNKOJ1nUmojHFdP+rGmQrOhmzRo0u86yjk3n1Qjnr2VwLpE7nkI4GcesY/6ArGCSmJWu+TueIxaUjINpCXKZqEH9XapA8Fy6Z0BkM8hYwVggxSggRRDndC5LqLABm6+NzgRd0PtYFwCydeW8Uat+LlKx5XjBMYHdYIQRCdI2JVRAaJEvalLZJ1iCGQbpGgwR8Im9nGmdCh6NYUsqoEOIqVHZzP/A3KeW7QogfA7VSygXAXcB9Qoh1uOn80fUeQWUTjAJXZhPBAjxNLFBmVldokHhcSd3OHl/pLHhFptJBmViJZYZBYl1gYkVihTnVHTppHERK+RRqIxi77PvWcStwXpprb0bvx5ELjJZI7hM+nyDWRRokX7UHKIGRbQg6LkmR5ubaSBcIl0iBLpaCAnLSk+H4IL5UDRLvko8cz9sQL0DMw69IByllysxfIQQBn3B8rc6E9DDpCgX5+8XbgOGBZMfU7xPEOv8bE4rG83a5LahOmIuT7tVho3HJbf9+34k6dRptpJ9Ime/I3y/eBuIeUSzzuyNOejQW565XN9Cgp0cYhKNxZ7Q5H5HLQKGXD2LjxdWdm5jCK6xcKMjfL94GjAbxsqU74qTPeXoVP/nXSu56ZUNCeSgad0ab8w1SypwGCr18EBvtDfXu2NeaMEPYfV6qSVcoKFwGiXtrEH8HnfTt+1oBlSXERigay1sNItOYm17Y3RTm8f9uyWjytKf5Nu9p5oRbnuf2F1NzXxWyiVWw0929ppqY3x0JVUa0/X3HS++ztd7dlu/tLfvoXVHS7vt2JWJpzE0vtEZilKKkfTJmHjmEBcu30dqO5HPGJP3Fs6v58tTRCasHFXmFySEFzCDqf8o4SAc1SH2z63v8c3nilnynTxjU7vt2JeJpInpeqAwGiOI9IHjNGYeyYPk2rn54OQ+9mbhnqxDwzWljOWmM905ptlVWtz/E0N7u1okyh2kw+YaCZRA3zJtY7vd1LMy7uynEjCMGcftFx3SEvAMK0zmzcYR7lgfYk+aczWDrdzUydoC7CeybG3bzwqoP0zJIOOZqneT2z7QcON9RsAySzsTqqAbZ0xSmutJzI9y8hXnfbAarMznn9kDoby6YzMfGuimMjvzRcxmnoYSsafLJzS+RiAI1sfLT68wC725rADp3qkksLqlviVBdUVgMkk5YeCFTDXskPtnhD/gEW/Y285uFa6hrSPVfQtbYSXKYva2wcj6jIBmkJRxj/jLlH3hNNUn+QNlmKRw7dgzb7vk2sYYPnXO33HILY8aM4dBDD+XZZ7NaDXzAEfeYuNke2Bok2Z8J+AWL3vuQ3z2/lj+/tD7lWluDJGvwtsLK+YyCZJCwJa3a0iC5ZCl8ufYdek45h7//+VYAVq5cybx583j33Xd55pln+NrXvkYsln/bCzizCjoopm2mSL6XPc1md1Mo5dqGFje4kTwWIincbf4KkkFsWzhlJN0nePbdOicBWi5ZCmNxScVhH+Xdt15DSsn8+fOZNWsWpaWljBo1ijFjxrB4cVaz8Q8oYmnGhHJFIBODWJMNIx5TUX67aI1znGLhFrCTXpAMUmbNiUp10tX/U3/1EpBblsJITCJ8fip69GT37t1ZXQudm7x6z549TJ8+nbFjxzJ9+nT27t2bUmfZsmWceOKJTJw4kUmTJvGPxx4BOj4Vvy0fxCCUtG59yaa9bLPGVVJ8EIpTTQ4oKoMBXvi/j/OTTx3uOZu3vTBTLHK9Q2cmr54zZw7Tpk1j7dq1TJs2LcFn2lbfwqKVdVRUVHDvvfc6pt/3rr+GeGtjJ/ggbndI1iDv72xyjpMHEpdsSgwcJwdJvFYwFgoKkkEARvev4pITRqSUJzNMLlkKozGJjMdobmygb9++WWeG70zc9cCjvO6fSDwumT17Nk888YRzbuYfX+OKe2sZN24cY8eOBWDIkCH07defWPO+DgkH8F6+7IXkzCcj+lYCcOFxwwGPMK8s1HH0AmaQdEjuJNlkdzdZCiOxOM2rXuWoEz6GEIKZM2cyb948QqEQGzZsYO3atRx3XNcmr967eyfLd/toDEcZNGgQdXV1zrldjco5tp3gxYsXEwlHCPQZ3GETy440ZWaQRA1iEj0Mr1a7dB1MJlbBDhSmQ0p4MocshTOnHkNDOMBX73sAgIkTJ3L++eczYcIEAoEAt912G35/x2f0nnbaaezYkboRz803uwsrm0MxepaVOJ320VpXk8Ul+AVs376dSy65hFt/fwdXv9ic1kkXQnwJ+BLA8OHD6VcZZG9zOCONmTp0MoMYp91M5vQysQpVhRx0DOJlZmSbpfD193dz4V/fYNjIUc65G2+8kRtvvLFTaXzg7/9i5/4Qhw/tlXLOX9mbaOMemsNRtm/f7uxXcsM/3nHqRONxmhqbOPvss7n55puZdMyx8OJLaaV+cnb3/1w/rc3Qa/K9bphxGD97ahWQamKZsLtZUOYZxcr4tPxFh0wsIUS1EGKhEGKt/t/Ho85kIcTrQoh3hRBvCyEusM7NFUJsEEIs03+TO0IPdGwswEjCrk4wMON3r/CJP7zqea5izPE0rXieplCMe+65h3POOUfT5va6ltYQn/70p7n00ks599xzcx4oDAZ8ade2DOlVBqQKGjttaPJW06bdyvQ9vcZBCnWgsKMa5DrgeSnlHCHEdfr3d5PqNAOXSinXCiGGAEuEEM9KKev1+WuklI91kA4HHfkO9/xnIwDlXZxDdneTMm9u+3fidm59KoL0POFcds2fwxknTWbCuEN45BEVwg1tX0vjsqfpe9Y3ePTRR3j55ZfZvXs3c+fOJRSNEz72iwR8R3eYNsMI4aQB0eNGVTvHzeEYq3fsd35v3auWBaTTIIU81aSjDHIOcLI+vgd4kSQGkVKusY63CSE+BPoD9R18tic6IqmM9pkwuGv3Gu9dUUJ9c4RfPLs6lYbyngyc9TNunDGeL04d7ZSXDh5L6WAVuTr3/M/xxc9f5pxbsXUfn/jDq52SkmjswCrW72pK2UrhsEFumzSHY5zx25cT6fYJZ5GZZ5i3QI2sjjLIQCnldn28A8i4/ZIQ4jggCNjLzm4WQnwfeB64TkqZOo/hACESizOppleX5776+Lj+1G7cywvf+bhT9ty7dXz9oaXO7+Q18TaSZ9WaqFFnpCX61fmT+fTanYzqV5m2zh0XH52iJQb1KnMyw6eYWAU8kt4mgwghFgFeK4USPFcppRRCpPX8hBCDgfuA2VJK4+Vdj2KsIMqJ/C7w4zTXJ0Ri0iHSgfT9kQO0VXE0rvbnsP2A5K0BHnjzAxaurEu+FEiV0IZhOoOxq0oDnHn44Ix10p1/a6MaMEwxsTpMVfehTQaRUp6W7pwQok4IMVhKuV0zwIdp6vUEngRulFK+Yd3baJ+QEOJu4DsZ6Ghznz2Aj43rx+vrd2d6pbQ4UBkA43GZEkwoseY6lQZ8TBmRGO8YXl3Bc5phkpMqGCe9uxPbmccnz+Yt5LxYHTWxTM7dOfr//OQKOl/vP4B7k51xi7kE8ClgRQfp4ZAObEAZicW7ZI++ZETjMsXGtxnzqlPG8PVpY1Ouu/LB//Lk29t5f2cTNX0qEu4HHZtmkw36VZVyZE1qaNrA+H9e60EKlD86PJI+B5guhFgLnKZ/I4SYIoS4U9c5H5gKXOYRzn1ACPEO8A7QD/hpB+nJqpOsqdvvmAM2DoSJtXFXEwtX1qWs/rOfW5Ime8rpeofd2X9LnFFsNEhX735Ve9Np3HXZsWnPm7ZPDfMWLoN0SFxKKXcD0zzKa4Er9PH9wP1prj+1I8/3QjYb3Jz+GxWB2Tjn7ITyA2Fiffr21wCP/Tms5/avKsULYwZ4a8d82cHJvFNyWq3/ZRMr79ARDRCJxdNK787CXp01ZV9LYpTK9kEG6cG6ZEwc0osTRlendMBYDktuuxIijQ8S/18dSc9H5GKHJy/8icQkJV1opvzfI8ud4027mxPO2ZEfe3vmZAR8vpQOaPKAdXdybV8GE6tQbayDToPkEupMNqminWhibd7TzOY9iUzw+H+3ZHWt7YAnw+8TKeMgjgbpZnFnfKDUkfTCTT160DFIOjvdC5GoVCMwGuGY7DQT68K/vsGWvS1tV9SYPKw3f77kGE4+tH/GHMDv72xky94WPqN9GXCT3R2oLarTwQnzemSV+V+dapJ36FdVygmjq3ljvZoRWxFMfEX744VTTKx4p5lYDS0Rzpw4iM9/ZKRTdv+bH6Rka7RxxsS2Mzcapivx+whqZq4sDTBhSE9G9k0/+n0gkC7Mq1YUFiaHHHQMAjCsTwVvsIdt9a0pGmXZ5nrnONUH6TwTKy5hSO9yjh/d1ynbtLvZYZAfzZzYofv/5dIp9CrPr1zBRrYUVxTmOaaNV+MFYY9pJ02hqHOcvOVxtBNNLK9tme0NeGafNLJD98/HTPOuD+KVOK4wWST/WrkTYDpi8roFVeYyjW1iSSkJd6KJFfOYTtKZnTofN8U0THAwrSjMv1buBJTqzvPrhWtSztlM82FDK3UNrWzf18LmPa5t3xnw2pa5b5oBwPagux1yL4h0JhYFyx8Hpw9iNMMra3elnLNzOn3uzjdTzld00lysWDx1z8DkCYgHG3xp52Klzj0rFByUDNIcTp8etEUnHLjmjEPpVV6CTwh8Qn3ckoDgtPEZl7RkhXRbohVqJCdbGK2WPJCppvcX5rsflAxyyqEq0cEpI8uZPn06GzduZOTIkdzxt/u46YkVCAGXf3QUZSV+li1bxle/+lUaGhrw+/2Eb7yRCy5Qy+Yvu+wyXnrpJXr1UjNY586dy+TJkzM+Oy4lX7pvCdA1s2uvO+swnn5ne9sVuwHmdZOHQWJ5vsd8JhyUDFIe9NOrvIQ1z93PJ6dN47rrrmPOnDncfMsc6Dmdzx033FmgZLIUjh07lm3btnHMMcdwxhln0Lt3bwB+8YtfcO6552b9bIFwFjp59Yll35+emvUjB3zl44fwlY8f0v4bdCHSTTWJxgrXxCpMqrNAwCdY9eYLzJ49G4DZs2fzwrNPAjB9gmtGJWcpHDBgAB3Jr2srjedXpa4f610RLLgNerKF35nNm2xixQtWgxy0DOL3CZrq9zB4sFoeOmjQIHbvVB02mCZStXjxYsLhMIcc4kroG2+8kUmTJnH11VcTCuW2XH5/hnXlByOcMG+ShozGZbdPxW8vCp5BTjvtNA4//PCUv4ZV/8FeDS2EcMR70GM8wmQpvPvuu/Fpc+CWW25h1apVvPXWW+zZs4ef//znnjSky+6evM48W2ST4d2goaGBmpoarrrqqnY9qzMhdLMmm1iF7IMUPIMsWrSIFStWpPz1P+KjVPTqy/btyqHdvn07vavVBpTJDNLQ0OBkKTzhhBOc8sGDByOEoLS0lM9//vNp9wZJl929vQySKcN7Mr73ve8xderUdj2ns5EuzFv0QfIQAZ+PkUdP5Z577gHgnnvuYdxxpwCJg4HhcDghS6ENw1xSSp544gkOP/zwrJ5t1m2nM+XagtnQB0jJ8G5jyZIl1NXVcfrpp7frOZ0NvzOSnlgejccTFoQVEg5aBvH7BJM/MZuFCxcyduxYFi1axJpBanXw28v+yxVXXAHAI4+oLIUmhDt58mSWLVsGwEUXXcQRRxzBEUccwa5du7jpppuyevb1M8YD3tO+s0FdXV2C72RneDeIx+P83//9H7/85S/bvF9nbvCT+TmaNg8TKx9H/rNBh8K8Qohq4GFgJLAROF9KmWIwCyFiqMQMAB9IKWfq8lHAPKAvsAS4REqZOe14lgj4BPtkOT/40zyn7KYnVvDBnmY+c/pULjjrZAAuvvhiLr74Ys97vPDCC+1+NqSm57GRTYZ3UL6T1wDj7bffzowZM6ipqWmTnmxTJnUUxsRav7OJl9e4jNgaKdwo1oHIzQvQIqWc7FH+c+A3Usp5Qog7gMuBP3WQJgB6lZfw5oY9XJqUAeRjY/t1+US/wb3LAZg6Lv1uU4sWLUp7buDAgWzfvp3BgwcnZHi38frrr/PKK69w++2309jYSDgcpqqqKqO/0tUI6PSjj/93S8rqyXybmp8tujw3bzroXFinAp+zrv8hncQgf7r4GDbsakwp70jerGwxtHc5b94wLW12krZgNvS57rrrEjK823jggQec47lz51JbW9utzAF6A9VvTeXD/Yn7qAshmDika/MddxUOVG7eMiFELRAF5kgpn0CZVfVSSrNAYwvQafubVVcGqa6sbrtiF2FgT+/MJNnguuuu4/zzz+euu+5ixIgRTob32tpa7rjjDu6888427tB9GFZdwbDq9GvqCw5Syox/wCJUxkPzFwY2oLRHfVLdvWnuMVT/H43yVQ5BJYpbZ9UZBqzIQMeXgFqgdvjw4RKQa9eulckYMWKEXLhwYUp5Z2D27NnyxhtvlFIRVOtF5zHHHGPOp9DXlbTZ9KWjzdCXru26EtnQlo9/QiZP3m8DQoiNwBVSykVCiNXAydLNzfuilPLQNq6fC/wLeBzYCQySUkaFECcCP5RSnpEFDTs1g60Akoe3j0Ax4X6yRz8gdW58KkaiBMQ2YISUMsXJ0LRtAo7R9AWBwUAF4AfWpKGtCjgU2K7vbzBIn+sBxIHdKG2bib4SL9os+uy262HRZwdTbAxAWQcBff91uO0+AKgETE7SfSgBmjNtHrReg0ppOwL1fW6XUv7COv8TVMra8cBPpZQ/tM6dDLyA2p/G4Eop5T3ZPNtBrhyF6nyn6eNfoLYsAOWg3+pRvw9Qqo/7AWuBCfr3o8AsfXwH8LUc6JDAmEz05XCvrKQaMFd/iKzpA44DLkFpwKgXbUAJsAx4w74/irlagW+jOmEZMKmj9Nltl0TfRo+6VwBvAxNQ654OAaqt8/uBX6MYpAQ4qqNtZ11zLXA0ijEPRQmeWdb52cBZqJzQP0y69mRgS679O4WGdjLI9cBK1CY421ASpcnq7FOAu1Aa4jJglf4oW/Q121GZ3EcDi/X1jxpGsp7lB25A7SeyHxUKHmZ95K9ohqsHbtMfcCPKLKwH9gJ368aVwEx97YuoPMARTXeDPv8l/T679H3qgc3AZckfGSV5/w38J0v65qMY5HrdLiFNW5l+nkQFKn4KvKTp2qzLJYpJtum2+6N+bib6emm66rNsu9P0O/8QuF/X8+lnSiBgtd1PgNdQ0jkODLC+2UezoM203e9BWTFZ9r3fA3/wKL+fLmKQ9jrpFwFnoD7iP/XLhoFPAvOklLVCiL8DJ0kp5wohXkSp3VdQEmk0Sv0tk1Jm2lf528CFwAyUaTKJRJX5CeBYoCeqA/xTl0/S979Cl5mJSrNQGelBhZQ/AA5HdViAU1CRtSUo6X0eyu8ZZhMlhOgLPI1irB5Z0vc2ioEvQu2TUgOMQ2nh5LhzH5Q0fhNlXvUGbkV1vPtR2vYW4OP63l70LUUx3/FZtt1mUlGDMr8ANgghovodhqEk98UoAfaCNrG3AGNRbftYBtqeBp6TUmY38ooT9fwY8OdsrwEGCCHqUO/9BHCTlLIph+vbPZL+RynlZinlHuBmVCd+EJgphDAhjM8BDyVd9yMpZZOU8h2U9LywjedcgXqp1VJhuVQJsw3mSCnrpZQfoJh0si5fDDRb9JmN0T9p0fchcI+UsgWlcQB+BHwaeA7VCc+XUu6WUi6znjkEJeEfRX38bOkz9/gjirHCmrYvoCQjKI0Jyt5/GdXBeuiyN1DMPgelGQZJKSMZ6CsDvphD240hFfYo5GSUABkAvCPV1nqDNM1SH69EmUML26Dt0VyYQ+OHqP56d5b1V2maB6OE3jEoUzAntJdBbGmzCRgipVwHvIfbCWeimCbjdW08ZxiJ27Ulwx6KbkZJW1COov0cE35+D6XlfCizy9BntpzdbD0zHX1nA+UoBsqFvhBK+tptMArVkefq38NQHawvaku6FuAtfc4H/BLli+xOQ5tNX1UOtDVrOpJhp4bcJ6XciDK5hlvnd+lzEZRJuw/4SBu03ZGBrhQIIa4CLgXOlllu0Sel3CGlXCmljEspN6D8mc/m8lxoP4PYanM4btTlIZRWOAdYqZkmm+vSYTPKKcwVZaiojHmOiVA9rOnrB2xLQ595Zjr6/go8AzyFMilypW8YyjStQNn9AmXigLLfv4WSyDtRZpkJM5pRRyOt07WdoQ+UY50rDG0Aq1F+WjrY9IFqu0yrwZy2E0JklQZSCPEFVABompQyu+TG3pC0p7+300l/B6V+q1HS92f63GCUNHoZ+KZ1zUhN4AOoxp+IMnFOb+NZ16A+wlhUR5qEkq5n6vttwo2izUU5uBtR/s4eVMj3dZRUkyi124xyIB8HFqIc1dUWfeNQnSIGrEeZFZOTniGAO1HBhXeS6DvPup/xL8r0s+Ko8OolKC2wBKXVQrp+FMV0G4F39f+YPvchSgru17/rUD5E3zT0vQk0onystG2n6bsPJdw2ofypXSgB0UvfQ6LMpxrdfg/p93lf07wOZWp9xaLt7Tba7gWgvI3vfxFK041Pc75Et+2D+t5lgF+fOwUVHjY+07+Bu3Pu7+1kEDuKdQ9QYZ1/XjfaIA8GMVGiHcC1WTzLD9yE6vD7UebGcP1hJCr+vRwlKc0HMPTt0XUaULanRHXO5/XxC7jM9aRF326Uf/ABSpqGUBuPOh9ZuhGe+1AMttGibyMqCCFRnX82biTK/Jn7hoGtqKiQREWo4igmeVw/5+/6XAzFuGHgdhQDRVFS24u+AMpRb26j7bzo26q/7Trgt9bzN+tv8YzVdv/WdDXqtngXxZxttd29KF+vLMP332Dd2/zdYZ2f60G7iZp9W79Hs6b790CPLmeQ9vzhMkigE+51IvCs9ft64PosaVhh/V4NDNbHxxr6UFGSC73qFTJtXUjfYGC1Pu4Qffn4V4jrQYaS6Oi2dw6XPY/MXiTRkfvnM21dRZ89B6+z7p836HYGEUI8LYRo9Pi7obtp0zgSeDkTfUKId4UQjeh94E0dlMTuVtq6mj6pVIVss2IaGNo8/i7qKG2dgQOSF0uq8KDnihkp5Vk53m4ridGwGl2WK5w93lG28hqp5oQl3383cIQlMVMgpZwIkDyfTAhxfTvo6lTaupo+PUBo8hvl/G0MbfmKfNAgw4QQ/xZCrNTS5JttXPIWMFYIMUrvwW6PjucCs8c7JO7xvgC4VCicgIrxZ5vKMJ9pKwT68g/d7QShnLyj9XEP1LSICW1cY6Z2vA/cmMUzHkJFiCIou/hy3MG4taiR9GpdV6DmJr2PCuFOyfF98pa2QqAv3/5ynu7e1RBCzEdNZVmYrk6/fv3kyJEjDxxRHliyZMku6TFtO59pg+6nLxNt+Yi8ys0rhBgJHIWKo6fFyJEjqa2tPSA0pYMQYpNXeT7TBt1PXyba8hHd7oMYCCGqUKPb35JSNnicPyCpa2zc+cp63li/u+2KXQApJb98djWrd+Sy7iu/IKXklqfeY/3O1NwAhYK8YBAhRAmKOR6QUv7dq45Mk72wPdjTFE5ISwOwZW8ztRv3JJT99Mn3mPWXNzr0rPaiJRLjj/9ex7l3/Kdbnt8ebKtvoTns7gG5szHEn19ez4V/7Z427Ax0O4Poef53Ae9JKXOejtwefP7uxVz6t8W0RtyNdj76839z7h2vH4jHZwWTc25/azRzxTzCSXNe4NK73DRLQkf26xpyS/qdT+h2BkFNjb4EOFUIsUz/zejKB67fqdbM2NuxdTfqGlrZWu/OLm9vVsZssXxzPRf8+XXPjU7bA7PlQe2mvW5ZngWA2oNud9KllK9ygPd4LAn4IJS4y2134/ifPQ/AxjlnA6l7bHQ2vjd/BW9v2cd72/czeVjvDt+v1YPRuprJDwTyQYN0KTbvaebrDy1l+z5XOptEyl7SM1/C3tEu7lzlOvN8S4b9HHOB176QRQbJQyxaWce+ZneNz2NLtvDP5dt4Yqm7viigU/G3ephYkeTdX7oJXW2elAcVg9h+WEfgxWgHg4l1UDHI/tYIV9xby6V3u46i+UR2RzD7g3hpkM6yyTsKLw0y97UNTP7xc51yf6NBMu0InAsiHubqQaBADi4GMdJ/+eZ6p6zEI9O6a2KlflSvss7G0g/2cv4d3g6yMfG8fJAf/nMl9c2RTjGLjAZpaacGaQwlRte8tEXRxMozRD2kWInWFlHLdDImllcUK6wZxHTQaMNOTjnlFCZMmMDEiRP53e9+12E6b3piBYs37mHNjtQBNMPkXp2rZ5mKqexqVGHTxlCUbzy0lLe31OdMg+ODtINBNu9p5vAfPMtfX17vlHnxQtHE6mbMX7aVx5e46/i9zBKzL4UdsSrJaGKpejHzcX1+fvWrX7Fy5UreeOMNbrvtNlauXNkhuiuCxrxJHeMwNHm9S2WpYhAjvVfv2M+C5du49ZnV7aahxaJhd2OIW556zxES6bBTM+j85e5Mdi+GPhg0SLeHeTuCb85bBsBnj1Hpm6IeDrZhENtGNmaXl5NuOqj5uIGqao466igAevTowfjx49m6tT3LT1yUB1Wze0nvUDSukvB6SF+zS5PpwD+65io2P/kk83tVwxXrU+pnQmnAOOluG/x20Vrue2MThw3uwaePSr8xjzEDbUY6WBmkoDVIMiIeOzqZb2Qzj9lAx0uDOCaW1UGN2bNx40aWLl3K8ccfn3BNW/PElm2uT+hMpYH0UTRHg2WhDWd8ZhYDzvsR7bFkzKZVdhuUlSi6duzLPPJtZI0d8fOioWhi5Rm8NIj5SPbHdE2s7DpoOBansbGRz372s/z2t7+lZ8/EzWAyzRPbsreZT932Gt+fv8IpMx3dqwOFIokaTN8fSNUgk449EX95D+/e2QbM/W0mNYIjlmHrOPvaBA3ShpPuFeUqBBwUDGI+hHeoMfWcMbE8GSRinHS3rKklxGc/+1mqJ53Krat65USbYcxX17m7K/idyJoHg6RhUHA7cDipTnvktOnQdvjbaBW7r0speWP97oQBVNOmtl/npfFsAdBZ4y0HGgcFgyR3GBuuOZAqKUMeHy0c0xJcf1wpJVd95UuMHz+eKZ+8JGezwexdua/FHbx0GMSDoVOCBLhS3p/E2A6DtEGSlwkY99AgBvbtHl2yhVl/eYN/vu2unPUSSHa7OKFq60ZezykEFLSTbhCKxigP+j13lc3VxEpmttDWlTz28IMcccQR7HjiaZpCMZ466vcp16WDV2cy+4l7RYu8TKxQJAblJSk+iHk32YYOkR673Bpy7DlUZpdam+F27FP7Da7ZsV/lUMFl3ohFvz1uE41LSvwi4R0KVYMcFAxiOpqnD2LGM+J2B1X/vTSIYRojBctqJrK2roExA3rwnUeX8/r7u5kx49SsaTOd2KbNl8nE89CGyRrEZWI0rVmTk0KXVxvY2qsqKbQMbpsmmFjWNaFonBK/L4FpCpVBDgoTy8ssMYh5+CDmu2XUIEkfHFTH8NiyPCPMY21/I+DLoEGSBirBDQe7Jpb6ffN3vsyO+75DaPcWampquOuuu3KgK9XEino4315jNoY0WyvbyturDYsmVjfCdBj7I0kpEUK40s4j4uIl1YxUTHCSrdCv6aTZwssv8nkMXia/S9RD+iZrkGvm/ImND/6XEr9g7c25LaHxagPTVnbo1yugkK1DHvNg8kLDQaFBjHSyP5LT0Y0p4WEv22VmfpY71cS9vysRXTs9W3gyiDMGkT6KFvPocGaKTLKEbs8MZK82iHm2S+pUHc95VzKVGYpRrDyBl4nlmCrGnIrYJlaq9Eyx7z2YLS4lOSqQNOMDJDzL610ymViuD9J+syUa99AgMj1dsbY0iFXWpP0VW0EWGaQbEU5yrMH9IE440zIbzIdLkJTJ0tnLxIrLTtEgXmafgbeJpeoZ5nTNwJxI8aTBbpe4h7ZtK6SbXA9ch75oYuUJ3PlTVlkksaPbEkx6aBCR1PkSzLUO+CBenSnqYeu775KqQZz3k+nr5ArXB0nt+HZky9RLp0G8xjyaQ7GEc+qehemkHxQM4uWDJJtdIU8n3S0zl3pqEEtiixw1iFfo2ZhGXpovkw/i+A3GCe7AXCcvweFMIbG1hRMm92YQ4//Ybd+kI14J75AnC9FyxUHBII7U94j8mG9kLzKKeUjwZEZKGKizOrI/xxbLpEFcbeWea416RIDCiWWGnmhCR81NQrvawiP87RH6tceR7Fdq8YhYNYVSy4o+SDfCkbDWh0vu6KFo3GEg84G9zAvTae1OYDvuneKDJE0Xt+s0e9jvrVFvc7EjA3G2tjDHXmFer4HOhGCIR8TKOOl2WUu4aGJ1GzyjWB5mSCrTpI/gJESxrIhYzgzipUFi6Rlkv+5cXuMg2Wi5rOmy/bWo9/3tZ6TzQbzMW8fEsp7x4poPKUQcHAziIVEzhUs9HdR4+s5nm3C5hnm9HOlkU8lmokadSTHu0QmTNUhHTJjEMYrETu61ECpiPStBM0RSAySOBrGuWfpBfU705QsKmkFMZ231UPPO6LqHsyu9JKUua/YwD+Y8vYqmULRdUSxbEyQ7vI4GscwXk2rU00lP1iAdmMrhxVyZBg/tmceZrgX46ysbUuhLvq5QUOAM4j39G2yp69ZPdihDFsOYb+kVwweVGjQWlzlHseJemsh09FhqR39dZ5M3z68M+tndFE4o63wNkujDeQUv0ptYqYII1Hubso+O6QekZkIpBBQ0gyTPJ7K/USYNYr5vUzhKLC4TY/jhVIloyqV0p6rnSqOiSUefknyQ5Gn6m3Y3OZ1w3KAerK1TWyAkm2ZeYyVZ0+UlTDxMT6Pdom2ZWEkMUt8Sceg78ZC+gMpbVmgoWAaxpX6mqSaZpF1cQn1zOKHOO1v3EY3FUz54Q0tERbFybLGYRydODhIkzxjZtLvZZZABPdiwqymBbvMeXqPt7aHLzNQ1HTohJO5EsWwTy72P47/oa2+YcRigFoiZZ/SuKAEKK1O9QcEySFtq3qusoTXVfHp57c4U8+CXz61x6vz0U4c718bbEeZN8IsiiRqjyYlYqd+fO344oEwR8/zqqiChaJxwNG6ZWKmRo/aYWP2qggBs04ui7FB3NGlWcyTNZEVXU6vfvSvUPZVA0WXlqqzIIAcQ6dZrOGVWJzIS7DGdQysuXbt4854W54MH9SjgK2t3OtrJXNvQGmnXXCx7/MDVdOq3G7FSvwf2KFPloajzfj10srjmcDRF88Tikpb1S9j61y9zyRknMGfOnKzpisUlI/pWAioRnCpzzzcn+2t2SNxq5027mxPqVWsG2WeZWKYNG0NFE6tdEEKcKYRYLYRYJ4S4Lptr4glqPtVp/dXCNU7ZwB5l+IRrOsTjkspSP73KS9jVGHKu+9b0sQBMHdffNQ8s6ReXdGguVvIs3KZwjLc27nE0iMMMoajTuXqWlTh1DdPsagyzcVcTkUiUPQv/xIDzfsRvHn2ehx56KOukdjGpEtH1qwo6DGJPeWnQa+gzTdUB+LVuZ/OefSpdBjH1epUXTax2QwjhR20dfBYwAbhQCDGhrevsj/Tsu3W0RmIp6S+llMTiaoHSSYf0Y29z2LnW7xNUVwbZ2xxxmK004KdPRQmNra4E71muOm2TNntynu7uMSBna5XL577ldK6e5S4zGP8ikWnce/164Ro2rX6bQO/BlPQeRBQ/s2bNYv78+WSDeFziFzCsuoIPjAZJCm2D66SHPMaMDFQ7awaxNK4pMwzSUGSQduE4YJ2Ucr2UMgzMA85p66LkMOyLq1N9iYbWqDN/qndFCfV6WwTjS/SuKGFvU9jpGH4BPcpK2N/qmgclfh9Bv4/mcCwrHyQuJVc/vIwXVtUpOtMEDo4bWQ3Ax8b2d5ihIujH7xM0h10NYhikKRxLuG5wrzLqd9UR7NUfIWDhyjpqamo8sz56ZTWJxZWQ6FdVyh4dRo5LqNYa4F86i0nM8ktWbN3nlPl9gsMG9QCgvjniCKc+GUysYhSrfRgKbLZ+b9FlGZEsxbbsbXYY5CfasTad3ycEfSqCjgYxvkS1LjPX+X2CnuUBGiwN4vcJyoN+WsLZOekCwT+WbuW97ftT6Hz23R2A6mADepZySH/lAxhm9/sEFUE/TSFlTgV8gsqgq0FiUnLIgEr69yhlX0sEKSUBv49+VaWs+zD9TrJeie3Mu1SVBpypIfG4pKZPedp2/sQfXtX0qnD3N6Ypk3T7vlanDStK/QT9PsUg+tKKYICATxRNrK5EshQ0HfjaMw8F1AxSY8701VJwrw7hKgYpcUKPxpfoXRFU0k9/SSEEPUqVBjGd1idUp1UapG0fRAjl7DdoaWmHYu9+bSOgGCLgE1TqzukwiOmwoSjRuMSn64By3A1j9ypX2rCizwAi+3ZywZRhbK1vYfPmzQwd2qZscWjw+wSVpX4nWBCLS0oDPj53/HD69yhNod8grsPdJuNJc9I79CwvccLiqg2VJixqkPZhKzDM+l2jyxKQLAVtJzbo99EciTpSzGYQMz2ksjSAlMqhVyPiUFXqVx3U0haVpUqCx5M0SHMklnVWkx5lAc85Vfo9iMZU568I+mkOxdzO5dfPCse0jyCcfTyatZPu9wnKSnyEY3EGHTKB8J6ttOzZTjwaYd68h5k5c2ZWja7GdARVpSXO9HSjVSqDfs8pN861mrYE5rXaq8q0ofbZhBDadC08DZIPWU3eAsYKIUahGGMW8Lm2Lko1gWJUaXPExOIbQzHi2hywN4yJS/WBy/R1tvQrDwZoibjayK81SIv2QbKJYvUqL2HL3pYEOg2a9H2M+bRDT2FJeJZ+fkAzEbiM7ROC0oCfUDRGnCCjZn6d2777eXbvb+Xib3yFiRMntkkf4DBgVamfcCyu7iclJX4fFcGAIxBiceloUOdaw0ilLvPaWrg8GEhgaID+PUoP7E6tnYRu1yBSyihwFfAs8B7wiJTy3bauS+5UzVYY1Hy4Fq0dhIAya9NK09HLS/yEonEnquTzCSpK/AlOss8HFSUBZUZkOVC4flcTL63ZycptDQ6d3zh1DKCc12hc4vf5qCzVHUnXCfiE+6x4HJ9PUBZwGduYZkG/zxk47Dv+BH7/95cZ+uU7+co3r8mixXX76TYwZpLSmjgdX0q1eCsal/SpCPLlqaOdrPRxY/4FXQ1iM4Ni8mjCuNHjXz2J3846Kmv68gX5oEGQUj4FPJXLNSbk6bM0iO0UgmaGuCQY8LkbxmjpLIQrnY2T6hO4Jk6ShqpvDhOPk1PiuA27mhxGGztQRXz2NUcsH8SfMGru8ymttq857HS48mAig/h9gtISH01Nyk+xtUwuiRHiccMMupO36jC2TzjtZ8wkw0jOiH4Kc0Udx121v/teuY4b5Ru6XYO0F66JhdYgUedjutuLuR+zPEWDuNuQGRvcRJFaLG3kE4Jdq95k0Y8/x5JfXELt/LvbpO3BL7r7hxgn1/hF9S1horG4fpZyyM2zAo4Gs5jB7CViwsy6LGS9W2XQ7ajZIhqPE7A7eViFxH0Cy3SKEpOKLhNubtTM4BOCCsvEktL1z+w2zHVyZ74hLzRIe5AQZSoJOL6FT7gbwbREXLPB3pPP2NBlDoNE3XsF/UTj0hkYk/E4r917K4dddgu+qr6s+tu32hytHt2vCtBjAbrj9DAj4iE3Glap/Y0EE8/xQVTnEpp2u8z4ILGYJODzuVomh809zQBqme3j6A5taxBj6lVp+htbjSBSA6slfpGiLSqCKjpnTLFCRsFqkGQTyEgsn92pzEcSJHQi4+yaMrNOQd0rMVnz8v/W0nfwcGSPgeAvYcJHz2xztNqMHJuwsj9B2kYd6V0eVJE1Y+IFfHbgwA0pl2umiUscDRKOxp1QsJs/NwcTK0mLGtPTvp8JQfuFq0EaWiMJmqEiGHDGaEyZbfIWOH8ULoMYqWtscGe9RlKnMpLNtuVNPacjhFwfpCKJaeq2b6PPgMGOCdez78CU0erkMZqyEjX6Xt8SdsKpCQ6tM8ahntXQYmkwx8SKu+9S4ndyTfmFIBjwqSQUMtEHac7BBzEd3zY9jYlVEUzyLXyCHsnjMZq2qtIAjSHVpqbMeYcso375jIJlkLjlIxjH2mgGQGuQuGNO2R3BzKkyJlZjkokF7sQ6IRQTtka0xPawqZPHaIRQI/L7tTkSsJihORRznGtDkxlAC/hdEytqmSxlJT5Ly6FNrLhTp8Iabc+6/XQn9woC2OFbw6hVZa4zb4e7jf9nz1Mz0blINJ7z7Od8Q8EySPL0DNsHAaVBWiNWSNfuCFqqeznp5UlMU1MzlP271RSR5nCU/XvqshqtrixVpkc0nmjX7w9FHQ1mIkiGGc04jKIpmqANnUibjmKFom7nbY+JZUyi5OCFEIlOf0xrhkrLmbeTeFeWBlLCvNXWQG1Rg3QTnCiTlqDNSU5heYkt2VJNCXvw0O58piM3aql+7LHHsXPrJiL1OwiHw7z7ytNZjVYrRzXm0GRGwB1t4bO1lSqzpff+1qhr05e400EC2geJxCSRaCrzZ91+cTMq7zrpcemOK4E7AJgQ7bJGyEH5Ww0tiWtlzJT3nftDRQ3SXTDjC0YKtkbiROIyoVPZjm2iMyqd6BckmljlSSZWWbCEK679KR8+8n223flVDv/omVmNVlcG/U4I10jRymDA9TcsZnQ0iOWr7G+NOsxeVuJPoNHscd4ciToDh2YWcJvtJiU794eckHHKDIMkbRGNxxOYpikpYtWnooQ9ekqPYQazaGpXY+FrkIIP8yY728KKpNQ7USQIJExbNyFOn3MdJErPBkuqf/TU6Ty4XSUemDZ1dFb0VZQGdBTLNUcqSv3OZp62BmmwGaTUfX6/KjVhsLzEn2AGlmpmr2+O0Kci6Ax6mjqZsGVvCxf+9Q21j6BPUKbHWVrCcWeOWmnAh08ofyke17MJgraJ5TJD74og9U2RhKhbn0oVxatraGVE34qs2itfUbAaxB7IsxnE5M51wrzWxywr8dFij5onj4P4SHDSAz4VMjYSVdXJTiKaCX/GRFFlAcuc8jn3tZnRdMSGlohrLlo+iN8n6Kkd5r1N4QRnOZtxEJ8QNDl+kM8RHC0Rd4Kk8UMMMwR8Psc/awq5A7Kg1n/sD0UJx+JOQgvjg6jNPAu2iwEFzCBmqok9drG/NepGsYzjbvslQT+NVrg02SG3/ZKGlggBvetUfy3JwV233hZMJMeORlWWBhxtkeiDpGqQpnDM2Wy03DKxFIO4Kw8DDoMEsgrz+oT7PPN+ZSU+1wfxudrORNx8Fv2NocTwrdEWe5pCjnlrFk0BRQbpLiRPNQFlqpiPrgar4okDWFoCgtIERnoa0yRhHlI45myqM7CnyyClJVkyiJ6PZNZOgKLTrPX2+Tyc9CRtZbZcM1P1QW30Y5YBq/e3w9pt+yA+IRKYDUgYaDUmaqU1Gm4YtbI0MfAB7szp3Y1hS1P7qdTvZra2K1QUrA/izLa1Rnn3NoWdTqcc9xhlJX5LgwSsiYmu9LSnmhitAq6EtSWicZDbQkVpwOlMhkGrSgOOORXwcNIDPp/jpAMOY5mReUNTz7ISmla9yr5XH+QvezbzxfGLnXUsbcGOKgVs5rJmCyv6/ZYG1Iyq545Ja4TcrEHf3RROoHNon3LW1DUWNUh3wXbSTQfe2RhKHH12fBB0WeKAGxizy5Wo9liI6Ri23xEMZK9BIjFJayTmjjAHAwnmlAkw7HO0irsG3dSBZAbx0aOshGC/EfT/9A0MOexo/R7ZmVgBfyqDlJWYOWFx57yZSGnmXQEOE8aSfBCAXY2hhImJg3olLt0tVBQug1hOuom7x+JqjTaojh/XKwhtH8CNIrlSscEyccCVirZ58IlJg1VZlk6642y3RlwnvdTSTkmDaoamnmUlDr2GQW0GKfGpUfqSfsMo6VvjLEKqyNLEsn0ovz7uURZQS2QtDdKzLKDXrsQT2i85imXaXsrEpQCf1O21szHUJk35jIJlELOjUjDgczo0uJ3aaIHmcMxR89WVQT5sUB/MSMp+PUqdTIXmA5uZt7a0PXxor4Q6bcEMrO1riTrMWBFM1Q59rQCAz6e0lZHKZqq7zSBGw5nrnSnmpf6sRtJLLA1omGFo73K27G1JMKeG9i5n694WIjE3ElUZDFizeROFif1OAMOrVXi3JNdcrXmGgvVB7MmK5SV+gnqGa8DDLDEfuF9VaYqDOrBnmVPPnyTp9za5SQYuPXEE1RVBPnHk4KzoM7N39zWH6a+f4WU+9bU0iJHufSuD7GoM8cytV3L4rU20RmJs07mrvvx4Ob/95c/pWVbO3uYIAsupTjMXSwjxJeBLAMOHD3e0jqFhWHUFC5ZvIy5dphlWXcF+PdBp2q9/j1KefKeJ8qDfCSZUBAN6wmI0wfw8angfrjzlED4+bkBW7ZWvKEj2bgpF+e7jbwOq8wudwgdwTCwTflR1tLawpLWRbAN6uGWmw5hk0Xa6/opggPOPHZagBTLBONv1LRHHLOtvPcs4+4ZBggGfE0EytJ/7vT+zYsUKapcuZ8jltzPk8tu596lXOOecc5wkc0aD9KkocQZGk+GV9gcSmcFcZjMNJGpgkxLo3W0NCc63SeNqM2gw4OOaMw7juFHVWbVXvqIgGSQUjTtJ2MyHMsnJzEfv7RGLN8mawe0Ig3u5GsRYCL++YDIAV50ypt002vOZjKlmP8ss6qrWNJVaHe4Ibc6ZfUHsdzHmmtFGRhtUVwaRUmWrbwtOW+lnDuvjjnYbYTJS5+21y86e5GrPUktbnHtMDQBr6tLn5ipUFKSJVRrw0aKPzcczHyw5uqLquCaCgem0Zq24ulbVO+XQAWycc3aHaLTHM8zzB1uRHaNB+lUqmvZb0ve08QP56ysb+GB3U8p9zfvue+81ttz3S2ht4Oyzz2boIeNh6jUOU2VCdaXKB2aEyXBrOohpg3EDqzzpV4OK8QRz6gS9/8fBiILUIPZYhJGCn5g0BFADVpAYHfIysYwknjq2n1NmBrc6A14+0Kh+rlQ2GmTi0J4p147TTLutvtUpM9NLDOMde/KZ1Fx5D9c/+l/q6ur4472PAe77Z8KfLjqGycN68xFtGg2y/LCA4/wLPjJGdXw7WHHqYQP0O7llVaUFKWezQkG+mf3BjGNrOtouHVbsVa7CpTFrPlCipHQ7gkFlJ37ovlW2WWTCtoKATxCNS4fJjx+VKn37VAa58LjhnH2Ea9IYz8IwvjGLNmotM6BnmZMrty0cOqgHT1z5Eee3iYy1WCFxgAF6OwY74Zsp29GQGr4d2vvgGPuwUZAaxIZhFpMowSSoBjjl0P4JdcwcJnA7rY2KTtQgtjNvh1Z/9pkjGNWvksG9VUfz+wRnTxrMZ45OXIR1y2eO4KOWdpvzmUnU9Cl3nPrLThrJsOpyvj19HABjBlTxzLemOtud5YpjRvQBEteQTx2nnm+mxwBMG680SPLqxVeuPYWnvvGxdj07n1GQGgTgG9PG8sranU5HH9izlHEDq/jaya5j/emjanh7y74EyXrksN4s31yP39JCPzlnIo//d2vOG3Rmi137XWl7/pRhnD9lWML52z53dJv3OHvS4AQnuU9lkFeuPbXTaBwzoIpX1+2i1doHZNr4gZw5cRBXfMyd4n/syGrOnjSYi44bnnC9iXodbChYBvn29HGO9ARlKj139ccT6iR3KlAjvMs319Pb8hEuOXEkl5w4stNp7FcVZFdjmFMOy/+xgI+N7cfc/2x0NAkojXvHJcck1Csr8WfF0AcLCpZB2osvfGQUM44YzJADYC//57ppbNzdxJj+VW1X7mZMGz+Qpd+b7kwdKULhf45BfD5xQJgD1GDZuIHZOc75gCJzpKLgnfQiiuhKCHvjxkKBEGIn0ATs6qRb9mvHvUZIKfsnF2raNrXznl1KG+RF26WlLR9RkAwCIISolVJOybd7dfY985m2zr5XPqJoYhVRRAYUGaSIIjKgkBnkL3l6r86+Zz7T1tn3yjsUrA9SRBEHAoWsQYooostRkAwihDhTCLFaCLFOCHFdFvX/JoT4UAixwiqrFkIsFEKs1f/76HIhhPi9vvfbQoic5lXkM22FQF/eQUpZUH+AH3gfGA0EgeXAhDaumQocDaywym4FrtPH1wE/18czgKdRi/VOAN48GGgrBPry8a/bCciZYDgReNb6fT1wfRbXjUz6yKuBwfp4MLBaH/8ZuNCrXiHTVgj05eNfIZpYQ4HN1u8tuixXDJRSbtfHO4CBnXD/fKatEOjLOxQig3Q6pBJ3eRnOy2faIP/p6ygKkUG2AvaKoxpdlivqhBCDAfT/Dzvh/vlMWyHQl3coRAZ5CxgrhBglhAgCs4AF7bjPAmC2Pp4NzLfKL9URmROAfZY5Uci0FQJ9+YfudoLa84eKlqxBRWRuzKL+Q8B2IIKyiy8H+gLPA2uBRUC1riuA2/S93wGmHCy0FQJ9+fZXHEkvoogMKEQTq4giDhiKDFJEERlQZJAiisiAIoMUUUQGFBmkiCIyoMggRRSRAUUGKaKIDCgySBFFZMD/A90JctaZJf1/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x216 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "r=[random.randint(0,356),random.randint(0,356),random.randint(0,356)]\n",
    "r=r+r\n",
    "print(r)\n",
    "fig = plt.figure(figsize=(2, 3))\n",
    "for i in range(6):\n",
    "    x = i%2\n",
    "    y = i//2\n",
    "    ax = fig.add_subplot(2, 3, i+1)\n",
    "    if(i<3):\n",
    "        ax.title.set_text(\"rPPG_chunck_\"+str(r[i]))\n",
    "        ax.plot(rPPG[r[i]][0]) \n",
    "    else:\n",
    "        ax.title.set_text(\"bvp_chunck_\"+str(r[i]))\n",
    "        ax.plot(rPPG[r[i]][1]) \n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6186d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe87ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('epoch_loss.sv', 'rb') as f:\n",
    "    loss = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bcf59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): \n",
    "    for data in testloader: \n",
    "        inputs, targets = data \n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        predicted_outputs = model(inputs,0.2) \n",
    "        print(predicted_outputs[0][0])\n",
    "        print(targets[0][0])\n",
    "\n",
    "        #_, predicted = torch.max(predicted_outputs, 1) \n",
    "        #total += outputs.size(0) \n",
    "        #running_accuracy += (predicted == outputs).sum().item() \n",
    "\n",
    "    #print('Accuracy of the model based on the test set of', test_split ,'inputs is: %d %%' % (100 * running_accuracy / total))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60046908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_bvp = signal.resample(sigGT.data, len(webs))\n",
    "print(webs.shape,torch.as_tensor(train_bvp).shape)\n",
    "dataset = torch.utils.data.TensorDataset(webs,torch.as_tensor(train_bvp))\n",
    "trainloader = torch.utils.data.DataLoader(dataset, shuffle=True, num_workers=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd398866",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "accuracy = 0.0\n",
    "total = 0.0\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(trainloader, 1):\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        outputs = model(inputs)\n",
    "        err = torch.abs(torch.mean(outputs,1)- targets).item()\n",
    "        total = i\n",
    "        accuracy += err\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write(f\"Iteration {i}, Accuracy: {accuracy/total:1.5f} {outputs}\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a6ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 15\n",
    "EMBED_DIM = PATCH_SIZE * PATCH_SIZE * 3\n",
    "NUM_PATCHES = 100\n",
    "IMG_SIZE = PATCH_SIZE * NUM_PATCHES\n",
    "HEADS = 5\n",
    "BLOCKS = 12\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "  def __init__(self, img_size, patch_size, in_chans=3, embed_dim=EMBED_DIM):\n",
    "    super().__init__()\n",
    "    self.img_size = img_size\n",
    "    self.patch_size = patch_size\n",
    "    self.n_patches = (img_size // patch_size) ** 2\n",
    "    self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.movedim(x,3,1)\n",
    "    x = self.proj(x)       # (n_samples, embed_dim, n_patches ** 0.5, n_patches ** 0.5)\n",
    "    x = x.flatten(2)        # (n_samples, embed_dim, n_patches)\n",
    "    x = x.transpose(1, 2)  # (n_samples, n_patches, embed_dim)\n",
    "\n",
    "    return x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "\n",
    "\n",
    "  def __init__(self, dim, n_heads=HEADS, qkv_bias=True, attn_p=0., proj_p=0.):\n",
    "    super().__init__()\n",
    "    self.n_heads = n_heads\n",
    "    self.dim = dim\n",
    "    self.head_dim = dim // n_heads\n",
    "    self.scale = self.head_dim ** -0.5\n",
    "\n",
    "    self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "    self.attn_drop = nn.Dropout(attn_p)\n",
    "    self.proj = nn.Linear(dim, dim)\n",
    "    self.proj_drop = nn.Dropout(proj_p)\n",
    "\n",
    "  def forward(self, x):\n",
    "    n_samples, n_tokens, dim = x.shape\n",
    "\n",
    "    if dim != self.dim:\n",
    "      raise ValueError\n",
    "\n",
    "    qkv = self.qkv(x)  # (n_samples, n_patches + 1, 3 * dim)\n",
    "    qkv = qkv.reshape(n_samples, n_tokens, 3, self.n_heads, self.head_dim)  # (n_smaples, n_patches + 1, 3, n_heads, head_dim)\n",
    "    qkv = qkv.permute(2, 0, 3, 1, 4)  # (3, n_samples, n_heads, n_patches + 1, head_dim)\n",
    "\n",
    "    # compute att matrices\n",
    "    q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "    k_t = k.transpose(-2, -1)   # (n_samples, n_heads, head_dim, n_patches + 1)\n",
    "    dp = (q @ k_t) * self.scale\n",
    "\n",
    "    attn = dp.softmax(dim=-1)   # (n_samples, n_heads, n_patches + 1, n_patches + 1)\n",
    "    attn = self.attn_drop(attn)\n",
    "\n",
    "    # compute weigthed avg\n",
    "    weighted_avg = attn @ v  # (n_samples, n_heads, n_patches +1, head_dim)\n",
    "    weighted_avg = weighted_avg.transpose(1, 2)  # (n_samples, n_patches + 1, n_heads, head_dim)\n",
    "    weighted_avg = weighted_avg.flatten(2)  # (n_samples, n_patches + 1, dim)\n",
    "\n",
    "    # linear projection\n",
    "    x = self.proj(weighted_avg)  # (n_samples, n_patches + 1, dim)\n",
    "    x = self.proj_drop(x)        # (n_samples, n_patches + 1, dim)\n",
    "\n",
    "    return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, hidden_features, out_features, p=0.):\n",
    "      super().__init__()\n",
    "      self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "      self.act = nn.GELU()\n",
    "      self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "      self.drop = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.fc1(x)   # (n_samples, n_patches + 1, hidden_features)\n",
    "      x = self.act(x)   # (n_samples, n_patches + 1, hidden_features)\n",
    "      x = self.drop(x)  # (n_samples, n_patches + 1, hidden_features)\n",
    "      x = self.fc2(x)   # (n_samples, n_patches + 1, hidden_features)\n",
    "      x = self.drop(x)  # (n_samples, n_patches + 1, hidden_features)\n",
    "\n",
    "      return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim, n_heads, mlp_ratio=4.0, qkv_bias=True, p=0., attn_p=0.):\n",
    "      super().__init__()\n",
    "      self.norm1 = nn.LayerNorm(dim, eps=1e-6)\n",
    "      self.attn = Attention(dim, n_heads=n_heads, qkv_bias=qkv_bias, attn_p=attn_p, proj_p=p)\n",
    "      self.norm2 = nn.LayerNorm(dim, eps=1e-6)\n",
    "      hidden_features = int(dim * mlp_ratio)\n",
    "      self.mlp = MLP(in_features=dim, hidden_features=hidden_features, out_features=dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "     \n",
    "      \n",
    "      x = x + self.attn(self.norm1(x))\n",
    "      x = x + self.mlp(self.norm2(x))\n",
    "\n",
    "      return x\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "  \n",
    "  def __init__(\n",
    "          self,\n",
    "          img_size=IMG_SIZE,\n",
    "          patch_size=PATCH_SIZE,\n",
    "          in_chans=3,\n",
    "          n_classes=1000,\n",
    "          embed_dim=EMBED_DIM,\n",
    "          depth=BLOCKS,\n",
    "          n_heads=HEADS,\n",
    "          mlp_ratio=4.,\n",
    "          qkv_bias=True,\n",
    "          p=0.,\n",
    "          attn_p=0.,\n",
    "  ):\n",
    "    super().__init__()\n",
    "\n",
    "    self.patch_embed = PatchEmbed(\n",
    "            img_size=img_size,\n",
    "            patch_size=patch_size,\n",
    "            in_chans=in_chans,\n",
    "            embed_dim=embed_dim,\n",
    "    )\n",
    "    self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "    self.pos_embed = nn.Parameter(\n",
    "            torch.zeros(1, 1 + self.patch_embed.n_patches, embed_dim)\n",
    "    )\n",
    "    self.pos_drop = nn.Dropout(p=p)\n",
    "\n",
    "    self.blocks = nn.ModuleList(\n",
    "        [\n",
    "            Block(\n",
    "                dim=embed_dim,\n",
    "                n_heads=n_heads,\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                qkv_bias=qkv_bias,\n",
    "                p=p,\n",
    "                attn_p=attn_p,\n",
    "            )\n",
    "            for _ in range(depth)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.norm = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "    self.head = nn.Linear(embed_dim, n_classes)\n",
    "    self.lastConv = nn.Conv1d(embed_dim, 1,1,stride=1, padding=0)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    n_samples = x.shape[0]\n",
    "    x = self.patch_embed(x)  #(n_samples, n_patches, embed_dim)\n",
    "    \n",
    "    \n",
    "    cls_token = self.cls_token.expand(n_samples, -1, -1)  # (n_samples, 1, embed_dim)\n",
    "    x = torch.cat((cls_token, x), dim=1)  # (n_samples, 1 + n_patches, embed_dim)\n",
    "    #x = x + self.pos_embed  # (n_samples, 1 + n_patches, embed_dim)\n",
    "    x = self.pos_drop(x)\n",
    "\n",
    "    for block in self.blocks:\n",
    "      x = block(x)\n",
    "\n",
    "    x = self.norm(x)\n",
    "\n",
    "    cls_token_final = x[:, 0]  # just the CLS token\n",
    "    #x = self.head(cls_token_final)\n",
    "    #x = x.type(torch.DoubleTensor)\n",
    "    #x = torch.mean(x,1)\n",
    "    #x = torch.mean(x,1)\n",
    "    x = x.permute(0, 2, 1) \n",
    "    x = self.lastConv(x)\n",
    "    x = x.squeeze(1)\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744425cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b38c1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
